{"trial_data": [["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00099\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303939948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 26,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 26,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 26,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"99_activation=relu,batch_size=128,dropout_rate=0.1000,hidden_sizes=512,lr=0.0001,num_epochs=26,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00099\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00099\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00031\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303331948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 18,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 18,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 18,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"31_activation=relu,batch_size=32,dropout_rate=0.2000,hidden_sizes=512,lr=0.0001,num_epochs=18,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00031\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00031\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724685496.0711832,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.9079255751662123,\n    \"precision\": 0.9079604371812396,\n    \"recall\": 0.9079255751662123,\n    \"f1_score\": 0.9075367276919162,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d62756666657294939428438086090000000000001d000000000000002f0200000000000067000000000000000d000000000000008c0a0000000000003f010000000000005e0000000000000095010000000000005e01000000000000a24b00000000000002050000000000001b00000000000000350000000000000068020000000000009834000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.85      0.78      0.81      3129\\n     hyponym       0.86      0.86      0.86      3126\\n        none       0.93      0.90      0.92     21399\\n    synonymy       0.90      0.95      0.93     14160\\n\\n    accuracy                           0.91     41814\\n   macro avg       0.88      0.87      0.88     41814\\nweighted avg       0.91      0.91      0.91     41814\\n\",\n    \"timestamp\": 1724685683,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00031\",\n    \"date\": \"2024-08-26_18-21-23\",\n    \"time_this_iter_s\": 187.3624668121338,\n    \"time_total_s\": 187.3624668121338,\n    \"pid\": 7064,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 18,\n      \"batch_size\": 32,\n      \"hidden_sizes\": [\n        512\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 187.3624668121338,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"31_activation=relu,batch_size=32,dropout_rate=0.2000,hidden_sizes=512,lr=0.0001,num_epochs=18,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724685683.4380293,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.9079255751662123,\n      \"min\": 0.9079255751662123,\n      \"avg\": 0.9079255751662123,\n      \"last\": 0.9079255751662123,\n      \"last-5-avg\": 0.9079255751662123,\n      \"last-10-avg\": 0.9079255751662123\n    },\n    \"precision\": {\n      \"max\": 0.9079604371812396,\n      \"min\": 0.9079604371812396,\n      \"avg\": 0.9079604371812396,\n      \"last\": 0.9079604371812396,\n      \"last-5-avg\": 0.9079604371812396,\n      \"last-10-avg\": 0.9079604371812396\n    },\n    \"recall\": {\n      \"max\": 0.9079255751662123,\n      \"min\": 0.9079255751662123,\n      \"avg\": 0.9079255751662123,\n      \"last\": 0.9079255751662123,\n      \"last-5-avg\": 0.9079255751662123,\n      \"last-10-avg\": 0.9079255751662123\n    },\n    \"f1_score\": {\n      \"max\": 0.9075367276919162,\n      \"min\": 0.9075367276919162,\n      \"avg\": 0.9075367276919162,\n      \"last\": 0.9075367276919162,\n      \"last-5-avg\": 0.9075367276919162,\n      \"last-10-avg\": 0.9075367276919162\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 187.3624668121338,\n      \"min\": 187.3624668121338,\n      \"avg\": 187.3624668121338,\n      \"last\": 187.3624668121338,\n      \"last-5-avg\": 187.3624668121338,\n      \"last-10-avg\": 187.3624668121338\n    },\n    \"time_total_s\": {\n      \"max\": 187.3624668121338,\n      \"min\": 187.3624668121338,\n      \"avg\": 187.3624668121338,\n      \"last\": 187.3624668121338,\n      \"last-5-avg\": 187.3624668121338,\n      \"last-10-avg\": 187.3624668121338\n    },\n    \"time_since_restore\": {\n      \"max\": 187.3624668121338,\n      \"min\": 187.3624668121338,\n      \"avg\": 187.3624668121338,\n      \"last\": 187.3624668121338,\n      \"last-5-avg\": 187.3624668121338,\n      \"last-10-avg\": 187.3624668121338\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fed0db9ef914ed2612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fed0db9ef914ed2612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084f2bf80b030eed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084f2bf80b030eed3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d24e91efb90ded3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d24e91efb90ded3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086261ab768a0aed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086261ab768a0aed3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740676b9954000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740676b9954000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740676b9954000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740676b9954000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740676b9954000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740676b9954000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00095\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303935948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 45,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 45,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 45,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"95_activation=relu,batch_size=512,dropout_rate=0.1000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=45,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00095\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00095\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00054\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303534948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 43,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 43,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 43,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"54_activation=relu,batch_size=32,dropout_rate=0.2000,hidden_sizes=512,lr=0.0001,num_epochs=43,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00054\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00054\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724691150.1037242,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.910675850193715,\n    \"precision\": 0.9105632474955996,\n    \"recall\": 0.910675850193715,\n    \"f1_score\": 0.9103683958902826,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380e3090000000000000e000000000000000b020000000000003d000000000000001800000000000000470a0000000000008a010000000000004d00000000000000b301000000000000fb00000000000000304c000000000000b90400000000000022000000000000001700000000000000b2020000000000006534000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.84      0.81      0.82      3129\\n     hyponym       0.90      0.84      0.87      3126\\n        none       0.92      0.91      0.92     21399\\n    synonymy       0.91      0.95      0.93     14160\\n\\n    accuracy                           0.91     41814\\n   macro avg       0.89      0.88      0.88     41814\\nweighted avg       0.91      0.91      0.91     41814\\n\",\n    \"timestamp\": 1724691498,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00054\",\n    \"date\": \"2024-08-26_19-58-18\",\n    \"time_this_iter_s\": 348.84644412994385,\n    \"time_total_s\": 348.84644412994385,\n    \"pid\": 29336,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 43,\n      \"batch_size\": 32,\n      \"hidden_sizes\": [\n        512\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 348.84644412994385,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"54_activation=relu,batch_size=32,dropout_rate=0.2000,hidden_sizes=512,lr=0.0001,num_epochs=43,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724691498.9541702,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.910675850193715,\n      \"min\": 0.910675850193715,\n      \"avg\": 0.910675850193715,\n      \"last\": 0.910675850193715,\n      \"last-5-avg\": 0.910675850193715,\n      \"last-10-avg\": 0.910675850193715\n    },\n    \"precision\": {\n      \"max\": 0.9105632474955996,\n      \"min\": 0.9105632474955996,\n      \"avg\": 0.9105632474955996,\n      \"last\": 0.9105632474955996,\n      \"last-5-avg\": 0.9105632474955996,\n      \"last-10-avg\": 0.9105632474955996\n    },\n    \"recall\": {\n      \"max\": 0.910675850193715,\n      \"min\": 0.910675850193715,\n      \"avg\": 0.910675850193715,\n      \"last\": 0.910675850193715,\n      \"last-5-avg\": 0.910675850193715,\n      \"last-10-avg\": 0.910675850193715\n    },\n    \"f1_score\": {\n      \"max\": 0.9103683958902826,\n      \"min\": 0.9103683958902826,\n      \"avg\": 0.9103683958902826,\n      \"last\": 0.9103683958902826,\n      \"last-5-avg\": 0.9103683958902826,\n      \"last-10-avg\": 0.9103683958902826\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 348.84644412994385,\n      \"min\": 348.84644412994385,\n      \"avg\": 348.84644412994385,\n      \"last\": 348.84644412994385,\n      \"last-5-avg\": 348.84644412994385,\n      \"last-10-avg\": 348.84644412994385\n    },\n    \"time_total_s\": {\n      \"max\": 348.84644412994385,\n      \"min\": 348.84644412994385,\n      \"avg\": 348.84644412994385,\n      \"last\": 348.84644412994385,\n      \"last-5-avg\": 348.84644412994385,\n      \"last-10-avg\": 348.84644412994385\n    },\n    \"time_since_restore\": {\n      \"max\": 348.84644412994385,\n      \"min\": 348.84644412994385,\n      \"avg\": 348.84644412994385,\n      \"last\": 348.84644412994385,\n      \"last-5-avg\": 348.84644412994385,\n      \"last-10-avg\": 348.84644412994385\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fed2441ae3ad919612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fed2441ae3ad919612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430866dc1d895523ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430866dc1d895523ed3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430819d93aae4124ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430819d93aae4124ed3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d224f5e6bc21ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d224f5e6bc21ed3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474075cd8b09000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474075cd8b09000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474075cd8b09000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474075cd8b09000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474075cd8b09000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474075cd8b09000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00025\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 69,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 69,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 69,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"25_activation=relu,batch_size=512,dropout_rate=0.1000,hidden_sizes=512,lr=0.0000,num_epochs=69,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00025\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00025\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724684901.13622,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8847754340651457,\n    \"precision\": 0.8837967017558492,\n    \"recall\": 0.8847754340651457,\n    \"f1_score\": 0.8826836014902246,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380cd070000000000001100000000000000cf030000000000008c000000000000000f0000000000000020090000000000006202000000000000a5000000000000004801000000000000f100000000000000fd4c00000000000061040000000000003a00000000000000430000000000000039040000000000009a32000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.83      0.64      0.72      3129\\n     hyponym       0.88      0.75      0.81      3126\\n        none       0.88      0.92      0.90     21399\\n    synonymy       0.90      0.91      0.91     14160\\n\\n    accuracy                           0.88     41814\\n   macro avg       0.87      0.81      0.83     41814\\nweighted avg       0.88      0.88      0.88     41814\\n\",\n    \"timestamp\": 1724685002,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00025\",\n    \"date\": \"2024-08-26_18-10-02\",\n    \"time_this_iter_s\": 101.83702158927917,\n    \"time_total_s\": 101.83702158927917,\n    \"pid\": 3876,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 69,\n      \"batch_size\": 512,\n      \"hidden_sizes\": [\n        512\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.1,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 101.83702158927917,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"25_activation=relu,batch_size=512,dropout_rate=0.1000,hidden_sizes=512,lr=0.0000,num_epochs=69,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724685002.9787972,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8847754340651457,\n      \"min\": 0.8847754340651457,\n      \"avg\": 0.8847754340651457,\n      \"last\": 0.8847754340651457,\n      \"last-5-avg\": 0.8847754340651457,\n      \"last-10-avg\": 0.8847754340651457\n    },\n    \"precision\": {\n      \"max\": 0.8837967017558492,\n      \"min\": 0.8837967017558492,\n      \"avg\": 0.8837967017558492,\n      \"last\": 0.8837967017558492,\n      \"last-5-avg\": 0.8837967017558492,\n      \"last-10-avg\": 0.8837967017558492\n    },\n    \"recall\": {\n      \"max\": 0.8847754340651457,\n      \"min\": 0.8847754340651457,\n      \"avg\": 0.8847754340651457,\n      \"last\": 0.8847754340651457,\n      \"last-5-avg\": 0.8847754340651457,\n      \"last-10-avg\": 0.8847754340651457\n    },\n    \"f1_score\": {\n      \"max\": 0.8826836014902246,\n      \"min\": 0.8826836014902246,\n      \"avg\": 0.8826836014902246,\n      \"last\": 0.8826836014902246,\n      \"last-5-avg\": 0.8826836014902246,\n      \"last-10-avg\": 0.8826836014902246\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 101.83702158927917,\n      \"min\": 101.83702158927917,\n      \"avg\": 101.83702158927917,\n      \"last\": 101.83702158927917,\n      \"last-5-avg\": 101.83702158927917,\n      \"last-10-avg\": 101.83702158927917\n    },\n    \"time_total_s\": {\n      \"max\": 101.83702158927917,\n      \"min\": 101.83702158927917,\n      \"avg\": 101.83702158927917,\n      \"last\": 101.83702158927917,\n      \"last-5-avg\": 101.83702158927917,\n      \"last-10-avg\": 101.83702158927917\n    },\n    \"time_since_restore\": {\n      \"max\": 101.83702158927917,\n      \"min\": 101.83702158927917,\n      \"avg\": 101.83702158927917,\n      \"last\": 101.83702158927917,\n      \"last-5-avg\": 101.83702158927917,\n      \"last-10-avg\": 101.83702158927917\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fec50149233a5ee612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fec50149233a5ee612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430848544b051048ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430848544b051048ec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308eea533921450ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308eea533921450ec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085eb623aef13eec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085eb623aef13eec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740597591c3000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740597591c3000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740597591c3000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740597591c3000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740597591c3000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740597591c3000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00023\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303233948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 28,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 28,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 28,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"23_activation=relu,batch_size=32,dropout_rate=0.2000,hidden_sizes=128_64,lr=0.0000,num_epochs=28,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00023\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00023\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724684313.7291772,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8752092600564404,\n    \"precision\": 0.8739789176591659,\n    \"recall\": 0.8752092600564404,\n    \"f1_score\": 0.8721837973449857,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380210700000000000011000000000000003b04000000000000cc000000000000000c00000000000000d3080000000000009502000000000000c20000000000000030010000000000001801000000000000154c0000000000003a050000000000002c000000000000004c00000000000000ed03000000000000eb32000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.84      0.58      0.69      3129\\n     hyponym       0.86      0.72      0.78      3126\\n        none       0.88      0.91      0.89     21399\\n    synonymy       0.88      0.92      0.90     14160\\n\\n    accuracy                           0.88     41814\\n   macro avg       0.86      0.78      0.82     41814\\nweighted avg       0.87      0.88      0.87     41814\\n\",\n    \"timestamp\": 1724684625,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00023\",\n    \"date\": \"2024-08-26_18-03-45\",\n    \"time_this_iter_s\": 311.95633125305176,\n    \"time_total_s\": 311.95633125305176,\n    \"pid\": 31080,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 28,\n      \"batch_size\": 32,\n      \"hidden_sizes\": [\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 311.95633125305176,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"23_activation=relu,batch_size=32,dropout_rate=0.2000,hidden_sizes=128_64,lr=0.0000,num_epochs=28,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724684625.6915114,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8752092600564404,\n      \"min\": 0.8752092600564404,\n      \"avg\": 0.8752092600564404,\n      \"last\": 0.8752092600564404,\n      \"last-5-avg\": 0.8752092600564404,\n      \"last-10-avg\": 0.8752092600564404\n    },\n    \"precision\": {\n      \"max\": 0.8739789176591659,\n      \"min\": 0.8739789176591659,\n      \"avg\": 0.8739789176591659,\n      \"last\": 0.8739789176591659,\n      \"last-5-avg\": 0.8739789176591659,\n      \"last-10-avg\": 0.8739789176591659\n    },\n    \"recall\": {\n      \"max\": 0.8752092600564404,\n      \"min\": 0.8752092600564404,\n      \"avg\": 0.8752092600564404,\n      \"last\": 0.8752092600564404,\n      \"last-5-avg\": 0.8752092600564404,\n      \"last-10-avg\": 0.8752092600564404\n    },\n    \"f1_score\": {\n      \"max\": 0.8721837973449857,\n      \"min\": 0.8721837973449857,\n      \"avg\": 0.8721837973449857,\n      \"last\": 0.8721837973449857,\n      \"last-5-avg\": 0.8721837973449857,\n      \"last-10-avg\": 0.8721837973449857\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 311.95633125305176,\n      \"min\": 311.95633125305176,\n      \"avg\": 311.95633125305176,\n      \"last\": 311.95633125305176,\n      \"last-5-avg\": 311.95633125305176,\n      \"last-10-avg\": 311.95633125305176\n    },\n    \"time_total_s\": {\n      \"max\": 311.95633125305176,\n      \"min\": 311.95633125305176,\n      \"avg\": 311.95633125305176,\n      \"last\": 311.95633125305176,\n      \"last-5-avg\": 311.95633125305176,\n      \"last-10-avg\": 311.95633125305176\n    },\n    \"time_since_restore\": {\n      \"max\": 311.95633125305176,\n      \"min\": 311.95633125305176,\n      \"avg\": 311.95633125305176,\n      \"last\": 311.95633125305176,\n      \"last-5-avg\": 311.95633125305176,\n      \"last-10-avg\": 311.95633125305176\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fec01b6d9a32921612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fec01b6d9a32921612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c2aa97a2a2f7eb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c2aa97a2a2f7eb3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082129a3d9b601ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082129a3d9b601ec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086c54b6feede8eb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086c54b6feede8eb3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740737f4d22000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740737f4d22000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740737f4d22000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740737f4d22000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740737f4d22000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740737f4d22000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00066\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303636948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 46,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 46,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 46,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"66_activation=relu,batch_size=32,dropout_rate=0.2000,hidden_sizes=1024_512_256_128_64,lr=0.0000,num_epochs=46,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00066\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00066\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724693205.5181086,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.919668053761898,\n    \"precision\": 0.9216999893852965,\n    \"recall\": 0.919668053761898,\n    \"f1_score\": 0.919695504929337,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380980a00000000000013000000000000005a0100000000000034000000000000001600000000000000f00a00000000000001010000000000002f00000000000000fb010000000000005301000000000000dd4a0000000000006c05000000000000310000000000000027000000000000002601000000000000d235000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.82      0.87      0.84      3129\\n     hyponym       0.88      0.90      0.89      3126\\n        none       0.96      0.90      0.92     21399\\n    synonymy       0.90      0.97      0.94     14160\\n\\n    accuracy                           0.92     41814\\n   macro avg       0.89      0.91      0.90     41814\\nweighted avg       0.92      0.92      0.92     41814\\n\",\n    \"timestamp\": 1724693964,\n    \"checkpoint_dir_name\": null,\n    \"done\": false,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00066\",\n    \"date\": \"2024-08-26_20-39-24\",\n    \"time_this_iter_s\": 759.4424123764038,\n    \"time_total_s\": 759.4424123764038,\n    \"pid\": 2872,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 46,\n      \"batch_size\": 32,\n      \"hidden_sizes\": [\n        1024,\n        512,\n        256,\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 759.4424123764038,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"66_activation=relu,batch_size=32,dropout_rate=0.2000,hidden_sizes=1024_512_256_128_64,lr=0.0000,num_epochs=46,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724693964.9649727,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.919668053761898,\n      \"min\": 0.919668053761898,\n      \"avg\": 0.919668053761898,\n      \"last\": 0.919668053761898,\n      \"last-5-avg\": 0.919668053761898,\n      \"last-10-avg\": 0.919668053761898\n    },\n    \"precision\": {\n      \"max\": 0.9216999893852965,\n      \"min\": 0.9216999893852965,\n      \"avg\": 0.9216999893852965,\n      \"last\": 0.9216999893852965,\n      \"last-5-avg\": 0.9216999893852965,\n      \"last-10-avg\": 0.9216999893852965\n    },\n    \"recall\": {\n      \"max\": 0.919668053761898,\n      \"min\": 0.919668053761898,\n      \"avg\": 0.919668053761898,\n      \"last\": 0.919668053761898,\n      \"last-5-avg\": 0.919668053761898,\n      \"last-10-avg\": 0.919668053761898\n    },\n    \"f1_score\": {\n      \"max\": 0.919695504929337,\n      \"min\": 0.919695504929337,\n      \"avg\": 0.919695504929337,\n      \"last\": 0.919695504929337,\n      \"last-5-avg\": 0.919695504929337,\n      \"last-10-avg\": 0.919695504929337\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 759.4424123764038,\n      \"min\": 759.4424123764038,\n      \"avg\": 759.4424123764038,\n      \"last\": 759.4424123764038,\n      \"last-5-avg\": 759.4424123764038,\n      \"last-10-avg\": 759.4424123764038\n    },\n    \"time_total_s\": {\n      \"max\": 759.4424123764038,\n      \"min\": 759.4424123764038,\n      \"avg\": 759.4424123764038,\n      \"last\": 759.4424123764038,\n      \"last-5-avg\": 759.4424123764038,\n      \"last-10-avg\": 759.4424123764038\n    },\n    \"time_since_restore\": {\n      \"max\": 759.4424123764038,\n      \"min\": 759.4424123764038,\n      \"avg\": 759.4424123764038,\n      \"last\": 759.4424123764038,\n      \"last-5-avg\": 759.4424123764038,\n      \"last-10-avg\": 759.4424123764038\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fed6debb2c2aa92612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fed6debb2c2aa92612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c744e4f9907eed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c744e4f9907eed3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430892aac2b2eb6ded3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430892aac2b2eb6ded3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430805647e44256eed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430805647e44256eed3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474087bb8a0f800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474087bb8a0f800000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474087bb8a0f800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474087bb8a0f800000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474087bb8a0f800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474087bb8a0f800000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00016\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303136948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 43,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 43,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 43,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"16_activation=relu,batch_size=512,dropout_rate=0.0000,hidden_sizes=1024_512_256_128_64,lr=0.0000,num_epochs=43,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00016\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00016\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724682669.3572075,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8772811230144071,\n    \"precision\": 0.8755394815436105,\n    \"recall\": 0.8772811230144071,\n    \"f1_score\": 0.8758540801883841,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d62756666657294939428438004080000000000002900000000000000380300000000000094000000000000002c00000000000000d8080000000000003202000000000000f500000000000000fb010000000000006901000000000000c946000000000000fd0400000000000070000000000000007e00000000000000e0020000000000008133000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.76      0.67      0.71      3065\\n     hyponym       0.81      0.73      0.77      3115\\n        none       0.90      0.89      0.89     20266\\n    synonymy       0.89      0.93      0.91     14159\\n\\n    accuracy                           0.88     40605\\n   macro avg       0.84      0.81      0.82     40605\\nweighted avg       0.88      0.88      0.88     40605\\n\",\n    \"timestamp\": 1724682771,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00016\",\n    \"date\": \"2024-08-26_17-32-51\",\n    \"time_this_iter_s\": 102.24685907363892,\n    \"time_total_s\": 102.24685907363892,\n    \"pid\": 23804,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 43,\n      \"batch_size\": 512,\n      \"hidden_sizes\": [\n        1024,\n        512,\n        256,\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.0,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 102.24685907363892,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"16_activation=relu,batch_size=512,dropout_rate=0.0000,hidden_sizes=1024_512_256_128_64,lr=0.0000,num_epochs=43,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724682771.6082778,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8772811230144071,\n      \"min\": 0.8772811230144071,\n      \"avg\": 0.8772811230144071,\n      \"last\": 0.8772811230144071,\n      \"last-5-avg\": 0.8772811230144071,\n      \"last-10-avg\": 0.8772811230144071\n    },\n    \"precision\": {\n      \"max\": 0.8755394815436105,\n      \"min\": 0.8755394815436105,\n      \"avg\": 0.8755394815436105,\n      \"last\": 0.8755394815436105,\n      \"last-5-avg\": 0.8755394815436105,\n      \"last-10-avg\": 0.8755394815436105\n    },\n    \"recall\": {\n      \"max\": 0.8772811230144071,\n      \"min\": 0.8772811230144071,\n      \"avg\": 0.8772811230144071,\n      \"last\": 0.8772811230144071,\n      \"last-5-avg\": 0.8772811230144071,\n      \"last-10-avg\": 0.8772811230144071\n    },\n    \"f1_score\": {\n      \"max\": 0.8758540801883841,\n      \"min\": 0.8758540801883841,\n      \"avg\": 0.8758540801883841,\n      \"last\": 0.8758540801883841,\n      \"last-5-avg\": 0.8758540801883841,\n      \"last-10-avg\": 0.8758540801883841\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 102.24685907363892,\n      \"min\": 102.24685907363892,\n      \"avg\": 102.24685907363892,\n      \"last\": 102.24685907363892,\n      \"last-5-avg\": 102.24685907363892,\n      \"last-10-avg\": 102.24685907363892\n    },\n    \"time_total_s\": {\n      \"max\": 102.24685907363892,\n      \"min\": 102.24685907363892,\n      \"avg\": 102.24685907363892,\n      \"last\": 102.24685907363892,\n      \"last-5-avg\": 102.24685907363892,\n      \"last-10-avg\": 102.24685907363892\n    },\n    \"time_since_restore\": {\n      \"max\": 102.24685907363892,\n      \"min\": 102.24685907363892,\n      \"avg\": 102.24685907363892,\n      \"last\": 102.24685907363892,\n      \"last-5-avg\": 102.24685907363892,\n      \"last-10-avg\": 102.24685907363892\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fec12afdc97d74c612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fec12afdc97d74c612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430873c5f25f6b04ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430873c5f25f6b04ec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084cd797dcaf12ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084cd797dcaf12ec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ce45cf22ff06ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ce45cf22ff06ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740598fcc8a000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740598fcc8a000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740598fcc8a000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740598fcc8a000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740598fcc8a000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740598fcc8a000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00034\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303334948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 44,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 44,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 44,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"34_activation=relu,batch_size=32,dropout_rate=0.2000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=44,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00034\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00034\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724685977.411401,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.9165373722447975,\n    \"precision\": 0.9170318688644103,\n    \"recall\": 0.9165373722447975,\n    \"f1_score\": 0.9162133710349052,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380180a0000000000000c000000000000009b010000000000003a0000000000000019000000000000003e0a000000000000910100000000000043000000000000007801000000000000dc00000000000000ae47000000000000280500000000000020000000000000002100000000000000b2010000000000005c35000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.86      0.84      0.85      3065\\n     hyponym       0.91      0.84      0.87      3115\\n        none       0.94      0.91      0.92     20266\\n    synonymy       0.90      0.96      0.93     14159\\n\\n    accuracy                           0.92     40605\\n   macro avg       0.90      0.89      0.89     40605\\nweighted avg       0.92      0.92      0.92     40605\\n\",\n    \"timestamp\": 1724686690,\n    \"checkpoint_dir_name\": null,\n    \"done\": false,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00034\",\n    \"date\": \"2024-08-26_18-38-10\",\n    \"time_this_iter_s\": 712.9551215171814,\n    \"time_total_s\": 712.9551215171814,\n    \"pid\": 33244,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 44,\n      \"batch_size\": 32,\n      \"hidden_sizes\": [\n        1024,\n        512,\n        256,\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 712.9551215171814,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"34_activation=relu,batch_size=32,dropout_rate=0.2000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=44,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724686690.3715305,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.9165373722447975,\n      \"min\": 0.9165373722447975,\n      \"avg\": 0.9165373722447975,\n      \"last\": 0.9165373722447975,\n      \"last-5-avg\": 0.9165373722447975,\n      \"last-10-avg\": 0.9165373722447975\n    },\n    \"precision\": {\n      \"max\": 0.9170318688644103,\n      \"min\": 0.9170318688644103,\n      \"avg\": 0.9170318688644103,\n      \"last\": 0.9170318688644103,\n      \"last-5-avg\": 0.9170318688644103,\n      \"last-10-avg\": 0.9170318688644103\n    },\n    \"recall\": {\n      \"max\": 0.9165373722447975,\n      \"min\": 0.9165373722447975,\n      \"avg\": 0.9165373722447975,\n      \"last\": 0.9165373722447975,\n      \"last-5-avg\": 0.9165373722447975,\n      \"last-10-avg\": 0.9165373722447975\n    },\n    \"f1_score\": {\n      \"max\": 0.9162133710349052,\n      \"min\": 0.9162133710349052,\n      \"avg\": 0.9162133710349052,\n      \"last\": 0.9162133710349052,\n      \"last-5-avg\": 0.9162133710349052,\n      \"last-10-avg\": 0.9162133710349052\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 712.9551215171814,\n      \"min\": 712.9551215171814,\n      \"avg\": 712.9551215171814,\n      \"last\": 712.9551215171814,\n      \"last-5-avg\": 712.9551215171814,\n      \"last-10-avg\": 712.9551215171814\n    },\n    \"time_total_s\": {\n      \"max\": 712.9551215171814,\n      \"min\": 712.9551215171814,\n      \"avg\": 712.9551215171814,\n      \"last\": 712.9551215171814,\n      \"last-5-avg\": 712.9551215171814,\n      \"last-10-avg\": 712.9551215171814\n    },\n    \"time_since_restore\": {\n      \"max\": 712.9551215171814,\n      \"min\": 712.9551215171814,\n      \"avg\": 712.9551215171814,\n      \"last\": 712.9551215171814,\n      \"last-5-avg\": 712.9551215171814,\n      \"last-10-avg\": 712.9551215171814\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fed54462eeb4d47612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fed54462eeb4d47612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086832c5375358ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086832c5375358ed3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308474deb2e4654ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308474deb2e4654ed3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308321718b49e51ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308321718b49e51ed3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447408647a416c00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447408647a416c00000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447408647a416c00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447408647a416c00000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447408647a416c00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447408647a416c00000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00042\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303432948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 65,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 65,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 65,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"42_activation=relu,batch_size=32,dropout_rate=0.2000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=65,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00042\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00042\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724687555.1728356,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.920477773673193,\n    \"precision\": 0.9218191345819003,\n    \"recall\": 0.920477773673193,\n    \"f1_score\": 0.9202203002468098,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380580a00000000000014000000000000005e010000000000002f000000000000001a00000000000000690a000000000000540100000000000054000000000000008b01000000000000d900000000000000454700000000000081050000000000001a0000000000000012000000000000002901000000000000fa35000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.86      0.86      0.86      3065\\n     hyponym       0.91      0.86      0.88      3115\\n        none       0.95      0.90      0.92     20266\\n    synonymy       0.90      0.98      0.94     14159\\n\\n    accuracy                           0.92     40605\\n   macro avg       0.90      0.90      0.90     40605\\nweighted avg       0.92      0.92      0.92     40605\\n\",\n    \"timestamp\": 1724688574,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00042\",\n    \"date\": \"2024-08-26_19-09-34\",\n    \"time_this_iter_s\": 1018.9297451972961,\n    \"time_total_s\": 1018.9297451972961,\n    \"pid\": 32532,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 65,\n      \"batch_size\": 32,\n      \"hidden_sizes\": [\n        1024,\n        512,\n        256,\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 1018.9297451972961,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"42_activation=relu,batch_size=32,dropout_rate=0.2000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=65,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724688574.108467,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.920477773673193,\n      \"min\": 0.920477773673193,\n      \"avg\": 0.920477773673193,\n      \"last\": 0.920477773673193,\n      \"last-5-avg\": 0.920477773673193,\n      \"last-10-avg\": 0.920477773673193\n    },\n    \"precision\": {\n      \"max\": 0.9218191345819003,\n      \"min\": 0.9218191345819003,\n      \"avg\": 0.9218191345819003,\n      \"last\": 0.9218191345819003,\n      \"last-5-avg\": 0.9218191345819003,\n      \"last-10-avg\": 0.9218191345819003\n    },\n    \"recall\": {\n      \"max\": 0.920477773673193,\n      \"min\": 0.920477773673193,\n      \"avg\": 0.920477773673193,\n      \"last\": 0.920477773673193,\n      \"last-5-avg\": 0.920477773673193,\n      \"last-10-avg\": 0.920477773673193\n    },\n    \"f1_score\": {\n      \"max\": 0.9202203002468098,\n      \"min\": 0.9202203002468098,\n      \"avg\": 0.9202203002468098,\n      \"last\": 0.9202203002468098,\n      \"last-5-avg\": 0.9202203002468098,\n      \"last-10-avg\": 0.9202203002468098\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 1018.9297451972961,\n      \"min\": 1018.9297451972961,\n      \"avg\": 1018.9297451972961,\n      \"last\": 1018.9297451972961,\n      \"last-5-avg\": 1018.9297451972961,\n      \"last-10-avg\": 1018.9297451972961\n    },\n    \"time_total_s\": {\n      \"max\": 1018.9297451972961,\n      \"min\": 1018.9297451972961,\n      \"avg\": 1018.9297451972961,\n      \"last\": 1018.9297451972961,\n      \"last-5-avg\": 1018.9297451972961,\n      \"last-10-avg\": 1018.9297451972961\n    },\n    \"time_since_restore\": {\n      \"max\": 1018.9297451972961,\n      \"min\": 1018.9297451972961,\n      \"avg\": 1018.9297451972961,\n      \"last\": 1018.9297451972961,\n      \"last-5-avg\": 1018.9297451972961,\n      \"last-10-avg\": 1018.9297451972961\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fed748dcdd3e14f612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fed748dcdd3e14f612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308af667bd78a7fed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308af667bd78a7fed3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084fe1d3cd8d74ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084fe1d3cd8d74ed3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308759cd5d77172ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308759cd5d77172ed3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447408fd7701e400000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447408fd7701e400000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447408fd7701e400000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447408fd7701e400000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447408fd7701e400000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447408fd7701e400000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00046\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303436948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 14,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 14,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 14,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"46_activation=relu,batch_size=32,dropout_rate=0.2000,hidden_sizes=1024_512_256_128_64,lr=0.0000,num_epochs=14,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00046\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00046\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724689260.2616134,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8943233591922177,\n    \"precision\": 0.8967843944077888,\n    \"recall\": 0.8943233591922177,\n    \"f1_score\": 0.8943197861527394,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d6275666665729493942843809e090000000000001f000000000000009e010000000000009e000000000000002300000000000000360a0000000000004a0100000000000088000000000000008202000000000000780100000000000003450000000000002d0600000000000054000000000000003f00000000000000b9010000000000000335000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.76      0.80      0.78      3065\\n     hyponym       0.85      0.84      0.84      3115\\n        none       0.94      0.87      0.90     20266\\n    synonymy       0.88      0.96      0.92     14159\\n\\n    accuracy                           0.89     40605\\n   macro avg       0.86      0.87      0.86     40605\\nweighted avg       0.90      0.89      0.89     40605\\n\",\n    \"timestamp\": 1724689533,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00046\",\n    \"date\": \"2024-08-26_19-25-33\",\n    \"time_this_iter_s\": 273.37144470214844,\n    \"time_total_s\": 273.37144470214844,\n    \"pid\": 5368,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 14,\n      \"batch_size\": 32,\n      \"hidden_sizes\": [\n        1024,\n        512,\n        256,\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 273.37144470214844,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"46_activation=relu,batch_size=32,dropout_rate=0.2000,hidden_sizes=1024_512_256_128_64,lr=0.0000,num_epochs=14,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724689533.6380584,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8943233591922177,\n      \"min\": 0.8943233591922177,\n      \"avg\": 0.8943233591922177,\n      \"last\": 0.8943233591922177,\n      \"last-5-avg\": 0.8943233591922177,\n      \"last-10-avg\": 0.8943233591922177\n    },\n    \"precision\": {\n      \"max\": 0.8967843944077888,\n      \"min\": 0.8967843944077888,\n      \"avg\": 0.8967843944077888,\n      \"last\": 0.8967843944077888,\n      \"last-5-avg\": 0.8967843944077888,\n      \"last-10-avg\": 0.8967843944077888\n    },\n    \"recall\": {\n      \"max\": 0.8943233591922177,\n      \"min\": 0.8943233591922177,\n      \"avg\": 0.8943233591922177,\n      \"last\": 0.8943233591922177,\n      \"last-5-avg\": 0.8943233591922177,\n      \"last-10-avg\": 0.8943233591922177\n    },\n    \"f1_score\": {\n      \"max\": 0.8943197861527394,\n      \"min\": 0.8943197861527394,\n      \"avg\": 0.8943197861527394,\n      \"last\": 0.8943197861527394,\n      \"last-5-avg\": 0.8943197861527394,\n      \"last-10-avg\": 0.8943197861527394\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 273.37144470214844,\n      \"min\": 273.37144470214844,\n      \"avg\": 273.37144470214844,\n      \"last\": 273.37144470214844,\n      \"last-5-avg\": 273.37144470214844,\n      \"last-10-avg\": 273.37144470214844\n    },\n    \"time_total_s\": {\n      \"max\": 273.37144470214844,\n      \"min\": 273.37144470214844,\n      \"avg\": 273.37144470214844,\n      \"last\": 273.37144470214844,\n      \"last-5-avg\": 273.37144470214844,\n      \"last-10-avg\": 273.37144470214844\n    },\n    \"time_since_restore\": {\n      \"max\": 273.37144470214844,\n      \"min\": 273.37144470214844,\n      \"avg\": 273.37144470214844,\n      \"last\": 273.37144470214844,\n      \"last-5-avg\": 273.37144470214844,\n      \"last-10-avg\": 273.37144470214844\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fec9e4c0578f124612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fec9e4c0578f124612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308836db12f75b2ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308836db12f75b2ec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430824f178054c9eec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430824f178054c9eec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a6223687449eec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a6223687449eec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407115f170000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407115f170000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407115f170000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407115f170000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407115f170000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407115f170000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00048\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303438948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 50,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 50,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 50,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"48_activation=relu,batch_size=32,dropout_rate=0.2000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=50,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00048\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00048\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724689625.8153622,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.9201941933323767,\n    \"precision\": 0.9223477140807763,\n    \"recall\": 0.9201941933323767,\n    \"f1_score\": 0.920173038360211,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d6275666665729493942843809a0a0000000000001700000000000000570100000000000031000000000000001000000000000000070b000000000000e9000000000000003600000000000000f1010000000000004e01000000000000ba4a0000000000009e050000000000001a0000000000000022000000000000002201000000000000f235000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.83      0.87      0.85      3129\\n     hyponym       0.88      0.90      0.89      3126\\n        none       0.96      0.89      0.92     21399\\n    synonymy       0.90      0.98      0.94     14160\\n\\n    accuracy                           0.92     41814\\n   macro avg       0.89      0.91      0.90     41814\\nweighted avg       0.92      0.92      0.92     41814\\n\",\n    \"timestamp\": 1724690443,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00048\",\n    \"date\": \"2024-08-26_19-40-43\",\n    \"time_this_iter_s\": 817.7616677284241,\n    \"time_total_s\": 817.7616677284241,\n    \"pid\": 4768,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 50,\n      \"batch_size\": 32,\n      \"hidden_sizes\": [\n        1024,\n        512,\n        256,\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 817.7616677284241,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"48_activation=relu,batch_size=32,dropout_rate=0.2000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=50,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724690443.5830336,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.9201941933323767,\n      \"min\": 0.9201941933323767,\n      \"avg\": 0.9201941933323767,\n      \"last\": 0.9201941933323767,\n      \"last-5-avg\": 0.9201941933323767,\n      \"last-10-avg\": 0.9201941933323767\n    },\n    \"precision\": {\n      \"max\": 0.9223477140807763,\n      \"min\": 0.9223477140807763,\n      \"avg\": 0.9223477140807763,\n      \"last\": 0.9223477140807763,\n      \"last-5-avg\": 0.9223477140807763,\n      \"last-10-avg\": 0.9223477140807763\n    },\n    \"recall\": {\n      \"max\": 0.9201941933323767,\n      \"min\": 0.9201941933323767,\n      \"avg\": 0.9201941933323767,\n      \"last\": 0.9201941933323767,\n      \"last-5-avg\": 0.9201941933323767,\n      \"last-10-avg\": 0.9201941933323767\n    },\n    \"f1_score\": {\n      \"max\": 0.920173038360211,\n      \"min\": 0.920173038360211,\n      \"avg\": 0.920173038360211,\n      \"last\": 0.920173038360211,\n      \"last-5-avg\": 0.920173038360211,\n      \"last-10-avg\": 0.920173038360211\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 817.7616677284241,\n      \"min\": 817.7616677284241,\n      \"avg\": 817.7616677284241,\n      \"last\": 817.7616677284241,\n      \"last-5-avg\": 817.7616677284241,\n      \"last-10-avg\": 817.7616677284241\n    },\n    \"time_total_s\": {\n      \"max\": 817.7616677284241,\n      \"min\": 817.7616677284241,\n      \"avg\": 817.7616677284241,\n      \"last\": 817.7616677284241,\n      \"last-5-avg\": 817.7616677284241,\n      \"last-10-avg\": 817.7616677284241\n    },\n    \"time_since_restore\": {\n      \"max\": 817.7616677284241,\n      \"min\": 817.7616677284241,\n      \"avg\": 817.7616677284241,\n      \"last\": 817.7616677284241,\n      \"last-5-avg\": 817.7616677284241,\n      \"last-10-avg\": 817.7616677284241\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fed723b17ca9cf4612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fed723b17ca9cf4612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308aa8d705adf83ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308aa8d705adf83ed3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f49cca173b72ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f49cca173b72ed3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308bf604dba0e72ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308bf604dba0e72ed3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740898e17e5400000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740898e17e5400000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740898e17e5400000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740898e17e5400000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740898e17e5400000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740898e17e5400000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00043\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303433948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 50,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 50,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 50,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"43_activation=relu,batch_size=32,dropout_rate=0.1000,hidden_sizes=512,lr=0.0001,num_epochs=50,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00043\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00043\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724688582.749114,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.9125173386903908,\n    \"precision\": 0.9132933819638612,\n    \"recall\": 0.9125173386903908,\n    \"f1_score\": 0.9124688302104329,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d6275666665729493942843801d0a0000000000001700000000000000d10100000000000034000000000000001100000000000000e50a00000000000014010000000000002c00000000000000e20100000000000092010000000000002c4b000000000000f7040000000000002a000000000000002b000000000000001d02000000000000de34000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.83      0.83      0.83      3129\\n     hyponym       0.86      0.89      0.87      3126\\n        none       0.94      0.90      0.92     21399\\n    synonymy       0.91      0.96      0.93     14160\\n\\n    accuracy                           0.91     41814\\n   macro avg       0.88      0.89      0.89     41814\\nweighted avg       0.91      0.91      0.91     41814\\n\",\n    \"timestamp\": 1724688974,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00043\",\n    \"date\": \"2024-08-26_19-16-14\",\n    \"time_this_iter_s\": 391.7135434150696,\n    \"time_total_s\": 391.7135434150696,\n    \"pid\": 23036,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 50,\n      \"batch_size\": 32,\n      \"hidden_sizes\": [\n        512\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.1,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 391.7135434150696,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"43_activation=relu,batch_size=32,dropout_rate=0.1000,hidden_sizes=512,lr=0.0001,num_epochs=50,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724688974.4676585,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.9125173386903908,\n      \"min\": 0.9125173386903908,\n      \"avg\": 0.9125173386903908,\n      \"last\": 0.9125173386903908,\n      \"last-5-avg\": 0.9125173386903908,\n      \"last-10-avg\": 0.9125173386903908\n    },\n    \"precision\": {\n      \"max\": 0.9132933819638612,\n      \"min\": 0.9132933819638612,\n      \"avg\": 0.9132933819638612,\n      \"last\": 0.9132933819638612,\n      \"last-5-avg\": 0.9132933819638612,\n      \"last-10-avg\": 0.9132933819638612\n    },\n    \"recall\": {\n      \"max\": 0.9125173386903908,\n      \"min\": 0.9125173386903908,\n      \"avg\": 0.9125173386903908,\n      \"last\": 0.9125173386903908,\n      \"last-5-avg\": 0.9125173386903908,\n      \"last-10-avg\": 0.9125173386903908\n    },\n    \"f1_score\": {\n      \"max\": 0.9124688302104329,\n      \"min\": 0.9124688302104329,\n      \"avg\": 0.9124688302104329,\n      \"last\": 0.9124688302104329,\n      \"last-5-avg\": 0.9124688302104329,\n      \"last-10-avg\": 0.9124688302104329\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 391.7135434150696,\n      \"min\": 391.7135434150696,\n      \"avg\": 391.7135434150696,\n      \"last\": 391.7135434150696,\n      \"last-5-avg\": 391.7135434150696,\n      \"last-10-avg\": 391.7135434150696\n    },\n    \"time_total_s\": {\n      \"max\": 391.7135434150696,\n      \"min\": 391.7135434150696,\n      \"avg\": 391.7135434150696,\n      \"last\": 391.7135434150696,\n      \"last-5-avg\": 391.7135434150696,\n      \"last-10-avg\": 391.7135434150696\n    },\n    \"time_since_restore\": {\n      \"max\": 391.7135434150696,\n      \"min\": 391.7135434150696,\n      \"avg\": 391.7135434150696,\n      \"last\": 391.7135434150696,\n      \"last-5-avg\": 391.7135434150696,\n      \"last-10-avg\": 391.7135434150696\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fed33578fd6a971612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fed33578fd6a971612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084304e60ab339ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084304e60ab339ed3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430871a9d68f5733ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430871a9d68f5733ed3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430824f10bd5f132ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430824f10bd5f132ed3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740787b6aac800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740787b6aac800000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740787b6aac800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740787b6aac800000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740787b6aac800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740787b6aac800000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00072\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303732948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 69,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 69,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 69,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"72_activation=relu,batch_size=128,dropout_rate=0.0000,hidden_sizes=128_64,lr=0.0000,num_epochs=69,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00072\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00072\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00074\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303734948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 55,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 55,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 55,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"74_activation=relu,batch_size=128,dropout_rate=0.1000,hidden_sizes=128_64,lr=0.0000,num_epochs=55,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00074\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00074\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00030\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303330948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 10,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 10,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 10,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"30_activation=relu,batch_size=512,dropout_rate=0.1000,hidden_sizes=128_64,lr=0.0001,num_epochs=10,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00030\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00030\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724685412.8963358,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8548454623814801,\n    \"precision\": 0.8549243869751608,\n    \"recall\": 0.8548454623814801,\n    \"f1_score\": 0.8512970608077765,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380c0060000000000000e000000000000007d04000000000000ae000000000000001000000000000000f7070000000000005003000000000000d4000000000000005a01000000000000d600000000000000d24800000000000028040000000000005c0000000000000067000000000000007e060000000000000e30000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.79      0.56      0.66      3065\\n     hyponym       0.86      0.65      0.74      3115\\n        none       0.84      0.92      0.88     20266\\n    synonymy       0.89      0.87      0.88     14159\\n\\n    accuracy                           0.85     40605\\n   macro avg       0.85      0.75      0.79     40605\\nweighted avg       0.85      0.85      0.85     40605\\n\",\n    \"timestamp\": 1724685487,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00030\",\n    \"date\": \"2024-08-26_18-18-07\",\n    \"time_this_iter_s\": 74.29801440238953,\n    \"time_total_s\": 74.29801440238953,\n    \"pid\": 19244,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 10,\n      \"batch_size\": 512,\n      \"hidden_sizes\": [\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.1,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 74.29801440238953,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"30_activation=relu,batch_size=512,dropout_rate=0.1000,hidden_sizes=128_64,lr=0.0001,num_epochs=10,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724685487.198354,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8548454623814801,\n      \"min\": 0.8548454623814801,\n      \"avg\": 0.8548454623814801,\n      \"last\": 0.8548454623814801,\n      \"last-5-avg\": 0.8548454623814801,\n      \"last-10-avg\": 0.8548454623814801\n    },\n    \"precision\": {\n      \"max\": 0.8549243869751608,\n      \"min\": 0.8549243869751608,\n      \"avg\": 0.8549243869751608,\n      \"last\": 0.8549243869751608,\n      \"last-5-avg\": 0.8549243869751608,\n      \"last-10-avg\": 0.8549243869751608\n    },\n    \"recall\": {\n      \"max\": 0.8548454623814801,\n      \"min\": 0.8548454623814801,\n      \"avg\": 0.8548454623814801,\n      \"last\": 0.8548454623814801,\n      \"last-5-avg\": 0.8548454623814801,\n      \"last-10-avg\": 0.8548454623814801\n    },\n    \"f1_score\": {\n      \"max\": 0.8512970608077765,\n      \"min\": 0.8512970608077765,\n      \"avg\": 0.8512970608077765,\n      \"last\": 0.8512970608077765,\n      \"last-5-avg\": 0.8512970608077765,\n      \"last-10-avg\": 0.8512970608077765\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 74.29801440238953,\n      \"min\": 74.29801440238953,\n      \"avg\": 74.29801440238953,\n      \"last\": 74.29801440238953,\n      \"last-5-avg\": 74.29801440238953,\n      \"last-10-avg\": 74.29801440238953\n    },\n    \"time_total_s\": {\n      \"max\": 74.29801440238953,\n      \"min\": 74.29801440238953,\n      \"avg\": 74.29801440238953,\n      \"last\": 74.29801440238953,\n      \"last-5-avg\": 74.29801440238953,\n      \"last-10-avg\": 74.29801440238953\n    },\n    \"time_since_restore\": {\n      \"max\": 74.29801440238953,\n      \"min\": 74.29801440238953,\n      \"avg\": 74.29801440238953,\n      \"last\": 74.29801440238953,\n      \"last-5-avg\": 74.29801440238953,\n      \"last-10-avg\": 74.29801440238953\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473feb5ae4df01ffa2612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473feb5ae4df01ffa2612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a88e53638a5beb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a88e53638a5beb3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a2ff01dfe45aeb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a2ff01dfe45aeb3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d9356b55d33deb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d9356b55d33deb3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740529312ab000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740529312ab000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740529312ab000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740529312ab000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740529312ab000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740529312ab000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00059\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303539948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 47,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 47,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 47,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"59_activation=relu,batch_size=128,dropout_rate=0.0000,hidden_sizes=512,lr=0.0001,num_epochs=47,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00059\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00059\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724692299.6173956,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.9044452653614087,\n    \"precision\": 0.9040858614462012,\n    \"recall\": 0.9044452653614087,\n    \"f1_score\": 0.9036616397501761,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380ef080000000000001300000000000000900200000000000067000000000000000900000000000000340a0000000000009f010000000000004f000000000000002f01000000000000fd000000000000003f48000000000000bf040000000000000b0000000000000013000000000000001e030000000000001334000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.88      0.75      0.81      3065\\n     hyponym       0.90      0.84      0.87      3115\\n        none       0.91      0.91      0.91     20266\\n    synonymy       0.91      0.94      0.92     14159\\n\\n    accuracy                           0.90     40605\\n   macro avg       0.90      0.86      0.88     40605\\nweighted avg       0.90      0.90      0.90     40605\\n\",\n    \"timestamp\": 1724692436,\n    \"checkpoint_dir_name\": null,\n    \"done\": false,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00059\",\n    \"date\": \"2024-08-26_20-13-56\",\n    \"time_this_iter_s\": 136.42914628982544,\n    \"time_total_s\": 136.42914628982544,\n    \"pid\": 26896,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 47,\n      \"batch_size\": 128,\n      \"hidden_sizes\": [\n        512\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.0,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 136.42914628982544,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"59_activation=relu,batch_size=128,dropout_rate=0.0000,hidden_sizes=512,lr=0.0001,num_epochs=47,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724692436.0520322,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.9044452653614087,\n      \"min\": 0.9044452653614087,\n      \"avg\": 0.9044452653614087,\n      \"last\": 0.9044452653614087,\n      \"last-5-avg\": 0.9044452653614087,\n      \"last-10-avg\": 0.9044452653614087\n    },\n    \"precision\": {\n      \"max\": 0.9040858614462012,\n      \"min\": 0.9040858614462012,\n      \"avg\": 0.9040858614462012,\n      \"last\": 0.9040858614462012,\n      \"last-5-avg\": 0.9040858614462012,\n      \"last-10-avg\": 0.9040858614462012\n    },\n    \"recall\": {\n      \"max\": 0.9044452653614087,\n      \"min\": 0.9044452653614087,\n      \"avg\": 0.9044452653614087,\n      \"last\": 0.9044452653614087,\n      \"last-5-avg\": 0.9044452653614087,\n      \"last-10-avg\": 0.9044452653614087\n    },\n    \"f1_score\": {\n      \"max\": 0.9036616397501761,\n      \"min\": 0.9036616397501761,\n      \"avg\": 0.9036616397501761,\n      \"last\": 0.9036616397501761,\n      \"last-5-avg\": 0.9036616397501761,\n      \"last-10-avg\": 0.9036616397501761\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 136.42914628982544,\n      \"min\": 136.42914628982544,\n      \"avg\": 136.42914628982544,\n      \"last\": 136.42914628982544,\n      \"last-5-avg\": 136.42914628982544,\n      \"last-10-avg\": 136.42914628982544\n    },\n    \"time_total_s\": {\n      \"max\": 136.42914628982544,\n      \"min\": 136.42914628982544,\n      \"avg\": 136.42914628982544,\n      \"last\": 136.42914628982544,\n      \"last-5-avg\": 136.42914628982544,\n      \"last-10-avg\": 136.42914628982544\n    },\n    \"time_since_restore\": {\n      \"max\": 136.42914628982544,\n      \"min\": 136.42914628982544,\n      \"avg\": 136.42914628982544,\n      \"last\": 136.42914628982544,\n      \"last-5-avg\": 136.42914628982544,\n      \"last-10-avg\": 136.42914628982544\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fecf1373277fa33612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fecf1373277fa33612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085bfff57845eeec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085bfff57845eeec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430833fa773237f1ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430833fa773237f1ec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308410eacd0cbeaec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308410eacd0cbeaec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740610dbb91000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740610dbb91000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740610dbb91000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740610dbb91000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740610dbb91000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740610dbb91000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00044\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303434948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 12,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 12,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 12,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"44_activation=relu,batch_size=512,dropout_rate=0.1000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=12,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00044\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00044\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724688982.7659764,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.9033616549685999,\n    \"precision\": 0.9047308312974351,\n    \"recall\": 0.9033616549685999,\n    \"f1_score\": 0.9029878882319398,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380b5090000000000001100000000000000aa0100000000000089000000000000000a00000000000000140a00000000000080010000000000008d00000000000000ec010000000000000d0100000000000026460000000000000b0600000000000020000000000000002b00000000000000aa010000000000005a35000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.82      0.81      0.82      3065\\n     hyponym       0.89      0.83      0.86      3115\\n        none       0.94      0.89      0.91     20266\\n    synonymy       0.88      0.96      0.92     14159\\n\\n    accuracy                           0.90     40605\\n   macro avg       0.88      0.87      0.88     40605\\nweighted avg       0.90      0.90      0.90     40605\\n\",\n    \"timestamp\": 1724689061,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00044\",\n    \"date\": \"2024-08-26_19-17-41\",\n    \"time_this_iter_s\": 78.59617829322815,\n    \"time_total_s\": 78.59617829322815,\n    \"pid\": 31000,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 12,\n      \"batch_size\": 512,\n      \"hidden_sizes\": [\n        1024,\n        512,\n        256,\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.1,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 78.59617829322815,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"44_activation=relu,batch_size=512,dropout_rate=0.1000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=12,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724689061.3671582,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.9033616549685999,\n      \"min\": 0.9033616549685999,\n      \"avg\": 0.9033616549685999,\n      \"last\": 0.9033616549685999,\n      \"last-5-avg\": 0.9033616549685999,\n      \"last-10-avg\": 0.9033616549685999\n    },\n    \"precision\": {\n      \"max\": 0.9047308312974351,\n      \"min\": 0.9047308312974351,\n      \"avg\": 0.9047308312974351,\n      \"last\": 0.9047308312974351,\n      \"last-5-avg\": 0.9047308312974351,\n      \"last-10-avg\": 0.9047308312974351\n    },\n    \"recall\": {\n      \"max\": 0.9033616549685999,\n      \"min\": 0.9033616549685999,\n      \"avg\": 0.9033616549685999,\n      \"last\": 0.9033616549685999,\n      \"last-5-avg\": 0.9033616549685999,\n      \"last-10-avg\": 0.9033616549685999\n    },\n    \"f1_score\": {\n      \"max\": 0.9029878882319398,\n      \"min\": 0.9029878882319398,\n      \"avg\": 0.9029878882319398,\n      \"last\": 0.9029878882319398,\n      \"last-5-avg\": 0.9029878882319398,\n      \"last-10-avg\": 0.9029878882319398\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 78.59617829322815,\n      \"min\": 78.59617829322815,\n      \"avg\": 78.59617829322815,\n      \"last\": 78.59617829322815,\n      \"last-5-avg\": 78.59617829322815,\n      \"last-10-avg\": 78.59617829322815\n    },\n    \"time_total_s\": {\n      \"max\": 78.59617829322815,\n      \"min\": 78.59617829322815,\n      \"avg\": 78.59617829322815,\n      \"last\": 78.59617829322815,\n      \"last-5-avg\": 78.59617829322815,\n      \"last-10-avg\": 78.59617829322815\n    },\n    \"time_since_restore\": {\n      \"max\": 78.59617829322815,\n      \"min\": 78.59617829322815,\n      \"avg\": 78.59617829322815,\n      \"last\": 78.59617829322815,\n      \"last-5-avg\": 78.59617829322815,\n      \"last-10-avg\": 78.59617829322815\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fece856b3919e4a612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fece856b3919e4a612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308405f83128ef3ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308405f83128ef3ec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084a9e91b356e8ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084a9e91b356e8ec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308367d14db46e5ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308367d14db46e5ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474053a627c9000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474053a627c9000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474053a627c9000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474053a627c9000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474053a627c9000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474053a627c9000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00086\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303836948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 56,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 56,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 56,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"86_activation=relu,batch_size=128,dropout_rate=0.1000,hidden_sizes=128_64,lr=0.0000,num_epochs=56,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00086\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00086\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00063\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303633948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 63,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 63,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 63,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"63_activation=relu,batch_size=512,dropout_rate=0.2000,hidden_sizes=128_64,lr=0.0000,num_epochs=63,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00063\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00063\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724692834.5954454,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8460041866765177,\n    \"precision\": 0.8430253554934553,\n    \"recall\": 0.8460041866765177,\n    \"f1_score\": 0.840977673219656,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d62756666657294939428438002060000000000001b00000000000000df04000000000000fd000000000000001700000000000000810700000000000067030000000000002c010000000000007e01000000000000ff000000000000002e470000000000007f0500000000000060000000000000008c00000000000000e4040000000000007f31000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.75      0.50      0.60      3065\\n     hyponym       0.82      0.62      0.70      3115\\n        none       0.84      0.90      0.87     20266\\n    synonymy       0.87      0.89      0.88     14159\\n\\n    accuracy                           0.85     40605\\n   macro avg       0.82      0.73      0.76     40605\\nweighted avg       0.84      0.85      0.84     40605\\n\",\n    \"timestamp\": 1724692935,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00063\",\n    \"date\": \"2024-08-26_20-22-15\",\n    \"time_this_iter_s\": 100.5828697681427,\n    \"time_total_s\": 100.5828697681427,\n    \"pid\": 27932,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 63,\n      \"batch_size\": 512,\n      \"hidden_sizes\": [\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 100.5828697681427,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"63_activation=relu,batch_size=512,dropout_rate=0.2000,hidden_sizes=128_64,lr=0.0000,num_epochs=63,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724692935.183315,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8460041866765177,\n      \"min\": 0.8460041866765177,\n      \"avg\": 0.8460041866765177,\n      \"last\": 0.8460041866765177,\n      \"last-5-avg\": 0.8460041866765177,\n      \"last-10-avg\": 0.8460041866765177\n    },\n    \"precision\": {\n      \"max\": 0.8430253554934553,\n      \"min\": 0.8430253554934553,\n      \"avg\": 0.8430253554934553,\n      \"last\": 0.8430253554934553,\n      \"last-5-avg\": 0.8430253554934553,\n      \"last-10-avg\": 0.8430253554934553\n    },\n    \"recall\": {\n      \"max\": 0.8460041866765177,\n      \"min\": 0.8460041866765177,\n      \"avg\": 0.8460041866765177,\n      \"last\": 0.8460041866765177,\n      \"last-5-avg\": 0.8460041866765177,\n      \"last-10-avg\": 0.8460041866765177\n    },\n    \"f1_score\": {\n      \"max\": 0.840977673219656,\n      \"min\": 0.840977673219656,\n      \"avg\": 0.840977673219656,\n      \"last\": 0.840977673219656,\n      \"last-5-avg\": 0.840977673219656,\n      \"last-10-avg\": 0.840977673219656\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 100.5828697681427,\n      \"min\": 100.5828697681427,\n      \"avg\": 100.5828697681427,\n      \"last\": 100.5828697681427,\n      \"last-5-avg\": 100.5828697681427,\n      \"last-10-avg\": 100.5828697681427\n    },\n    \"time_total_s\": {\n      \"max\": 100.5828697681427,\n      \"min\": 100.5828697681427,\n      \"avg\": 100.5828697681427,\n      \"last\": 100.5828697681427,\n      \"last-5-avg\": 100.5828697681427,\n      \"last-10-avg\": 100.5828697681427\n    },\n    \"time_since_restore\": {\n      \"max\": 100.5828697681427,\n      \"min\": 100.5828697681427,\n      \"avg\": 100.5828697681427,\n      \"last\": 100.5828697681427,\n      \"last-5-avg\": 100.5828697681427,\n      \"last-10-avg\": 100.5828697681427\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473feb12775f41c049612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473feb12775f41c049612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a61714f10faea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a61714f10faea3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430849c0415f7712eb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430849c0415f7712eb3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088ba064024ae9ea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088ba064024ae9ea3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474059254dbd000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474059254dbd000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474059254dbd000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474059254dbd000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474059254dbd000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474059254dbd000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00041\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303431948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 21,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 21,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 21,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"41_activation=relu,batch_size=512,dropout_rate=0.0000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=21,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00041\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00041\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724687462.4518988,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.9025982021918483,\n    \"precision\": 0.902501014709705,\n    \"recall\": 0.9025982021918483,\n    \"f1_score\": 0.9018183014668675,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d62756666657294939428438006090000000000001100000000000000c20200000000000020000000000000001000000000000000d0090000000000001c020000000000002f000000000000001a01000000000000bd00000000000000f5480000000000005e040000000000001b000000000000001900000000000000bc030000000000005f33000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.88      0.75      0.81      3065\\n     hyponym       0.92      0.81      0.86      3115\\n        none       0.89      0.92      0.91     20266\\n    synonymy       0.92      0.93      0.92     14159\\n\\n    accuracy                           0.90     40605\\n   macro avg       0.90      0.85      0.87     40605\\nweighted avg       0.90      0.90      0.90     40605\\n\",\n    \"timestamp\": 1724687547,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00041\",\n    \"date\": \"2024-08-26_18-52-27\",\n    \"time_this_iter_s\": 84.6484706401825,\n    \"time_total_s\": 84.6484706401825,\n    \"pid\": 33260,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 21,\n      \"batch_size\": 512,\n      \"hidden_sizes\": [\n        1024,\n        512,\n        256,\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.0,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 84.6484706401825,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"41_activation=relu,batch_size=512,dropout_rate=0.0000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=21,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724687547.10537,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.9025982021918483,\n      \"min\": 0.9025982021918483,\n      \"avg\": 0.9025982021918483,\n      \"last\": 0.9025982021918483,\n      \"last-5-avg\": 0.9025982021918483,\n      \"last-10-avg\": 0.9025982021918483\n    },\n    \"precision\": {\n      \"max\": 0.902501014709705,\n      \"min\": 0.902501014709705,\n      \"avg\": 0.902501014709705,\n      \"last\": 0.902501014709705,\n      \"last-5-avg\": 0.902501014709705,\n      \"last-10-avg\": 0.902501014709705\n    },\n    \"recall\": {\n      \"max\": 0.9025982021918483,\n      \"min\": 0.9025982021918483,\n      \"avg\": 0.9025982021918483,\n      \"last\": 0.9025982021918483,\n      \"last-5-avg\": 0.9025982021918483,\n      \"last-10-avg\": 0.9025982021918483\n    },\n    \"f1_score\": {\n      \"max\": 0.9018183014668675,\n      \"min\": 0.9018183014668675,\n      \"avg\": 0.9018183014668675,\n      \"last\": 0.9018183014668675,\n      \"last-5-avg\": 0.9018183014668675,\n      \"last-10-avg\": 0.9018183014668675\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 84.6484706401825,\n      \"min\": 84.6484706401825,\n      \"avg\": 84.6484706401825,\n      \"last\": 84.6484706401825,\n      \"last-5-avg\": 84.6484706401825,\n      \"last-10-avg\": 84.6484706401825\n    },\n    \"time_total_s\": {\n      \"max\": 84.6484706401825,\n      \"min\": 84.6484706401825,\n      \"avg\": 84.6484706401825,\n      \"last\": 84.6484706401825,\n      \"last-5-avg\": 84.6484706401825,\n      \"last-10-avg\": 84.6484706401825\n    },\n    \"time_since_restore\": {\n      \"max\": 84.6484706401825,\n      \"min\": 84.6484706401825,\n      \"avg\": 84.6484706401825,\n      \"last\": 84.6484706401825,\n      \"last-5-avg\": 84.6484706401825,\n      \"last-10-avg\": 84.6484706401825\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fece2159ffaf4cf612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fece2159ffaf4cf612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b41ed9ce49e1ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b41ed9ce49e1ec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cff4fa9f15e2ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cff4fa9f15e2ec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308bc80f70db2dbec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308bc80f70db2dbec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405529808b000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405529808b000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405529808b000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405529808b000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405529808b000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405529808b000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00076\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303736948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 34,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 34,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 34,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"76_activation=relu,batch_size=512,dropout_rate=0.2000,hidden_sizes=1024_512_256_128_64,lr=0.0000,num_epochs=34,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00076\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00076\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00047\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303437948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 14,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 14,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 14,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"47_activation=relu,batch_size=512,dropout_rate=0.2000,hidden_sizes=128_64,lr=0.0000,num_epochs=14,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00047\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00047\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724689542.1916196,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.7302056396995444,\n    \"precision\": 0.7177577692214233,\n    \"recall\": 0.7302056396995444,\n    \"f1_score\": 0.694616158440415,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380f9000000000000002c00000000000000f707000000000000dd02000000000000120000000000000028020000000000004806000000000000a90300000000000064000000000000006d00000000000000cc450000000000008d0800000000000035000000000000007900000000000000bc0b000000000000e52a000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.59      0.08      0.14      3065\\n     hyponym       0.67      0.18      0.28      3115\\n        none       0.73      0.88      0.80     20266\\n    synonymy       0.74      0.78      0.76     14159\\n\\n    accuracy                           0.73     40605\\n   macro avg       0.68      0.48      0.49     40605\\nweighted avg       0.72      0.73      0.69     40605\\n\",\n    \"timestamp\": 1724689617,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00047\",\n    \"date\": \"2024-08-26_19-26-57\",\n    \"time_this_iter_s\": 75.20808053016663,\n    \"time_total_s\": 75.20808053016663,\n    \"pid\": 26160,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 14,\n      \"batch_size\": 512,\n      \"hidden_sizes\": [\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 75.20808053016663,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"47_activation=relu,batch_size=512,dropout_rate=0.2000,hidden_sizes=128_64,lr=0.0000,num_epochs=14,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724689617.4037013,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.7302056396995444,\n      \"min\": 0.7302056396995444,\n      \"avg\": 0.7302056396995444,\n      \"last\": 0.7302056396995444,\n      \"last-5-avg\": 0.7302056396995444,\n      \"last-10-avg\": 0.7302056396995444\n    },\n    \"precision\": {\n      \"max\": 0.7177577692214233,\n      \"min\": 0.7177577692214233,\n      \"avg\": 0.7177577692214233,\n      \"last\": 0.7177577692214233,\n      \"last-5-avg\": 0.7177577692214233,\n      \"last-10-avg\": 0.7177577692214233\n    },\n    \"recall\": {\n      \"max\": 0.7302056396995444,\n      \"min\": 0.7302056396995444,\n      \"avg\": 0.7302056396995444,\n      \"last\": 0.7302056396995444,\n      \"last-5-avg\": 0.7302056396995444,\n      \"last-10-avg\": 0.7302056396995444\n    },\n    \"f1_score\": {\n      \"max\": 0.694616158440415,\n      \"min\": 0.694616158440415,\n      \"avg\": 0.694616158440415,\n      \"last\": 0.694616158440415,\n      \"last-5-avg\": 0.694616158440415,\n      \"last-10-avg\": 0.694616158440415\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 75.20808053016663,\n      \"min\": 75.20808053016663,\n      \"avg\": 75.20808053016663,\n      \"last\": 75.20808053016663,\n      \"last-5-avg\": 75.20808053016663,\n      \"last-10-avg\": 75.20808053016663\n    },\n    \"time_total_s\": {\n      \"max\": 75.20808053016663,\n      \"min\": 75.20808053016663,\n      \"avg\": 75.20808053016663,\n      \"last\": 75.20808053016663,\n      \"last-5-avg\": 75.20808053016663,\n      \"last-10-avg\": 75.20808053016663\n    },\n    \"time_since_restore\": {\n      \"max\": 75.20808053016663,\n      \"min\": 75.20808053016663,\n      \"avg\": 75.20808053016663,\n      \"last\": 75.20808053016663,\n      \"last-5-avg\": 75.20808053016663,\n      \"last-10-avg\": 75.20808053016663\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fe75dd837bba85e612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fe75dd837bba85e612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430891302824dff7e63f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430891302824dff7e63f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085ea8bb37d85de73f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085ea8bb37d85de73f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a5ca78aa4b3ae63f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a5ca78aa4b3ae63f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474052cd5131000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474052cd5131000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474052cd5131000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474052cd5131000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474052cd5131000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474052cd5131000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00071\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303731948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 52,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 52,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 52,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"71_activation=relu,batch_size=128,dropout_rate=0.0000,hidden_sizes=128_64,lr=0.0000,num_epochs=52,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00071\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00071\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00085\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303835948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 22,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 22,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 22,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"85_activation=relu,batch_size=512,dropout_rate=0.2000,hidden_sizes=512,lr=0.0000,num_epochs=22,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00085\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00085\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00032\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303332948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 57,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 57,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 57,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"32_activation=relu,batch_size=128,dropout_rate=0.1000,hidden_sizes=512,lr=0.0000,num_epochs=57,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00032\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00032\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724685691.3963366,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8991010959241472,\n    \"precision\": 0.8988278077640431,\n    \"recall\": 0.8991010959241472,\n    \"f1_score\": 0.8976952351781934,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d62756666657294939428438066080000000000001000000000000000fe02000000000000850000000000000010000000000000009709000000000000030200000000000081000000000000000301000000000000d3000000000000006c48000000000000e8040000000000001a000000000000001f00000000000000e3020000000000003334000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.88      0.70      0.78      3065\\n     hyponym       0.90      0.79      0.84      3115\\n        none       0.90      0.91      0.91     20266\\n    synonymy       0.90      0.94      0.92     14159\\n\\n    accuracy                           0.90     40605\\n   macro avg       0.90      0.84      0.86     40605\\nweighted avg       0.90      0.90      0.90     40605\\n\",\n    \"timestamp\": 1724685852,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00032\",\n    \"date\": \"2024-08-26_18-24-12\",\n    \"time_this_iter_s\": 161.2594404220581,\n    \"time_total_s\": 161.2594404220581,\n    \"pid\": 23232,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 57,\n      \"batch_size\": 128,\n      \"hidden_sizes\": [\n        512\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.1,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 161.2594404220581,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"32_activation=relu,batch_size=128,dropout_rate=0.1000,hidden_sizes=512,lr=0.0000,num_epochs=57,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724685852.6607833,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8991010959241472,\n      \"min\": 0.8991010959241472,\n      \"avg\": 0.8991010959241472,\n      \"last\": 0.8991010959241472,\n      \"last-5-avg\": 0.8991010959241472,\n      \"last-10-avg\": 0.8991010959241472\n    },\n    \"precision\": {\n      \"max\": 0.8988278077640431,\n      \"min\": 0.8988278077640431,\n      \"avg\": 0.8988278077640431,\n      \"last\": 0.8988278077640431,\n      \"last-5-avg\": 0.8988278077640431,\n      \"last-10-avg\": 0.8988278077640431\n    },\n    \"recall\": {\n      \"max\": 0.8991010959241472,\n      \"min\": 0.8991010959241472,\n      \"avg\": 0.8991010959241472,\n      \"last\": 0.8991010959241472,\n      \"last-5-avg\": 0.8991010959241472,\n      \"last-10-avg\": 0.8991010959241472\n    },\n    \"f1_score\": {\n      \"max\": 0.8976952351781934,\n      \"min\": 0.8976952351781934,\n      \"avg\": 0.8976952351781934,\n      \"last\": 0.8976952351781934,\n      \"last-5-avg\": 0.8976952351781934,\n      \"last-10-avg\": 0.8976952351781934\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 161.2594404220581,\n      \"min\": 161.2594404220581,\n      \"avg\": 161.2594404220581,\n      \"last\": 161.2594404220581,\n      \"last-5-avg\": 161.2594404220581,\n      \"last-10-avg\": 161.2594404220581\n    },\n    \"time_total_s\": {\n      \"max\": 161.2594404220581,\n      \"min\": 161.2594404220581,\n      \"avg\": 161.2594404220581,\n      \"last\": 161.2594404220581,\n      \"last-5-avg\": 161.2594404220581,\n      \"last-10-avg\": 161.2594404220581\n    },\n    \"time_since_restore\": {\n      \"max\": 161.2594404220581,\n      \"min\": 161.2594404220581,\n      \"avg\": 161.2594404220581,\n      \"last\": 161.2594404220581,\n      \"last-5-avg\": 161.2594404220581,\n      \"last-10-avg\": 161.2594404220581\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fecc56fa95957d4612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fecc56fa95957d4612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308419fe28832c3ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308419fe28832c3ec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d45759a96fc5ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d45759a96fc5ec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081bb19b5bebb9ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081bb19b5bebb9ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474064284d56000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474064284d56000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474064284d56000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474064284d56000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474064284d56000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474064284d56000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00094\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303934948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 32,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 32,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 32,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"94_activation=relu,batch_size=512,dropout_rate=0.2000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=32,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00094\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00094\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00020\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303230948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 17,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 17,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 17,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"20_activation=relu,batch_size=128,dropout_rate=0.1000,hidden_sizes=512,lr=0.0001,num_epochs=17,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00020\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00020\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724683684.562236,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.9014444922753145,\n    \"precision\": 0.9015772561270122,\n    \"recall\": 0.9014444922753145,\n    \"f1_score\": 0.9005357560759283,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d62756666657294939428438011090000000000000e00000000000000e90200000000000031000000000000001100000000000000a909000000000000370200000000000045000000000000002601000000000000b300000000000000e84d000000000000d6030000000000002a00000000000000180000000000000073040000000000009b32000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.87      0.74      0.80      3129\\n     hyponym       0.92      0.79      0.85      3126\\n        none       0.89      0.93      0.91     21399\\n    synonymy       0.92      0.91      0.92     14160\\n\\n    accuracy                           0.90     41814\\n   macro avg       0.90      0.84      0.87     41814\\nweighted avg       0.90      0.90      0.90     41814\\n\",\n    \"timestamp\": 1724683776,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00020\",\n    \"date\": \"2024-08-26_17-49-36\",\n    \"time_this_iter_s\": 91.7644567489624,\n    \"time_total_s\": 91.7644567489624,\n    \"pid\": 1760,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 17,\n      \"batch_size\": 128,\n      \"hidden_sizes\": [\n        512\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.1,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 91.7644567489624,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"20_activation=relu,batch_size=128,dropout_rate=0.1000,hidden_sizes=512,lr=0.0001,num_epochs=17,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724683776.332694,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.9014444922753145,\n      \"min\": 0.9014444922753145,\n      \"avg\": 0.9014444922753145,\n      \"last\": 0.9014444922753145,\n      \"last-5-avg\": 0.9014444922753145,\n      \"last-10-avg\": 0.9014444922753145\n    },\n    \"precision\": {\n      \"max\": 0.9015772561270122,\n      \"min\": 0.9015772561270122,\n      \"avg\": 0.9015772561270122,\n      \"last\": 0.9015772561270122,\n      \"last-5-avg\": 0.9015772561270122,\n      \"last-10-avg\": 0.9015772561270122\n    },\n    \"recall\": {\n      \"max\": 0.9014444922753145,\n      \"min\": 0.9014444922753145,\n      \"avg\": 0.9014444922753145,\n      \"last\": 0.9014444922753145,\n      \"last-5-avg\": 0.9014444922753145,\n      \"last-10-avg\": 0.9014444922753145\n    },\n    \"f1_score\": {\n      \"max\": 0.9005357560759283,\n      \"min\": 0.9005357560759283,\n      \"avg\": 0.9005357560759283,\n      \"last\": 0.9005357560759283,\n      \"last-5-avg\": 0.9005357560759283,\n      \"last-10-avg\": 0.9005357560759283\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 91.7644567489624,\n      \"min\": 91.7644567489624,\n      \"avg\": 91.7644567489624,\n      \"last\": 91.7644567489624,\n      \"last-5-avg\": 91.7644567489624,\n      \"last-10-avg\": 91.7644567489624\n    },\n    \"time_total_s\": {\n      \"max\": 91.7644567489624,\n      \"min\": 91.7644567489624,\n      \"avg\": 91.7644567489624,\n      \"last\": 91.7644567489624,\n      \"last-5-avg\": 91.7644567489624,\n      \"last-10-avg\": 91.7644567489624\n    },\n    \"time_since_restore\": {\n      \"max\": 91.7644567489624,\n      \"min\": 91.7644567489624,\n      \"avg\": 91.7644567489624,\n      \"last\": 91.7644567489624,\n      \"last-5-avg\": 91.7644567489624,\n      \"last-10-avg\": 91.7644567489624\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fecd8a21eaf6ae9612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fecd8a21eaf6ae9612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fd40bc8bb8d9ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fd40bc8bb8d9ec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e96aaf1ea2d8ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e96aaf1ea2d8ec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081d31a75c30d1ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081d31a75c30d1ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474056f0ecdc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474056f0ecdc000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474056f0ecdc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474056f0ecdc000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474056f0ecdc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474056f0ecdc000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00028\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303238948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 23,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 23,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 23,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"28_activation=relu,batch_size=512,dropout_rate=0.0000,hidden_sizes=512,lr=0.0000,num_epochs=23,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00028\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00028\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724685224.2450078,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8252499162959774,\n    \"precision\": 0.8221397221279025,\n    \"recall\": 0.8252499162959774,\n    \"f1_score\": 0.8153772117651591,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380430400000000000036000000000000004b0600000000000075010000000000000e00000000000000ed06000000000000a9030000000000009201000000000000f9000000000000002601000000000000414c00000000000037050000000000004000000000000000c500000000000000f1060000000000005a2f000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.77      0.35      0.48      3129\\n     hyponym       0.76      0.57      0.65      3126\\n        none       0.82      0.91      0.86     21399\\n    synonymy       0.85      0.86      0.85     14160\\n\\n    accuracy                           0.83     41814\\n   macro avg       0.80      0.67      0.71     41814\\nweighted avg       0.82      0.83      0.82     41814\\n\",\n    \"timestamp\": 1724685302,\n    \"checkpoint_dir_name\": null,\n    \"done\": false,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00028\",\n    \"date\": \"2024-08-26_18-15-02\",\n    \"time_this_iter_s\": 78.04343247413635,\n    \"time_total_s\": 78.04343247413635,\n    \"pid\": 21508,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 23,\n      \"batch_size\": 512,\n      \"hidden_sizes\": [\n        512\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.0,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 78.04343247413635,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"28_activation=relu,batch_size=512,dropout_rate=0.0000,hidden_sizes=512,lr=0.0000,num_epochs=23,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724685302.295442,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8252499162959774,\n      \"min\": 0.8252499162959774,\n      \"avg\": 0.8252499162959774,\n      \"last\": 0.8252499162959774,\n      \"last-5-avg\": 0.8252499162959774,\n      \"last-10-avg\": 0.8252499162959774\n    },\n    \"precision\": {\n      \"max\": 0.8221397221279025,\n      \"min\": 0.8221397221279025,\n      \"avg\": 0.8221397221279025,\n      \"last\": 0.8221397221279025,\n      \"last-5-avg\": 0.8221397221279025,\n      \"last-10-avg\": 0.8221397221279025\n    },\n    \"recall\": {\n      \"max\": 0.8252499162959774,\n      \"min\": 0.8252499162959774,\n      \"avg\": 0.8252499162959774,\n      \"last\": 0.8252499162959774,\n      \"last-5-avg\": 0.8252499162959774,\n      \"last-10-avg\": 0.8252499162959774\n    },\n    \"f1_score\": {\n      \"max\": 0.8153772117651591,\n      \"min\": 0.8153772117651591,\n      \"avg\": 0.8153772117651591,\n      \"last\": 0.8153772117651591,\n      \"last-5-avg\": 0.8153772117651591,\n      \"last-10-avg\": 0.8153772117651591\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 78.04343247413635,\n      \"min\": 78.04343247413635,\n      \"avg\": 78.04343247413635,\n      \"last\": 78.04343247413635,\n      \"last-5-avg\": 78.04343247413635,\n      \"last-10-avg\": 78.04343247413635\n    },\n    \"time_total_s\": {\n      \"max\": 78.04343247413635,\n      \"min\": 78.04343247413635,\n      \"avg\": 78.04343247413635,\n      \"last\": 78.04343247413635,\n      \"last-5-avg\": 78.04343247413635,\n      \"last-10-avg\": 78.04343247413635\n    },\n    \"time_since_restore\": {\n      \"max\": 78.04343247413635,\n      \"min\": 78.04343247413635,\n      \"avg\": 78.04343247413635,\n      \"last\": 78.04343247413635,\n      \"last-5-avg\": 78.04343247413635,\n      \"last-10-avg\": 78.04343247413635\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fea687283309322612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fea687283309322612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308120569f6f74eea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308120569f6f74eea3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308229330837268ea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308229330837268ea3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b9eb4df39117ea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b9eb4df39117ea3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405382c799000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405382c799000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405382c799000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405382c799000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405382c799000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405382c799000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00024\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303234948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 29,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 29,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 29,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"24_activation=relu,batch_size=32,dropout_rate=0.2000,hidden_sizes=512,lr=0.0001,num_epochs=29,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00024\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00024\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724684633.749604,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.9093365858324963,\n    \"precision\": 0.9095426787318628,\n    \"recall\": 0.9093365858324963,\n    \"f1_score\": 0.9083555934568067,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d6275666665729493942843801e090000000000000b00000000000000af0200000000000061000000000000000c00000000000000f709000000000000bc0100000000000077000000000000001801000000000000dc00000000000000234c000000000000800500000000000016000000000000001700000000000000d4010000000000004f35000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.88      0.75      0.81      3129\\n     hyponym       0.91      0.82      0.86      3126\\n        none       0.92      0.91      0.92     21399\\n    synonymy       0.89      0.96      0.93     14160\\n\\n    accuracy                           0.91     41814\\n   macro avg       0.90      0.86      0.88     41814\\nweighted avg       0.91      0.91      0.91     41814\\n\",\n    \"timestamp\": 1724684891,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00024\",\n    \"date\": \"2024-08-26_18-08-11\",\n    \"time_this_iter_s\": 257.49480080604553,\n    \"time_total_s\": 257.49480080604553,\n    \"pid\": 15628,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 29,\n      \"batch_size\": 32,\n      \"hidden_sizes\": [\n        512\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 257.49480080604553,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"24_activation=relu,batch_size=32,dropout_rate=0.2000,hidden_sizes=512,lr=0.0001,num_epochs=29,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724684891.250407,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.9093365858324963,\n      \"min\": 0.9093365858324963,\n      \"avg\": 0.9093365858324963,\n      \"last\": 0.9093365858324963,\n      \"last-5-avg\": 0.9093365858324963,\n      \"last-10-avg\": 0.9093365858324963\n    },\n    \"precision\": {\n      \"max\": 0.9095426787318628,\n      \"min\": 0.9095426787318628,\n      \"avg\": 0.9095426787318628,\n      \"last\": 0.9095426787318628,\n      \"last-5-avg\": 0.9095426787318628,\n      \"last-10-avg\": 0.9095426787318628\n    },\n    \"recall\": {\n      \"max\": 0.9093365858324963,\n      \"min\": 0.9093365858324963,\n      \"avg\": 0.9093365858324963,\n      \"last\": 0.9093365858324963,\n      \"last-5-avg\": 0.9093365858324963,\n      \"last-10-avg\": 0.9093365858324963\n    },\n    \"f1_score\": {\n      \"max\": 0.9083555934568067,\n      \"min\": 0.9083555934568067,\n      \"avg\": 0.9083555934568067,\n      \"last\": 0.9083555934568067,\n      \"last-5-avg\": 0.9083555934568067,\n      \"last-10-avg\": 0.9083555934568067\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 257.49480080604553,\n      \"min\": 257.49480080604553,\n      \"avg\": 257.49480080604553,\n      \"last\": 257.49480080604553,\n      \"last-5-avg\": 257.49480080604553,\n      \"last-10-avg\": 257.49480080604553\n    },\n    \"time_total_s\": {\n      \"max\": 257.49480080604553,\n      \"min\": 257.49480080604553,\n      \"avg\": 257.49480080604553,\n      \"last\": 257.49480080604553,\n      \"last-5-avg\": 257.49480080604553,\n      \"last-10-avg\": 257.49480080604553\n    },\n    \"time_since_restore\": {\n      \"max\": 257.49480080604553,\n      \"min\": 257.49480080604553,\n      \"avg\": 257.49480080604553,\n      \"last\": 257.49480080604553,\n      \"last-5-avg\": 257.49480080604553,\n      \"last-10-avg\": 257.49480080604553\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fed19490a269eab612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fed19490a269eab612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d8066f3ff91aed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d8066f3ff91aed3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ab9e260a4919ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ab9e260a4919ed3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081924e1bf3f11ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081924e1bf3f11ed3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407017eab4400000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407017eab4400000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407017eab4400000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407017eab4400000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407017eab4400000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407017eab4400000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00082\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303832948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 64,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 64,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 64,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"82_activation=relu,batch_size=32,dropout_rate=0.0000,hidden_sizes=128_64,lr=0.0001,num_epochs=64,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00082\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00082\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00003\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303033948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 58,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 58,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 58,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"3_activation=relu,batch_size=512,dropout_rate=0.2000,hidden_sizes=512,lr=0.0000,num_epochs=58,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00003\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00003\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724680296.476944,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8774781430858268,\n    \"precision\": 0.8763144799229958,\n    \"recall\": 0.8774781430858268,\n    \"f1_score\": 0.8752418189367172,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380980700000000000016000000000000007603000000000000d5000000000000000e00000000000000d8080000000000006602000000000000df000000000000006a01000000000000f000000000000000a5470000000000002b0500000000000036000000000000004000000000000000c0030000000000001933000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.82      0.63      0.71      3065\\n     hyponym       0.87      0.73      0.79      3115\\n        none       0.88      0.91      0.89     20266\\n    synonymy       0.88      0.92      0.90     14159\\n\\n    accuracy                           0.88     40605\\n   macro avg       0.86      0.80      0.83     40605\\nweighted avg       0.88      0.88      0.88     40605\\n\",\n    \"timestamp\": 1724680389,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00003\",\n    \"date\": \"2024-08-26_16-53-09\",\n    \"time_this_iter_s\": 92.9207706451416,\n    \"time_total_s\": 92.9207706451416,\n    \"pid\": 5060,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 58,\n      \"batch_size\": 512,\n      \"hidden_sizes\": [\n        512\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 92.9207706451416,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"3_activation=relu,batch_size=512,dropout_rate=0.2000,hidden_sizes=512,lr=0.0000,num_epochs=58,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724680389.4037156,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8774781430858268,\n      \"min\": 0.8774781430858268,\n      \"avg\": 0.8774781430858268,\n      \"last\": 0.8774781430858268,\n      \"last-5-avg\": 0.8774781430858268,\n      \"last-10-avg\": 0.8774781430858268\n    },\n    \"precision\": {\n      \"max\": 0.8763144799229958,\n      \"min\": 0.8763144799229958,\n      \"avg\": 0.8763144799229958,\n      \"last\": 0.8763144799229958,\n      \"last-5-avg\": 0.8763144799229958,\n      \"last-10-avg\": 0.8763144799229958\n    },\n    \"recall\": {\n      \"max\": 0.8774781430858268,\n      \"min\": 0.8774781430858268,\n      \"avg\": 0.8774781430858268,\n      \"last\": 0.8774781430858268,\n      \"last-5-avg\": 0.8774781430858268,\n      \"last-10-avg\": 0.8774781430858268\n    },\n    \"f1_score\": {\n      \"max\": 0.8752418189367172,\n      \"min\": 0.8752418189367172,\n      \"avg\": 0.8752418189367172,\n      \"last\": 0.8752418189367172,\n      \"last-5-avg\": 0.8752418189367172,\n      \"last-10-avg\": 0.8752418189367172\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 92.9207706451416,\n      \"min\": 92.9207706451416,\n      \"avg\": 92.9207706451416,\n      \"last\": 92.9207706451416,\n      \"last-5-avg\": 92.9207706451416,\n      \"last-10-avg\": 92.9207706451416\n    },\n    \"time_total_s\": {\n      \"max\": 92.9207706451416,\n      \"min\": 92.9207706451416,\n      \"avg\": 92.9207706451416,\n      \"last\": 92.9207706451416,\n      \"last-5-avg\": 92.9207706451416,\n      \"last-10-avg\": 92.9207706451416\n    },\n    \"time_since_restore\": {\n      \"max\": 92.9207706451416,\n      \"min\": 92.9207706451416,\n      \"avg\": 92.9207706451416,\n      \"last\": 92.9207706451416,\n      \"last-5-avg\": 92.9207706451416,\n      \"last-10-avg\": 92.9207706451416\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fec144d0af04519612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fec144d0af04519612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fcf908aac40aec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fcf908aac40aec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081945f00a4d14ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081945f00a4d14ec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430895978d21fb01ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430895978d21fb01ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740573aede8000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740573aede8000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740573aede8000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740573aede8000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740573aede8000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740573aede8000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00022\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303232948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 50,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 50,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 50,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"22_activation=relu,batch_size=32,dropout_rate=0.0000,hidden_sizes=512,lr=0.0001,num_epochs=50,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00022\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00022\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724683934.8648102,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.907853828861147,\n    \"precision\": 0.9086199918690748,\n    \"recall\": 0.907853828861147,\n    \"f1_score\": 0.907655476238949,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d6275666665729493942843809f090000000000002f00000000000000170200000000000054000000000000001200000000000000e30a0000000000000b010000000000003600000000000000a301000000000000de01000000000000fd4a000000000000190500000000000020000000000000003b000000000000002b02000000000000ca34000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.84      0.79      0.81      3129\\n     hyponym       0.83      0.89      0.86      3126\\n        none       0.93      0.90      0.92     21399\\n    synonymy       0.90      0.95      0.93     14160\\n\\n    accuracy                           0.91     41814\\n   macro avg       0.88      0.88      0.88     41814\\nweighted avg       0.91      0.91      0.91     41814\\n\",\n    \"timestamp\": 1724684306,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00022\",\n    \"date\": \"2024-08-26_17-58-26\",\n    \"time_this_iter_s\": 371.13676595687866,\n    \"time_total_s\": 371.13676595687866,\n    \"pid\": 33288,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 50,\n      \"batch_size\": 32,\n      \"hidden_sizes\": [\n        512\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.0,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 371.13676595687866,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"22_activation=relu,batch_size=32,dropout_rate=0.0000,hidden_sizes=512,lr=0.0001,num_epochs=50,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724684306.006574,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.907853828861147,\n      \"min\": 0.907853828861147,\n      \"avg\": 0.907853828861147,\n      \"last\": 0.907853828861147,\n      \"last-5-avg\": 0.907853828861147,\n      \"last-10-avg\": 0.907853828861147\n    },\n    \"precision\": {\n      \"max\": 0.9086199918690748,\n      \"min\": 0.9086199918690748,\n      \"avg\": 0.9086199918690748,\n      \"last\": 0.9086199918690748,\n      \"last-5-avg\": 0.9086199918690748,\n      \"last-10-avg\": 0.9086199918690748\n    },\n    \"recall\": {\n      \"max\": 0.907853828861147,\n      \"min\": 0.907853828861147,\n      \"avg\": 0.907853828861147,\n      \"last\": 0.907853828861147,\n      \"last-5-avg\": 0.907853828861147,\n      \"last-10-avg\": 0.907853828861147\n    },\n    \"f1_score\": {\n      \"max\": 0.907655476238949,\n      \"min\": 0.907655476238949,\n      \"avg\": 0.907655476238949,\n      \"last\": 0.907655476238949,\n      \"last-5-avg\": 0.907655476238949,\n      \"last-10-avg\": 0.907655476238949\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 371.13676595687866,\n      \"min\": 371.13676595687866,\n      \"avg\": 371.13676595687866,\n      \"last\": 371.13676595687866,\n      \"last-5-avg\": 371.13676595687866,\n      \"last-10-avg\": 371.13676595687866\n    },\n    \"time_total_s\": {\n      \"max\": 371.13676595687866,\n      \"min\": 371.13676595687866,\n      \"avg\": 371.13676595687866,\n      \"last\": 371.13676595687866,\n      \"last-5-avg\": 371.13676595687866,\n      \"last-10-avg\": 371.13676595687866\n    },\n    \"time_since_restore\": {\n      \"max\": 371.13676595687866,\n      \"min\": 371.13676595687866,\n      \"avg\": 371.13676595687866,\n      \"last\": 371.13676595687866,\n      \"last-5-avg\": 371.13676595687866,\n      \"last-10-avg\": 371.13676595687866\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fed0d2379103967612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fed0d2379103967612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080939b23b6a13ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080939b23b6a13ed3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430867391079230ded3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430867391079230ded3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430832694f7f830bed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430832694f7f830bed3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474077323031800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474077323031800000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474077323031800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474077323031800000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474077323031800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474077323031800000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00075\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303735948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 28,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 28,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 28,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"75_activation=relu,batch_size=512,dropout_rate=0.0000,hidden_sizes=512,lr=0.0001,num_epochs=28,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00075\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00075\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00021\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303231948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 36,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 36,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 36,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"21_activation=relu,batch_size=128,dropout_rate=0.1000,hidden_sizes=128_64,lr=0.0000,num_epochs=36,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00021\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00021\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724683784.4945703,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8611993596847679,\n    \"precision\": 0.8588004068270078,\n    \"recall\": 0.8611993596847679,\n    \"f1_score\": 0.858572787541356,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d62756666657294939428438012070000000000001a00000000000000c703000000000000060100000000000013000000000000007608000000000000a502000000000000fd00000000000000d3010000000000002f01000000000000e44600000000000044050000000000006f0000000000000067000000000000004c040000000000002d32000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.75      0.59      0.66      3065\\n     hyponym       0.83      0.70      0.76      3115\\n        none       0.87      0.90      0.88     20266\\n    synonymy       0.87      0.91      0.89     14159\\n\\n    accuracy                           0.86     40605\\n   macro avg       0.83      0.77      0.80     40605\\nweighted avg       0.86      0.86      0.86     40605\\n\",\n    \"timestamp\": 1724683926,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00021\",\n    \"date\": \"2024-08-26_17-52-06\",\n    \"time_this_iter_s\": 142.38823556900024,\n    \"time_total_s\": 142.38823556900024,\n    \"pid\": 2888,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 36,\n      \"batch_size\": 128,\n      \"hidden_sizes\": [\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.1,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 142.38823556900024,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"21_activation=relu,batch_size=128,dropout_rate=0.1000,hidden_sizes=128_64,lr=0.0000,num_epochs=36,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724683926.8878062,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8611993596847679,\n      \"min\": 0.8611993596847679,\n      \"avg\": 0.8611993596847679,\n      \"last\": 0.8611993596847679,\n      \"last-5-avg\": 0.8611993596847679,\n      \"last-10-avg\": 0.8611993596847679\n    },\n    \"precision\": {\n      \"max\": 0.8588004068270078,\n      \"min\": 0.8588004068270078,\n      \"avg\": 0.8588004068270078,\n      \"last\": 0.8588004068270078,\n      \"last-5-avg\": 0.8588004068270078,\n      \"last-10-avg\": 0.8588004068270078\n    },\n    \"recall\": {\n      \"max\": 0.8611993596847679,\n      \"min\": 0.8611993596847679,\n      \"avg\": 0.8611993596847679,\n      \"last\": 0.8611993596847679,\n      \"last-5-avg\": 0.8611993596847679,\n      \"last-10-avg\": 0.8611993596847679\n    },\n    \"f1_score\": {\n      \"max\": 0.858572787541356,\n      \"min\": 0.858572787541356,\n      \"avg\": 0.858572787541356,\n      \"last\": 0.858572787541356,\n      \"last-5-avg\": 0.858572787541356,\n      \"last-10-avg\": 0.858572787541356\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 142.38823556900024,\n      \"min\": 142.38823556900024,\n      \"avg\": 142.38823556900024,\n      \"last\": 142.38823556900024,\n      \"last-5-avg\": 142.38823556900024,\n      \"last-10-avg\": 142.38823556900024\n    },\n    \"time_total_s\": {\n      \"max\": 142.38823556900024,\n      \"min\": 142.38823556900024,\n      \"avg\": 142.38823556900024,\n      \"last\": 142.38823556900024,\n      \"last-5-avg\": 142.38823556900024,\n      \"last-10-avg\": 142.38823556900024\n    },\n    \"time_since_restore\": {\n      \"max\": 142.38823556900024,\n      \"min\": 142.38823556900024,\n      \"avg\": 142.38823556900024,\n      \"last\": 142.38823556900024,\n      \"last-5-avg\": 142.38823556900024,\n      \"last-10-avg\": 142.38823556900024\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473feb8ef1f5a5d4bd612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473feb8ef1f5a5d4bd612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308bda1a3fd4a7beb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308bda1a3fd4a7beb3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308bdd4a5f5f18eeb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308bdd4a5f5f18eeb3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c63877a36d79eb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c63877a36d79eb3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474061cc6c6d000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474061cc6c6d000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474061cc6c6d000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474061cc6c6d000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474061cc6c6d000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474061cc6c6d000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00067\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303637948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 57,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 57,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 57,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"67_activation=relu,batch_size=32,dropout_rate=0.0000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=57,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00067\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00067\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724693973.7532225,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.9194187907893117,\n    \"precision\": 0.9209972159695503,\n    \"recall\": 0.9194187907893117,\n    \"f1_score\": 0.9193098841443175,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d6275666665729493942843807c0a000000000000120000000000000041010000000000002a000000000000001500000000000000bd0a00000000000029010000000000003000000000000000cc010000000000002101000000000000d2460000000000006b050000000000001f000000000000001d000000000000004901000000000000ca35000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.84      0.88      0.86      3065\\n     hyponym       0.89      0.88      0.89      3115\\n        none       0.95      0.89      0.92     20266\\n    synonymy       0.90      0.97      0.94     14159\\n\\n    accuracy                           0.92     40605\\n   macro avg       0.90      0.91      0.90     40605\\nweighted avg       0.92      0.92      0.92     40605\\n\",\n    \"timestamp\": 1724694770,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00067\",\n    \"date\": \"2024-08-26_20-52-50\",\n    \"time_this_iter_s\": 796.7458076477051,\n    \"time_total_s\": 796.7458076477051,\n    \"pid\": 6772,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 57,\n      \"batch_size\": 32,\n      \"hidden_sizes\": [\n        1024,\n        512,\n        256,\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.0,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 796.7458076477051,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"67_activation=relu,batch_size=32,dropout_rate=0.0000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=57,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724694770.5051227,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.9194187907893117,\n      \"min\": 0.9194187907893117,\n      \"avg\": 0.9194187907893117,\n      \"last\": 0.9194187907893117,\n      \"last-5-avg\": 0.9194187907893117,\n      \"last-10-avg\": 0.9194187907893117\n    },\n    \"precision\": {\n      \"max\": 0.9209972159695503,\n      \"min\": 0.9209972159695503,\n      \"avg\": 0.9209972159695503,\n      \"last\": 0.9209972159695503,\n      \"last-5-avg\": 0.9209972159695503,\n      \"last-10-avg\": 0.9209972159695503\n    },\n    \"recall\": {\n      \"max\": 0.9194187907893117,\n      \"min\": 0.9194187907893117,\n      \"avg\": 0.9194187907893117,\n      \"last\": 0.9194187907893117,\n      \"last-5-avg\": 0.9194187907893117,\n      \"last-10-avg\": 0.9194187907893117\n    },\n    \"f1_score\": {\n      \"max\": 0.9193098841443175,\n      \"min\": 0.9193098841443175,\n      \"avg\": 0.9193098841443175,\n      \"last\": 0.9193098841443175,\n      \"last-5-avg\": 0.9193098841443175,\n      \"last-10-avg\": 0.9193098841443175\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 796.7458076477051,\n      \"min\": 796.7458076477051,\n      \"avg\": 796.7458076477051,\n      \"last\": 796.7458076477051,\n      \"last-5-avg\": 796.7458076477051,\n      \"last-10-avg\": 796.7458076477051\n    },\n    \"time_total_s\": {\n      \"max\": 796.7458076477051,\n      \"min\": 796.7458076477051,\n      \"avg\": 796.7458076477051,\n      \"last\": 796.7458076477051,\n      \"last-5-avg\": 796.7458076477051,\n      \"last-10-avg\": 796.7458076477051\n    },\n    \"time_since_restore\": {\n      \"max\": 796.7458076477051,\n      \"min\": 796.7458076477051,\n      \"avg\": 796.7458076477051,\n      \"last\": 796.7458076477051,\n      \"last-5-avg\": 796.7458076477051,\n      \"last-10-avg\": 796.7458076477051\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fed6be0f4b89320612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fed6be0f4b89320612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308067b4927cf78ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308067b4927cf78ed3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082093b8f4e06bed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082093b8f4e06bed3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b442e98ffc6aed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b442e98ffc6aed3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474088e5f76a000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474088e5f76a000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474088e5f76a000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474088e5f76a000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474088e5f76a000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474088e5f76a000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00012\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303132948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 68,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 68,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 68,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"12_activation=relu,batch_size=128,dropout_rate=0.1000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=68,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00012\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00012\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724682022.893721,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.9214377959535084,\n    \"precision\": 0.9225869475349338,\n    \"recall\": 0.9214377959535084,\n    \"f1_score\": 0.9213162885116039,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380480a0000000000001200000000000000b3010000000000002c000000000000001600000000000000f30a00000000000000010000000000002d000000000000009e010000000000005f01000000000000804b0000000000001a05000000000000300000000000000026000000000000003401000000000000c635000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.84      0.84      0.84      3129\\n     hyponym       0.87      0.90      0.88      3126\\n        none       0.95      0.90      0.93     21399\\n    synonymy       0.91      0.97      0.94     14160\\n\\n    accuracy                           0.92     41814\\n   macro avg       0.89      0.90      0.90     41814\\nweighted avg       0.92      0.92      0.92     41814\\n\",\n    \"timestamp\": 1724682350,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00012\",\n    \"date\": \"2024-08-26_17-25-50\",\n    \"time_this_iter_s\": 327.45317554473877,\n    \"time_total_s\": 327.45317554473877,\n    \"pid\": 33564,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 68,\n      \"batch_size\": 128,\n      \"hidden_sizes\": [\n        1024,\n        512,\n        256,\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.1,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 327.45317554473877,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"12_activation=relu,batch_size=128,dropout_rate=0.1000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=68,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724682350.3508995,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.9214377959535084,\n      \"min\": 0.9214377959535084,\n      \"avg\": 0.9214377959535084,\n      \"last\": 0.9214377959535084,\n      \"last-5-avg\": 0.9214377959535084,\n      \"last-10-avg\": 0.9214377959535084\n    },\n    \"precision\": {\n      \"max\": 0.9225869475349338,\n      \"min\": 0.9225869475349338,\n      \"avg\": 0.9225869475349338,\n      \"last\": 0.9225869475349338,\n      \"last-5-avg\": 0.9225869475349338,\n      \"last-10-avg\": 0.9225869475349338\n    },\n    \"recall\": {\n      \"max\": 0.9214377959535084,\n      \"min\": 0.9214377959535084,\n      \"avg\": 0.9214377959535084,\n      \"last\": 0.9214377959535084,\n      \"last-5-avg\": 0.9214377959535084,\n      \"last-10-avg\": 0.9214377959535084\n    },\n    \"f1_score\": {\n      \"max\": 0.9213162885116039,\n      \"min\": 0.9213162885116039,\n      \"avg\": 0.9213162885116039,\n      \"last\": 0.9213162885116039,\n      \"last-5-avg\": 0.9213162885116039,\n      \"last-10-avg\": 0.9213162885116039\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 327.45317554473877,\n      \"min\": 327.45317554473877,\n      \"avg\": 327.45317554473877,\n      \"last\": 327.45317554473877,\n      \"last-5-avg\": 327.45317554473877,\n      \"last-10-avg\": 327.45317554473877\n    },\n    \"time_total_s\": {\n      \"max\": 327.45317554473877,\n      \"min\": 327.45317554473877,\n      \"avg\": 327.45317554473877,\n      \"last\": 327.45317554473877,\n      \"last-5-avg\": 327.45317554473877,\n      \"last-10-avg\": 327.45317554473877\n    },\n    \"time_since_restore\": {\n      \"max\": 327.45317554473877,\n      \"min\": 327.45317554473877,\n      \"avg\": 327.45317554473877,\n      \"last\": 327.45317554473877,\n      \"last-5-avg\": 327.45317554473877,\n      \"last-10-avg\": 327.45317554473877\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fed7c6b1ddd657f612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fed7c6b1ddd657f612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d620ec0fd585ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d620ec0fd585ed3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087f65dd1d6b7ced3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087f65dd1d6b7ced3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f7bd0d4c6c7bed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f7bd0d4c6c7bed3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474074774035000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474074774035000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474074774035000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474074774035000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474074774035000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474074774035000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00087\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303837948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 58,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 58,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 58,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"87_activation=relu,batch_size=128,dropout_rate=0.2000,hidden_sizes=512,lr=0.0000,num_epochs=58,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00087\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00087\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00096\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303936948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 18,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 18,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 18,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"96_activation=relu,batch_size=128,dropout_rate=0.1000,hidden_sizes=128_64,lr=0.0000,num_epochs=18,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00096\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00096\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00055\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303535948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 27,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 27,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 27,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"55_activation=relu,batch_size=128,dropout_rate=0.2000,hidden_sizes=512,lr=0.0000,num_epochs=27,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00055\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00055\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724691507.8925343,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8814990194671641,\n    \"precision\": 0.8800910289662568,\n    \"recall\": 0.8814990194671641,\n    \"f1_score\": 0.8790720146007136,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d62756666657294939428438089070000000000001f00000000000000be03000000000000d3000000000000000b0000000000000004090000000000005102000000000000d6000000000000005c01000000000000fb00000000000000534c000000000000ed040000000000003c000000000000004400000000000000b5030000000000001b33000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.82      0.62      0.70      3129\\n     hyponym       0.87      0.74      0.80      3126\\n        none       0.89      0.91      0.90     21399\\n    synonymy       0.89      0.92      0.90     14160\\n\\n    accuracy                           0.88     41814\\n   macro avg       0.87      0.80      0.83     41814\\nweighted avg       0.88      0.88      0.88     41814\\n\",\n    \"timestamp\": 1724691621,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00055\",\n    \"date\": \"2024-08-26_20-00-21\",\n    \"time_this_iter_s\": 113.44709873199463,\n    \"time_total_s\": 113.44709873199463,\n    \"pid\": 9100,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 27,\n      \"batch_size\": 128,\n      \"hidden_sizes\": [\n        512\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 113.44709873199463,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"55_activation=relu,batch_size=128,dropout_rate=0.2000,hidden_sizes=512,lr=0.0000,num_epochs=27,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724691621.343633,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8814990194671641,\n      \"min\": 0.8814990194671641,\n      \"avg\": 0.8814990194671641,\n      \"last\": 0.8814990194671641,\n      \"last-5-avg\": 0.8814990194671641,\n      \"last-10-avg\": 0.8814990194671641\n    },\n    \"precision\": {\n      \"max\": 0.8800910289662568,\n      \"min\": 0.8800910289662568,\n      \"avg\": 0.8800910289662568,\n      \"last\": 0.8800910289662568,\n      \"last-5-avg\": 0.8800910289662568,\n      \"last-10-avg\": 0.8800910289662568\n    },\n    \"recall\": {\n      \"max\": 0.8814990194671641,\n      \"min\": 0.8814990194671641,\n      \"avg\": 0.8814990194671641,\n      \"last\": 0.8814990194671641,\n      \"last-5-avg\": 0.8814990194671641,\n      \"last-10-avg\": 0.8814990194671641\n    },\n    \"f1_score\": {\n      \"max\": 0.8790720146007136,\n      \"min\": 0.8790720146007136,\n      \"avg\": 0.8790720146007136,\n      \"last\": 0.8790720146007136,\n      \"last-5-avg\": 0.8790720146007136,\n      \"last-10-avg\": 0.8790720146007136\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 113.44709873199463,\n      \"min\": 113.44709873199463,\n      \"avg\": 113.44709873199463,\n      \"last\": 113.44709873199463,\n      \"last-5-avg\": 113.44709873199463,\n      \"last-10-avg\": 113.44709873199463\n    },\n    \"time_total_s\": {\n      \"max\": 113.44709873199463,\n      \"min\": 113.44709873199463,\n      \"avg\": 113.44709873199463,\n      \"last\": 113.44709873199463,\n      \"last-5-avg\": 113.44709873199463,\n      \"last-10-avg\": 113.44709873199463\n    },\n    \"time_since_restore\": {\n      \"max\": 113.44709873199463,\n      \"min\": 113.44709873199463,\n      \"avg\": 113.44709873199463,\n      \"last\": 113.44709873199463,\n      \"last-5-avg\": 113.44709873199463,\n      \"last-10-avg\": 113.44709873199463\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fec353d6e822944612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fec353d6e822944612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cd375da9b429ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cd375da9b429ec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084429826e3d35ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084429826e3d35ec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308aa3e31a25b21ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308aa3e31a25b21ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405c5c9d44000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405c5c9d44000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405c5c9d44000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405c5c9d44000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405c5c9d44000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405c5c9d44000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00038\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303338948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 35,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 35,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 35,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"38_activation=relu,batch_size=512,dropout_rate=0.1000,hidden_sizes=1024_512_256_128_64,lr=0.0000,num_epochs=35,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00038\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00038\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724687159.5415547,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8904568402906046,\n    \"precision\": 0.8906998147584304,\n    \"recall\": 0.8904568402906046,\n    \"f1_score\": 0.8899254618739464,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d6275666665729493942843801709000000000000140000000000000061020000000000006d000000000000002b000000000000007909000000000000d601000000000000b1000000000000003802000000000000410100000000000027460000000000008a050000000000006f00000000000000360000000000000024020000000000008634000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.76      0.76      0.76      3065\\n     hyponym       0.86      0.78      0.82      3115\\n        none       0.92      0.89      0.90     20266\\n    synonymy       0.89      0.95      0.92     14159\\n\\n    accuracy                           0.89     40605\\n   macro avg       0.86      0.84      0.85     40605\\nweighted avg       0.89      0.89      0.89     40605\\n\",\n    \"timestamp\": 1724687260,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00038\",\n    \"date\": \"2024-08-26_18-47-40\",\n    \"time_this_iter_s\": 100.5372428894043,\n    \"time_total_s\": 100.5372428894043,\n    \"pid\": 1900,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 35,\n      \"batch_size\": 512,\n      \"hidden_sizes\": [\n        1024,\n        512,\n        256,\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.1,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 100.5372428894043,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"38_activation=relu,batch_size=512,dropout_rate=0.1000,hidden_sizes=1024_512_256_128_64,lr=0.0000,num_epochs=35,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724687260.083803,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8904568402906046,\n      \"min\": 0.8904568402906046,\n      \"avg\": 0.8904568402906046,\n      \"last\": 0.8904568402906046,\n      \"last-5-avg\": 0.8904568402906046,\n      \"last-10-avg\": 0.8904568402906046\n    },\n    \"precision\": {\n      \"max\": 0.8906998147584304,\n      \"min\": 0.8906998147584304,\n      \"avg\": 0.8906998147584304,\n      \"last\": 0.8906998147584304,\n      \"last-5-avg\": 0.8906998147584304,\n      \"last-10-avg\": 0.8906998147584304\n    },\n    \"recall\": {\n      \"max\": 0.8904568402906046,\n      \"min\": 0.8904568402906046,\n      \"avg\": 0.8904568402906046,\n      \"last\": 0.8904568402906046,\n      \"last-5-avg\": 0.8904568402906046,\n      \"last-10-avg\": 0.8904568402906046\n    },\n    \"f1_score\": {\n      \"max\": 0.8899254618739464,\n      \"min\": 0.8899254618739464,\n      \"avg\": 0.8899254618739464,\n      \"last\": 0.8899254618739464,\n      \"last-5-avg\": 0.8899254618739464,\n      \"last-10-avg\": 0.8899254618739464\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 100.5372428894043,\n      \"min\": 100.5372428894043,\n      \"avg\": 100.5372428894043,\n      \"last\": 100.5372428894043,\n      \"last-5-avg\": 100.5372428894043,\n      \"last-10-avg\": 100.5372428894043\n    },\n    \"time_total_s\": {\n      \"max\": 100.5372428894043,\n      \"min\": 100.5372428894043,\n      \"avg\": 100.5372428894043,\n      \"last\": 100.5372428894043,\n      \"last-5-avg\": 100.5372428894043,\n      \"last-10-avg\": 100.5372428894043\n    },\n    \"time_since_restore\": {\n      \"max\": 100.5372428894043,\n      \"min\": 100.5372428894043,\n      \"avg\": 100.5372428894043,\n      \"last\": 100.5372428894043,\n      \"last-5-avg\": 100.5372428894043,\n      \"last-10-avg\": 100.5372428894043\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fec7e9f57f18648612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fec7e9f57f18648612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085a1adee59c80ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085a1adee59c80ec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084886f1579f7eec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084886f1579f7eec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089b0a54f6447aec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089b0a54f6447aec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474059226230000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474059226230000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474059226230000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474059226230000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474059226230000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474059226230000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00081\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303831948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 44,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 44,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 44,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"81_activation=relu,batch_size=128,dropout_rate=0.0000,hidden_sizes=128_64,lr=0.0001,num_epochs=44,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00081\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00081\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00029\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303239948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 64,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 64,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 64,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"29_activation=relu,batch_size=512,dropout_rate=0.2000,hidden_sizes=512,lr=0.0000,num_epochs=64,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00029\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00029\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724685310.151939,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8769363378894225,\n    \"precision\": 0.8758665770553167,\n    \"recall\": 0.8769363378894225,\n    \"f1_score\": 0.8746350617430394,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d6275666665729493942843809d0700000000000013000000000000007403000000000000d5000000000000001200000000000000bc080000000000008402000000000000d9000000000000005b01000000000000ea0000000000000089470000000000005c050000000000003b0000000000000041000000000000009d030000000000003633000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.82      0.64      0.72      3065\\n     hyponym       0.88      0.72      0.79      3115\\n        none       0.88      0.90      0.89     20266\\n    synonymy       0.88      0.93      0.90     14159\\n\\n    accuracy                           0.88     40605\\n   macro avg       0.86      0.80      0.83     40605\\nweighted avg       0.88      0.88      0.87     40605\\n\",\n    \"timestamp\": 1724685404,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00029\",\n    \"date\": \"2024-08-26_18-16-44\",\n    \"time_this_iter_s\": 94.73509883880615,\n    \"time_total_s\": 94.73509883880615,\n    \"pid\": 12908,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 64,\n      \"batch_size\": 512,\n      \"hidden_sizes\": [\n        512\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 94.73509883880615,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"29_activation=relu,batch_size=512,dropout_rate=0.2000,hidden_sizes=512,lr=0.0000,num_epochs=64,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724685404.891037,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8769363378894225,\n      \"min\": 0.8769363378894225,\n      \"avg\": 0.8769363378894225,\n      \"last\": 0.8769363378894225,\n      \"last-5-avg\": 0.8769363378894225,\n      \"last-10-avg\": 0.8769363378894225\n    },\n    \"precision\": {\n      \"max\": 0.8758665770553167,\n      \"min\": 0.8758665770553167,\n      \"avg\": 0.8758665770553167,\n      \"last\": 0.8758665770553167,\n      \"last-5-avg\": 0.8758665770553167,\n      \"last-10-avg\": 0.8758665770553167\n    },\n    \"recall\": {\n      \"max\": 0.8769363378894225,\n      \"min\": 0.8769363378894225,\n      \"avg\": 0.8769363378894225,\n      \"last\": 0.8769363378894225,\n      \"last-5-avg\": 0.8769363378894225,\n      \"last-10-avg\": 0.8769363378894225\n    },\n    \"f1_score\": {\n      \"max\": 0.8746350617430394,\n      \"min\": 0.8746350617430394,\n      \"avg\": 0.8746350617430394,\n      \"last\": 0.8746350617430394,\n      \"last-5-avg\": 0.8746350617430394,\n      \"last-10-avg\": 0.8746350617430394\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 94.73509883880615,\n      \"min\": 94.73509883880615,\n      \"avg\": 94.73509883880615,\n      \"last\": 94.73509883880615,\n      \"last-5-avg\": 94.73509883880615,\n      \"last-10-avg\": 94.73509883880615\n    },\n    \"time_total_s\": {\n      \"max\": 94.73509883880615,\n      \"min\": 94.73509883880615,\n      \"avg\": 94.73509883880615,\n      \"last\": 94.73509883880615,\n      \"last-5-avg\": 94.73509883880615,\n      \"last-10-avg\": 94.73509883880615\n    },\n    \"time_since_restore\": {\n      \"max\": 94.73509883880615,\n      \"min\": 94.73509883880615,\n      \"avg\": 94.73509883880615,\n      \"last\": 94.73509883880615,\n      \"last-5-avg\": 94.73509883880615,\n      \"last-10-avg\": 94.73509883880615\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fec0fdccb7d1725612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fec0fdccb7d1725612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e89503581907ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e89503581907ec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430825177dcbdc0fec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430825177dcbdc0fec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a6e143ab02fdeb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a6e143ab02fdeb3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474057af0bdc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474057af0bdc000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474057af0bdc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474057af0bdc000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474057af0bdc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474057af0bdc000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00068\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303638948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 18,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 18,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 18,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"68_activation=relu,batch_size=32,dropout_rate=0.1000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=18,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00068\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00068\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724694778.9081047,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.9134500406562396,\n    \"precision\": 0.9147729563612625,\n    \"recall\": 0.9134500406562396,\n    \"f1_score\": 0.9134338255185059,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380620a0000000000001000000000000000750100000000000052000000000000002a000000000000006a0a0000000000004a010000000000005800000000000000e8010000000000000f01000000000000444b0000000000005c050000000000004d000000000000002100000000000000bf010000000000002335000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.81      0.85      0.83      3129\\n     hyponym       0.89      0.85      0.87      3126\\n        none       0.94      0.90      0.92     21399\\n    synonymy       0.90      0.96      0.93     14160\\n\\n    accuracy                           0.91     41814\\n   macro avg       0.89      0.89      0.89     41814\\nweighted avg       0.91      0.91      0.91     41814\\n\",\n    \"timestamp\": 1724695310,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00068\",\n    \"date\": \"2024-08-26_21-01-50\",\n    \"time_this_iter_s\": 532.0122354030609,\n    \"time_total_s\": 532.0122354030609,\n    \"pid\": 33288,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 18,\n      \"batch_size\": 32,\n      \"hidden_sizes\": [\n        1024,\n        512,\n        256,\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.1,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 532.0122354030609,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"68_activation=relu,batch_size=32,dropout_rate=0.1000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=18,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724695310.9306648,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.9134500406562396,\n      \"min\": 0.9134500406562396,\n      \"avg\": 0.9134500406562396,\n      \"last\": 0.9134500406562396,\n      \"last-5-avg\": 0.9134500406562396,\n      \"last-10-avg\": 0.9134500406562396\n    },\n    \"precision\": {\n      \"max\": 0.9147729563612625,\n      \"min\": 0.9147729563612625,\n      \"avg\": 0.9147729563612625,\n      \"last\": 0.9147729563612625,\n      \"last-5-avg\": 0.9147729563612625,\n      \"last-10-avg\": 0.9147729563612625\n    },\n    \"recall\": {\n      \"max\": 0.9134500406562396,\n      \"min\": 0.9134500406562396,\n      \"avg\": 0.9134500406562396,\n      \"last\": 0.9134500406562396,\n      \"last-5-avg\": 0.9134500406562396,\n      \"last-10-avg\": 0.9134500406562396\n    },\n    \"f1_score\": {\n      \"max\": 0.9134338255185059,\n      \"min\": 0.9134338255185059,\n      \"avg\": 0.9134338255185059,\n      \"last\": 0.9134338255185059,\n      \"last-5-avg\": 0.9134338255185059,\n      \"last-10-avg\": 0.9134338255185059\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 532.0122354030609,\n      \"min\": 532.0122354030609,\n      \"avg\": 532.0122354030609,\n      \"last\": 532.0122354030609,\n      \"last-5-avg\": 532.0122354030609,\n      \"last-10-avg\": 532.0122354030609\n    },\n    \"time_total_s\": {\n      \"max\": 532.0122354030609,\n      \"min\": 532.0122354030609,\n      \"avg\": 532.0122354030609,\n      \"last\": 532.0122354030609,\n      \"last-5-avg\": 532.0122354030609,\n      \"last-10-avg\": 532.0122354030609\n    },\n    \"time_since_restore\": {\n      \"max\": 532.0122354030609,\n      \"min\": 532.0122354030609,\n      \"avg\": 532.0122354030609,\n      \"last\": 532.0122354030609,\n      \"last-5-avg\": 532.0122354030609,\n      \"last-10-avg\": 532.0122354030609\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fed3afb9464bfda612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fed3afb9464bfda612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088ac75aefd145ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088ac75aefd145ed3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308dabf6494fb3aed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308dabf6494fb3aed3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085c30f592d93aed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085c30f592d93aed3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474080a0190ee00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474080a0190ee00000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474080a0190ee00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474080a0190ee00000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474080a0190ee00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474080a0190ee00000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00036\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303336948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 63,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 63,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 63,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"36_activation=relu,batch_size=512,dropout_rate=0.2000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=63,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00036\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00036\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724686851.3212335,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.9203376859425073,\n    \"precision\": 0.9211829307078842,\n    \"recall\": 0.9203376859425073,\n    \"f1_score\": 0.9202468166777847,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380730a0000000000000d00000000000000990100000000000020000000000000001500000000000000ab0a0000000000003c010000000000003a00000000000000be01000000000000fe00000000000000d24b0000000000000905000000000000380000000000000018000000000000009d010000000000006335000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.84      0.85      0.85      3129\\n     hyponym       0.90      0.87      0.89      3126\\n        none       0.94      0.91      0.93     21399\\n    synonymy       0.91      0.97      0.94     14160\\n\\n    accuracy                           0.92     41814\\n   macro avg       0.90      0.90      0.90     41814\\nweighted avg       0.92      0.92      0.92     41814\\n\",\n    \"timestamp\": 1724686981,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00036\",\n    \"date\": \"2024-08-26_18-43-01\",\n    \"time_this_iter_s\": 129.8363254070282,\n    \"time_total_s\": 129.8363254070282,\n    \"pid\": 27608,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 63,\n      \"batch_size\": 512,\n      \"hidden_sizes\": [\n        1024,\n        512,\n        256,\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 129.8363254070282,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"36_activation=relu,batch_size=512,dropout_rate=0.2000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=63,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724686981.1634245,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.9203376859425073,\n      \"min\": 0.9203376859425073,\n      \"avg\": 0.9203376859425073,\n      \"last\": 0.9203376859425073,\n      \"last-5-avg\": 0.9203376859425073,\n      \"last-10-avg\": 0.9203376859425073\n    },\n    \"precision\": {\n      \"max\": 0.9211829307078842,\n      \"min\": 0.9211829307078842,\n      \"avg\": 0.9211829307078842,\n      \"last\": 0.9211829307078842,\n      \"last-5-avg\": 0.9211829307078842,\n      \"last-10-avg\": 0.9211829307078842\n    },\n    \"recall\": {\n      \"max\": 0.9203376859425073,\n      \"min\": 0.9203376859425073,\n      \"avg\": 0.9203376859425073,\n      \"last\": 0.9203376859425073,\n      \"last-5-avg\": 0.9203376859425073,\n      \"last-10-avg\": 0.9203376859425073\n    },\n    \"f1_score\": {\n      \"max\": 0.9202468166777847,\n      \"min\": 0.9202468166777847,\n      \"avg\": 0.9202468166777847,\n      \"last\": 0.9202468166777847,\n      \"last-5-avg\": 0.9202468166777847,\n      \"last-10-avg\": 0.9202468166777847\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 129.8363254070282,\n      \"min\": 129.8363254070282,\n      \"avg\": 129.8363254070282,\n      \"last\": 129.8363254070282,\n      \"last-5-avg\": 129.8363254070282,\n      \"last-10-avg\": 129.8363254070282\n    },\n    \"time_total_s\": {\n      \"max\": 129.8363254070282,\n      \"min\": 129.8363254070282,\n      \"avg\": 129.8363254070282,\n      \"last\": 129.8363254070282,\n      \"last-5-avg\": 129.8363254070282,\n      \"last-10-avg\": 129.8363254070282\n    },\n    \"time_since_restore\": {\n      \"max\": 129.8363254070282,\n      \"min\": 129.8363254070282,\n      \"avg\": 129.8363254070282,\n      \"last\": 129.8363254070282,\n      \"last-5-avg\": 129.8363254070282,\n      \"last-10-avg\": 129.8363254070282\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fed736804ccc7c9612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fed736804ccc7c9612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f1c220a0547aed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f1c220a0547aed3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c9c7cc046873ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c9c7cc046873ed3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085922bc73a972ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085922bc73a972ed3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740603ac32d800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740603ac32d800000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740603ac32d800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740603ac32d800000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740603ac32d800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740603ac32d800000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00083\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303833948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 48,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 48,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 48,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"83_activation=relu,batch_size=32,dropout_rate=0.2000,hidden_sizes=128_64,lr=0.0001,num_epochs=48,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00083\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00083\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00097\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303937948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 44,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 44,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 44,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"97_activation=relu,batch_size=32,dropout_rate=0.1000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=44,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00097\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00097\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00052\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303532948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 15,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 15,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 15,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"52_activation=relu,batch_size=32,dropout_rate=0.0000,hidden_sizes=512,lr=0.0001,num_epochs=15,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00052\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00052\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724690781.875166,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.9015638468168945,\n    \"precision\": 0.901525723521347,\n    \"recall\": 0.9015638468168945,\n    \"f1_score\": 0.9011842576832938,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380b2090000000000000b00000000000000f50100000000000047000000000000001e00000000000000be09000000000000db010000000000007400000000000000e001000000000000ea000000000000008b47000000000000d50400000000000031000000000000002500000000000000f4020000000000000534000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.82      0.81      0.81      3065\\n     hyponym       0.90      0.80      0.85      3115\\n        none       0.91      0.90      0.91     20266\\n    synonymy       0.90      0.94      0.92     14159\\n\\n    accuracy                           0.90     40605\\n   macro avg       0.88      0.86      0.87     40605\\nweighted avg       0.90      0.90      0.90     40605\\n\",\n    \"timestamp\": 1724690936,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00052\",\n    \"date\": \"2024-08-26_19-48-56\",\n    \"time_this_iter_s\": 154.8918318748474,\n    \"time_total_s\": 154.8918318748474,\n    \"pid\": 33728,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 15,\n      \"batch_size\": 32,\n      \"hidden_sizes\": [\n        512\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.0,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 154.8918318748474,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"52_activation=relu,batch_size=32,dropout_rate=0.0000,hidden_sizes=512,lr=0.0001,num_epochs=15,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724690936.7730055,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.9015638468168945,\n      \"min\": 0.9015638468168945,\n      \"avg\": 0.9015638468168945,\n      \"last\": 0.9015638468168945,\n      \"last-5-avg\": 0.9015638468168945,\n      \"last-10-avg\": 0.9015638468168945\n    },\n    \"precision\": {\n      \"max\": 0.901525723521347,\n      \"min\": 0.901525723521347,\n      \"avg\": 0.901525723521347,\n      \"last\": 0.901525723521347,\n      \"last-5-avg\": 0.901525723521347,\n      \"last-10-avg\": 0.901525723521347\n    },\n    \"recall\": {\n      \"max\": 0.9015638468168945,\n      \"min\": 0.9015638468168945,\n      \"avg\": 0.9015638468168945,\n      \"last\": 0.9015638468168945,\n      \"last-5-avg\": 0.9015638468168945,\n      \"last-10-avg\": 0.9015638468168945\n    },\n    \"f1_score\": {\n      \"max\": 0.9011842576832938,\n      \"min\": 0.9011842576832938,\n      \"avg\": 0.9011842576832938,\n      \"last\": 0.9011842576832938,\n      \"last-5-avg\": 0.9011842576832938,\n      \"last-10-avg\": 0.9011842576832938\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 154.8918318748474,\n      \"min\": 154.8918318748474,\n      \"avg\": 154.8918318748474,\n      \"last\": 154.8918318748474,\n      \"last-5-avg\": 154.8918318748474,\n      \"last-10-avg\": 154.8918318748474\n    },\n    \"time_total_s\": {\n      \"max\": 154.8918318748474,\n      \"min\": 154.8918318748474,\n      \"avg\": 154.8918318748474,\n      \"last\": 154.8918318748474,\n      \"last-5-avg\": 154.8918318748474,\n      \"last-10-avg\": 154.8918318748474\n    },\n    \"time_since_restore\": {\n      \"max\": 154.8918318748474,\n      \"min\": 154.8918318748474,\n      \"avg\": 154.8918318748474,\n      \"last\": 154.8918318748474,\n      \"last-5-avg\": 154.8918318748474,\n      \"last-10-avg\": 154.8918318748474\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fecd99c6caab45a612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fecd99c6caab45a612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088edc60794cd9ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088edc60794cd9ec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085ab4aa6c9cd9ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085ab4aa6c9cd9ec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308de6e4d5e80d6ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308de6e4d5e80d6ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740635c89e3000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740635c89e3000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740635c89e3000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740635c89e3000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740635c89e3000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740635c89e3000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00008\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303038948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 17,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 17,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 17,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"8_activation=relu,batch_size=128,dropout_rate=0.2000,hidden_sizes=512,lr=0.0001,num_epochs=17,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00008\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00008\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724681456.4294717,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.9031153798793252,\n    \"precision\": 0.9026911721628027,\n    \"recall\": 0.9031153798793252,\n    \"f1_score\": 0.902262589149673,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380ec080000000000000c000000000000007e0200000000000083000000000000001000000000000000f409000000000000bb010000000000006c00000000000000360100000000000000010000000000002f48000000000000c50400000000000020000000000000001900000000000000e6020000000000003034000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.86      0.75      0.80      3065\\n     hyponym       0.90      0.82      0.86      3115\\n        none       0.91      0.91      0.91     20266\\n    synonymy       0.90      0.94      0.92     14159\\n\\n    accuracy                           0.90     40605\\n   macro avg       0.89      0.85      0.87     40605\\nweighted avg       0.90      0.90      0.90     40605\\n\",\n    \"timestamp\": 1724681550,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00008\",\n    \"date\": \"2024-08-26_17-12-30\",\n    \"time_this_iter_s\": 93.68371605873108,\n    \"time_total_s\": 93.68371605873108,\n    \"pid\": 4544,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 17,\n      \"batch_size\": 128,\n      \"hidden_sizes\": [\n        512\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 93.68371605873108,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"8_activation=relu,batch_size=128,dropout_rate=0.2000,hidden_sizes=512,lr=0.0001,num_epochs=17,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724681550.1182668,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.9031153798793252,\n      \"min\": 0.9031153798793252,\n      \"avg\": 0.9031153798793252,\n      \"last\": 0.9031153798793252,\n      \"last-5-avg\": 0.9031153798793252,\n      \"last-10-avg\": 0.9031153798793252\n    },\n    \"precision\": {\n      \"max\": 0.9026911721628027,\n      \"min\": 0.9026911721628027,\n      \"avg\": 0.9026911721628027,\n      \"last\": 0.9026911721628027,\n      \"last-5-avg\": 0.9026911721628027,\n      \"last-10-avg\": 0.9026911721628027\n    },\n    \"recall\": {\n      \"max\": 0.9031153798793252,\n      \"min\": 0.9031153798793252,\n      \"avg\": 0.9031153798793252,\n      \"last\": 0.9031153798793252,\n      \"last-5-avg\": 0.9031153798793252,\n      \"last-10-avg\": 0.9031153798793252\n    },\n    \"f1_score\": {\n      \"max\": 0.902262589149673,\n      \"min\": 0.902262589149673,\n      \"avg\": 0.902262589149673,\n      \"last\": 0.902262589149673,\n      \"last-5-avg\": 0.902262589149673,\n      \"last-10-avg\": 0.902262589149673\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 93.68371605873108,\n      \"min\": 93.68371605873108,\n      \"avg\": 93.68371605873108,\n      \"last\": 93.68371605873108,\n      \"last-5-avg\": 93.68371605873108,\n      \"last-10-avg\": 93.68371605873108\n    },\n    \"time_total_s\": {\n      \"max\": 93.68371605873108,\n      \"min\": 93.68371605873108,\n      \"avg\": 93.68371605873108,\n      \"last\": 93.68371605873108,\n      \"last-5-avg\": 93.68371605873108,\n      \"last-10-avg\": 93.68371605873108\n    },\n    \"time_since_restore\": {\n      \"max\": 93.68371605873108,\n      \"min\": 93.68371605873108,\n      \"avg\": 93.68371605873108,\n      \"last\": 93.68371605873108,\n      \"last-5-avg\": 93.68371605873108,\n      \"last-10-avg\": 93.68371605873108\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fece65239a3150a612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fece65239a3150a612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f577da98d8e2ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f577da98d8e2ec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080a15a33952e6ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080a15a33952e6ec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080dab19cb55dfec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080dab19cb55dfec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740576bc201000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740576bc201000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740576bc201000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740576bc201000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740576bc201000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740576bc201000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00058\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303538948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 68,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 68,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 68,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"58_activation=relu,batch_size=512,dropout_rate=0.0000,hidden_sizes=1024_512_256_128_64,lr=0.0000,num_epochs=68,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00058\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00058\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724692162.2945578,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8937437221983068,\n    \"precision\": 0.8926517168479594,\n    \"recall\": 0.8937437221983068,\n    \"f1_score\": 0.8929600872539202,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380d00800000000000020000000000000000503000000000000440000000000000025000000000000009a0900000000000000020000000000007700000000000000bf0100000000000055010000000000005b4c000000000000280400000000000059000000000000006c0000000000000055030000000000003633000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.80      0.72      0.76      3129\\n     hyponym       0.84      0.79      0.81      3126\\n        none       0.90      0.91      0.91     21399\\n    synonymy       0.91      0.93      0.92     14160\\n\\n    accuracy                           0.89     41814\\n   macro avg       0.86      0.84      0.85     41814\\nweighted avg       0.89      0.89      0.89     41814\\n\",\n    \"timestamp\": 1724692291,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00058\",\n    \"date\": \"2024-08-26_20-11-31\",\n    \"time_this_iter_s\": 129.3781247138977,\n    \"time_total_s\": 129.3781247138977,\n    \"pid\": 7092,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 68,\n      \"batch_size\": 512,\n      \"hidden_sizes\": [\n        1024,\n        512,\n        256,\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.0,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 129.3781247138977,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"58_activation=relu,batch_size=512,dropout_rate=0.0000,hidden_sizes=1024_512_256_128_64,lr=0.0000,num_epochs=68,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724692291.6776862,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8937437221983068,\n      \"min\": 0.8937437221983068,\n      \"avg\": 0.8937437221983068,\n      \"last\": 0.8937437221983068,\n      \"last-5-avg\": 0.8937437221983068,\n      \"last-10-avg\": 0.8937437221983068\n    },\n    \"precision\": {\n      \"max\": 0.8926517168479594,\n      \"min\": 0.8926517168479594,\n      \"avg\": 0.8926517168479594,\n      \"last\": 0.8926517168479594,\n      \"last-5-avg\": 0.8926517168479594,\n      \"last-10-avg\": 0.8926517168479594\n    },\n    \"recall\": {\n      \"max\": 0.8937437221983068,\n      \"min\": 0.8937437221983068,\n      \"avg\": 0.8937437221983068,\n      \"last\": 0.8937437221983068,\n      \"last-5-avg\": 0.8937437221983068,\n      \"last-10-avg\": 0.8937437221983068\n    },\n    \"f1_score\": {\n      \"max\": 0.8929600872539202,\n      \"min\": 0.8929600872539202,\n      \"avg\": 0.8929600872539202,\n      \"last\": 0.8929600872539202,\n      \"last-5-avg\": 0.8929600872539202,\n      \"last-10-avg\": 0.8929600872539202\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 129.3781247138977,\n      \"min\": 129.3781247138977,\n      \"avg\": 129.3781247138977,\n      \"last\": 129.3781247138977,\n      \"last-5-avg\": 129.3781247138977,\n      \"last-10-avg\": 129.3781247138977\n    },\n    \"time_total_s\": {\n      \"max\": 129.3781247138977,\n      \"min\": 129.3781247138977,\n      \"avg\": 129.3781247138977,\n      \"last\": 129.3781247138977,\n      \"last-5-avg\": 129.3781247138977,\n      \"last-10-avg\": 129.3781247138977\n    },\n    \"time_since_restore\": {\n      \"max\": 129.3781247138977,\n      \"min\": 129.3781247138977,\n      \"avg\": 129.3781247138977,\n      \"last\": 129.3781247138977,\n      \"last-5-avg\": 129.3781247138977,\n      \"last-10-avg\": 129.3781247138977\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fec998c6f3b1aed612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fec998c6f3b1aed612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084f9152559a90ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084f9152559a90ec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ed1a3b6f8c99ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ed1a3b6f8c99ec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d1716c082193ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d1716c082193ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740602c1999000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740602c1999000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740602c1999000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740602c1999000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740602c1999000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740602c1999000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00000\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303030948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 48,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 48,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 48,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"0_activation=relu,batch_size=128,dropout_rate=0.1000,hidden_sizes=512,lr=0.0000,num_epochs=48,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00000\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00000\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724679083.4148977,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8982159085473764,\n    \"precision\": 0.8977411382845859,\n    \"recall\": 0.8982159085473764,\n    \"f1_score\": 0.8969906565604122,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d6275666665729493942843808f080000000000001500000000000000d802000000000000bd000000000000000b00000000000000d409000000000000b001000000000000a7000000000000004f010000000000002201000000000000ec4b0000000000003a05000000000000240000000000000037000000000000008e020000000000006734000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.85      0.70      0.77      3129\\n     hyponym       0.87      0.80      0.84      3126\\n        none       0.91      0.91      0.91     21399\\n    synonymy       0.89      0.95      0.92     14160\\n\\n    accuracy                           0.90     41814\\n   macro avg       0.88      0.84      0.86     41814\\nweighted avg       0.90      0.90      0.90     41814\\n\",\n    \"timestamp\": 1724679247,\n    \"checkpoint_dir_name\": null,\n    \"done\": false,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00000\",\n    \"date\": \"2024-08-26_16-34-07\",\n    \"time_this_iter_s\": 164.52081489562988,\n    \"time_total_s\": 164.52081489562988,\n    \"pid\": 33056,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 48,\n      \"batch_size\": 128,\n      \"hidden_sizes\": [\n        512\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.1,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 164.52081489562988,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"0_activation=relu,batch_size=128,dropout_rate=0.1000,hidden_sizes=512,lr=0.0000,num_epochs=48,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724679247.9468422,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8982159085473764,\n      \"min\": 0.8982159085473764,\n      \"avg\": 0.8982159085473764,\n      \"last\": 0.8982159085473764,\n      \"last-5-avg\": 0.8982159085473764,\n      \"last-10-avg\": 0.8982159085473764\n    },\n    \"precision\": {\n      \"max\": 0.8977411382845859,\n      \"min\": 0.8977411382845859,\n      \"avg\": 0.8977411382845859,\n      \"last\": 0.8977411382845859,\n      \"last-5-avg\": 0.8977411382845859,\n      \"last-10-avg\": 0.8977411382845859\n    },\n    \"recall\": {\n      \"max\": 0.8982159085473764,\n      \"min\": 0.8982159085473764,\n      \"avg\": 0.8982159085473764,\n      \"last\": 0.8982159085473764,\n      \"last-5-avg\": 0.8982159085473764,\n      \"last-10-avg\": 0.8982159085473764\n    },\n    \"f1_score\": {\n      \"max\": 0.8969906565604122,\n      \"min\": 0.8969906565604122,\n      \"avg\": 0.8969906565604122,\n      \"last\": 0.8969906565604122,\n      \"last-5-avg\": 0.8969906565604122,\n      \"last-10-avg\": 0.8969906565604122\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 164.52081489562988,\n      \"min\": 164.52081489562988,\n      \"avg\": 164.52081489562988,\n      \"last\": 164.52081489562988,\n      \"last-5-avg\": 164.52081489562988,\n      \"last-10-avg\": 164.52081489562988\n    },\n    \"time_total_s\": {\n      \"max\": 164.52081489562988,\n      \"min\": 164.52081489562988,\n      \"avg\": 164.52081489562988,\n      \"last\": 164.52081489562988,\n      \"last-5-avg\": 164.52081489562988,\n      \"last-10-avg\": 164.52081489562988\n    },\n    \"time_since_restore\": {\n      \"max\": 164.52081489562988,\n      \"min\": 164.52081489562988,\n      \"avg\": 164.52081489562988,\n      \"last\": 164.52081489562988,\n      \"last-5-avg\": 164.52081489562988,\n      \"last-10-avg\": 164.52081489562988\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fecbe2f49fea730612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fecbe2f49fea730612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087498a69f4bbaec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087498a69f4bbaec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430830a7fe492fbeec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430830a7fe492fbeec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430842d3d7bf25b4ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430842d3d7bf25b4ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447406490aa84000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447406490aa84000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447406490aa84000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447406490aa84000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447406490aa84000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447406490aa84000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00088\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303838948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 29,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 29,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 29,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"88_activation=relu,batch_size=128,dropout_rate=0.1000,hidden_sizes=512,lr=0.0000,num_epochs=29,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00088\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00088\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00027\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303237948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 13,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 13,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 13,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"27_activation=relu,batch_size=128,dropout_rate=0.0000,hidden_sizes=128_64,lr=0.0001,num_epochs=13,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00027\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00027\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724685122.3652847,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8870952312622566,\n    \"precision\": 0.8874698297481797,\n    \"recall\": 0.8870952312622566,\n    \"f1_score\": 0.8867530888497354,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d62756666657294939428438071090000000000001300000000000000230200000000000092000000000000002c000000000000003e09000000000000de01000000000000ee000000000000006b020000000000000501000000000000f54a00000000000032050000000000008100000000000000360000000000000058030000000000004133000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.75      0.77      0.76      3129\\n     hyponym       0.88      0.76      0.81      3126\\n        none       0.91      0.90      0.90     21399\\n    synonymy       0.88      0.93      0.91     14160\\n\\n    accuracy                           0.89     41814\\n   macro avg       0.86      0.84      0.85     41814\\nweighted avg       0.89      0.89      0.89     41814\\n\",\n    \"timestamp\": 1724685215,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00027\",\n    \"date\": \"2024-08-26_18-13-35\",\n    \"time_this_iter_s\": 93.46211814880371,\n    \"time_total_s\": 93.46211814880371,\n    \"pid\": 12140,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 13,\n      \"batch_size\": 128,\n      \"hidden_sizes\": [\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.0,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 93.46211814880371,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"27_activation=relu,batch_size=128,dropout_rate=0.0000,hidden_sizes=128_64,lr=0.0001,num_epochs=13,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724685215.8314025,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8870952312622566,\n      \"min\": 0.8870952312622566,\n      \"avg\": 0.8870952312622566,\n      \"last\": 0.8870952312622566,\n      \"last-5-avg\": 0.8870952312622566,\n      \"last-10-avg\": 0.8870952312622566\n    },\n    \"precision\": {\n      \"max\": 0.8874698297481797,\n      \"min\": 0.8874698297481797,\n      \"avg\": 0.8874698297481797,\n      \"last\": 0.8874698297481797,\n      \"last-5-avg\": 0.8874698297481797,\n      \"last-10-avg\": 0.8874698297481797\n    },\n    \"recall\": {\n      \"max\": 0.8870952312622566,\n      \"min\": 0.8870952312622566,\n      \"avg\": 0.8870952312622566,\n      \"last\": 0.8870952312622566,\n      \"last-5-avg\": 0.8870952312622566,\n      \"last-10-avg\": 0.8870952312622566\n    },\n    \"f1_score\": {\n      \"max\": 0.8867530888497354,\n      \"min\": 0.8867530888497354,\n      \"avg\": 0.8867530888497354,\n      \"last\": 0.8867530888497354,\n      \"last-5-avg\": 0.8867530888497354,\n      \"last-10-avg\": 0.8867530888497354\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 93.46211814880371,\n      \"min\": 93.46211814880371,\n      \"avg\": 93.46211814880371,\n      \"last\": 93.46211814880371,\n      \"last-5-avg\": 93.46211814880371,\n      \"last-10-avg\": 93.46211814880371\n    },\n    \"time_total_s\": {\n      \"max\": 93.46211814880371,\n      \"min\": 93.46211814880371,\n      \"avg\": 93.46211814880371,\n      \"last\": 93.46211814880371,\n      \"last-5-avg\": 93.46211814880371,\n      \"last-10-avg\": 93.46211814880371\n    },\n    \"time_since_restore\": {\n      \"max\": 93.46211814880371,\n      \"min\": 93.46211814880371,\n      \"avg\": 93.46211814880371,\n      \"last\": 93.46211814880371,\n      \"last-5-avg\": 93.46211814880371,\n      \"last-10-avg\": 93.46211814880371\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fec631589d6afb6612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fec631589d6afb6612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085790de202766ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085790de202766ec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b6afd6891563ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b6afd6891563ec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308319287034860ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308319287034860ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740575d9358000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740575d9358000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740575d9358000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740575d9358000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740575d9358000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740575d9358000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00035\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303335948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 19,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 19,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 19,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"35_activation=relu,batch_size=128,dropout_rate=0.1000,hidden_sizes=1024_512_256_128_64,lr=0.0000,num_epochs=19,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00035\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00035\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724686698.7547693,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8947720859042426,\n    \"precision\": 0.8967132527364813,\n    \"recall\": 0.8947720859042426,\n    \"f1_score\": 0.8949832265874086,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380c8090000000000001500000000000000ed010000000000006f000000000000003400000000000000050a0000000000005a01000000000000a300000000000000b6020000000000009001000000000000d84900000000000079050000000000007200000000000000580000000000000005020000000000008134000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.74      0.80      0.77      3129\\n     hyponym       0.83      0.82      0.83      3126\\n        none       0.93      0.88      0.91     21399\\n    synonymy       0.89      0.95      0.92     14160\\n\\n    accuracy                           0.89     41814\\n   macro avg       0.85      0.86      0.86     41814\\nweighted avg       0.90      0.89      0.89     41814\\n\",\n    \"timestamp\": 1724686842,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00035\",\n    \"date\": \"2024-08-26_18-40-42\",\n    \"time_this_iter_s\": 144.20624685287476,\n    \"time_total_s\": 144.20624685287476,\n    \"pid\": 23368,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 19,\n      \"batch_size\": 128,\n      \"hidden_sizes\": [\n        1024,\n        512,\n        256,\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.1,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 144.20624685287476,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"35_activation=relu,batch_size=128,dropout_rate=0.1000,hidden_sizes=1024_512_256_128_64,lr=0.0000,num_epochs=19,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724686842.9659507,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8947720859042426,\n      \"min\": 0.8947720859042426,\n      \"avg\": 0.8947720859042426,\n      \"last\": 0.8947720859042426,\n      \"last-5-avg\": 0.8947720859042426,\n      \"last-10-avg\": 0.8947720859042426\n    },\n    \"precision\": {\n      \"max\": 0.8967132527364813,\n      \"min\": 0.8967132527364813,\n      \"avg\": 0.8967132527364813,\n      \"last\": 0.8967132527364813,\n      \"last-5-avg\": 0.8967132527364813,\n      \"last-10-avg\": 0.8967132527364813\n    },\n    \"recall\": {\n      \"max\": 0.8947720859042426,\n      \"min\": 0.8947720859042426,\n      \"avg\": 0.8947720859042426,\n      \"last\": 0.8947720859042426,\n      \"last-5-avg\": 0.8947720859042426,\n      \"last-10-avg\": 0.8947720859042426\n    },\n    \"f1_score\": {\n      \"max\": 0.8949832265874086,\n      \"min\": 0.8949832265874086,\n      \"avg\": 0.8949832265874086,\n      \"last\": 0.8949832265874086,\n      \"last-5-avg\": 0.8949832265874086,\n      \"last-10-avg\": 0.8949832265874086\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 144.20624685287476,\n      \"min\": 144.20624685287476,\n      \"avg\": 144.20624685287476,\n      \"last\": 144.20624685287476,\n      \"last-5-avg\": 144.20624685287476,\n      \"last-10-avg\": 144.20624685287476\n    },\n    \"time_total_s\": {\n      \"max\": 144.20624685287476,\n      \"min\": 144.20624685287476,\n      \"avg\": 144.20624685287476,\n      \"last\": 144.20624685287476,\n      \"last-5-avg\": 144.20624685287476,\n      \"last-10-avg\": 144.20624685287476\n    },\n    \"time_since_restore\": {\n      \"max\": 144.20624685287476,\n      \"min\": 144.20624685287476,\n      \"avg\": 144.20624685287476,\n      \"last\": 144.20624685287476,\n      \"last-5-avg\": 144.20624685287476,\n      \"last-10-avg\": 144.20624685287476\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473feca1f911caa339612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473feca1f911caa339612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083593ccfddfb1ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083593ccfddfb1ec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430839a3ca11f9a1ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430839a3ca11f9a1ec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d32a15ddb3a3ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d32a15ddb3a3ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474062069993000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474062069993000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474062069993000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474062069993000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474062069993000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474062069993000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00018\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303138948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 30,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 30,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 30,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"18_activation=relu,batch_size=512,dropout_rate=0.2000,hidden_sizes=512,lr=0.0000,num_epochs=30,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00018\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00018\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724682933.6452131,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8388868365964782,\n    \"precision\": 0.8381536182479545,\n    \"recall\": 0.8388868365964782,\n    \"f1_score\": 0.8324939883794267,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380860500000000000014000000000000005605000000000000090100000000000010000000000000002b07000000000000bb0300000000000035010000000000003801000000000000bc000000000000006948000000000000cd04000000000000540000000000000075000000000000009106000000000000f52f000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.77      0.46      0.58      3065\\n     hyponym       0.85      0.59      0.70      3115\\n        none       0.82      0.91      0.87     20266\\n    synonymy       0.87      0.87      0.87     14159\\n\\n    accuracy                           0.84     40605\\n   macro avg       0.83      0.71      0.75     40605\\nweighted avg       0.84      0.84      0.83     40605\\n\",\n    \"timestamp\": 1724683013,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00018\",\n    \"date\": \"2024-08-26_17-36-53\",\n    \"time_this_iter_s\": 79.99665880203247,\n    \"time_total_s\": 79.99665880203247,\n    \"pid\": 33716,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 30,\n      \"batch_size\": 512,\n      \"hidden_sizes\": [\n        512\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 79.99665880203247,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"18_activation=relu,batch_size=512,dropout_rate=0.2000,hidden_sizes=512,lr=0.0000,num_epochs=30,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724683013.647879,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8388868365964782,\n      \"min\": 0.8388868365964782,\n      \"avg\": 0.8388868365964782,\n      \"last\": 0.8388868365964782,\n      \"last-5-avg\": 0.8388868365964782,\n      \"last-10-avg\": 0.8388868365964782\n    },\n    \"precision\": {\n      \"max\": 0.8381536182479545,\n      \"min\": 0.8381536182479545,\n      \"avg\": 0.8381536182479545,\n      \"last\": 0.8381536182479545,\n      \"last-5-avg\": 0.8381536182479545,\n      \"last-10-avg\": 0.8381536182479545\n    },\n    \"recall\": {\n      \"max\": 0.8388868365964782,\n      \"min\": 0.8388868365964782,\n      \"avg\": 0.8388868365964782,\n      \"last\": 0.8388868365964782,\n      \"last-5-avg\": 0.8388868365964782,\n      \"last-10-avg\": 0.8388868365964782\n    },\n    \"f1_score\": {\n      \"max\": 0.8324939883794267,\n      \"min\": 0.8324939883794267,\n      \"avg\": 0.8324939883794267,\n      \"last\": 0.8324939883794267,\n      \"last-5-avg\": 0.8324939883794267,\n      \"last-10-avg\": 0.8324939883794267\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 79.99665880203247,\n      \"min\": 79.99665880203247,\n      \"avg\": 79.99665880203247,\n      \"last\": 79.99665880203247,\n      \"last-5-avg\": 79.99665880203247,\n      \"last-10-avg\": 79.99665880203247\n    },\n    \"time_total_s\": {\n      \"max\": 79.99665880203247,\n      \"min\": 79.99665880203247,\n      \"avg\": 79.99665880203247,\n      \"last\": 79.99665880203247,\n      \"last-5-avg\": 79.99665880203247,\n      \"last-10-avg\": 79.99665880203247\n    },\n    \"time_since_restore\": {\n      \"max\": 79.99665880203247,\n      \"min\": 79.99665880203247,\n      \"avg\": 79.99665880203247,\n      \"last\": 79.99665880203247,\n      \"last-5-avg\": 79.99665880203247,\n      \"last-10-avg\": 79.99665880203247\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fead829350741b3612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fead829350741b3612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e2c46c8927d2ea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e2c46c8927d2ea3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b341073529d8ea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b341073529d8ea3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088899c66ecaa3ea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088899c66ecaa3ea3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474053ffc942000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474053ffc942000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474053ffc942000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474053ffc942000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474053ffc942000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474053ffc942000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00061\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303631948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 63,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 63,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 63,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"61_activation=relu,batch_size=512,dropout_rate=0.1000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=63,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00061\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00061\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724692609.5107262,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.9178983115702875,\n    \"precision\": 0.9189985499576935,\n    \"recall\": 0.9178983115702875,\n    \"f1_score\": 0.9176942879637915,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380380a00000000000013000000000000009b0100000000000053000000000000001300000000000000bc0a00000000000029010000000000003e0000000000000089010000000000002b010000000000005c4b0000000000008705000000000000150000000000000021000000000000007d010000000000009d35000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.86      0.84      0.85      3129\\n     hyponym       0.89      0.88      0.88      3126\\n        none       0.95      0.90      0.92     21399\\n    synonymy       0.90      0.97      0.93     14160\\n\\n    accuracy                           0.92     41814\\n   macro avg       0.90      0.90      0.90     41814\\nweighted avg       0.92      0.92      0.92     41814\\n\",\n    \"timestamp\": 1724692739,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00061\",\n    \"date\": \"2024-08-26_20-18-59\",\n    \"time_this_iter_s\": 130.29961013793945,\n    \"time_total_s\": 130.29961013793945,\n    \"pid\": 18388,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 63,\n      \"batch_size\": 512,\n      \"hidden_sizes\": [\n        1024,\n        512,\n        256,\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.1,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 130.29961013793945,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"61_activation=relu,batch_size=512,dropout_rate=0.1000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=63,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724692739.814336,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.9178983115702875,\n      \"min\": 0.9178983115702875,\n      \"avg\": 0.9178983115702875,\n      \"last\": 0.9178983115702875,\n      \"last-5-avg\": 0.9178983115702875,\n      \"last-10-avg\": 0.9178983115702875\n    },\n    \"precision\": {\n      \"max\": 0.9189985499576935,\n      \"min\": 0.9189985499576935,\n      \"avg\": 0.9189985499576935,\n      \"last\": 0.9189985499576935,\n      \"last-5-avg\": 0.9189985499576935,\n      \"last-10-avg\": 0.9189985499576935\n    },\n    \"recall\": {\n      \"max\": 0.9178983115702875,\n      \"min\": 0.9178983115702875,\n      \"avg\": 0.9178983115702875,\n      \"last\": 0.9178983115702875,\n      \"last-5-avg\": 0.9178983115702875,\n      \"last-10-avg\": 0.9178983115702875\n    },\n    \"f1_score\": {\n      \"max\": 0.9176942879637915,\n      \"min\": 0.9176942879637915,\n      \"avg\": 0.9176942879637915,\n      \"last\": 0.9176942879637915,\n      \"last-5-avg\": 0.9176942879637915,\n      \"last-10-avg\": 0.9176942879637915\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 130.29961013793945,\n      \"min\": 130.29961013793945,\n      \"avg\": 130.29961013793945,\n      \"last\": 130.29961013793945,\n      \"last-5-avg\": 130.29961013793945,\n      \"last-10-avg\": 130.29961013793945\n    },\n    \"time_total_s\": {\n      \"max\": 130.29961013793945,\n      \"min\": 130.29961013793945,\n      \"avg\": 130.29961013793945,\n      \"last\": 130.29961013793945,\n      \"last-5-avg\": 130.29961013793945,\n      \"last-10-avg\": 130.29961013793945\n    },\n    \"time_since_restore\": {\n      \"max\": 130.29961013793945,\n      \"min\": 130.29961013793945,\n      \"avg\": 130.29961013793945,\n      \"last\": 130.29961013793945,\n      \"last-5-avg\": 130.29961013793945,\n      \"last-10-avg\": 130.29961013793945\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fed5f6c47a7efa4612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fed5f6c47a7efa4612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088d78a4a56f68ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088d78a4a56f68ed3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a4efa7476c5fed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a4efa7476c5fed3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c8f95069c05ded3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c8f95069c05ded3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474060499668000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474060499668000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474060499668000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474060499668000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474060499668000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474060499668000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00017\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303137948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 35,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 35,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 35,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"17_activation=relu,batch_size=128,dropout_rate=0.2000,hidden_sizes=128_64,lr=0.0001,num_epochs=35,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00017\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00017\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724682780.2823186,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.9047926531783613,\n    \"precision\": 0.9050198691660967,\n    \"recall\": 0.9047926531783613,\n    \"f1_score\": 0.9043944019708879,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380ca09000000000000100000000000000015020000000000004a000000000000001000000000000000e809000000000000c5010000000000007900000000000000fc0100000000000003010000000000005a4b0000000000003e0500000000000034000000000000001c000000000000004302000000000000bd34000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.81      0.80      0.81      3129\\n     hyponym       0.89      0.81      0.85      3126\\n        none       0.92      0.90      0.91     21399\\n    synonymy       0.90      0.95      0.92     14160\\n\\n    accuracy                           0.90     41814\\n   macro avg       0.88      0.87      0.87     41814\\nweighted avg       0.91      0.90      0.90     41814\\n\",\n    \"timestamp\": 1724682925,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00017\",\n    \"date\": \"2024-08-26_17-35-25\",\n    \"time_this_iter_s\": 145.13041615486145,\n    \"time_total_s\": 145.13041615486145,\n    \"pid\": 33744,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 35,\n      \"batch_size\": 128,\n      \"hidden_sizes\": [\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 145.13041615486145,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"17_activation=relu,batch_size=128,dropout_rate=0.2000,hidden_sizes=128_64,lr=0.0001,num_epochs=35,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724682925.4167342,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.9047926531783613,\n      \"min\": 0.9047926531783613,\n      \"avg\": 0.9047926531783613,\n      \"last\": 0.9047926531783613,\n      \"last-5-avg\": 0.9047926531783613,\n      \"last-10-avg\": 0.9047926531783613\n    },\n    \"precision\": {\n      \"max\": 0.9050198691660967,\n      \"min\": 0.9050198691660967,\n      \"avg\": 0.9050198691660967,\n      \"last\": 0.9050198691660967,\n      \"last-5-avg\": 0.9050198691660967,\n      \"last-10-avg\": 0.9050198691660967\n    },\n    \"recall\": {\n      \"max\": 0.9047926531783613,\n      \"min\": 0.9047926531783613,\n      \"avg\": 0.9047926531783613,\n      \"last\": 0.9047926531783613,\n      \"last-5-avg\": 0.9047926531783613,\n      \"last-10-avg\": 0.9047926531783613\n    },\n    \"f1_score\": {\n      \"max\": 0.9043944019708879,\n      \"min\": 0.9043944019708879,\n      \"avg\": 0.9043944019708879,\n      \"last\": 0.9043944019708879,\n      \"last-5-avg\": 0.9043944019708879,\n      \"last-10-avg\": 0.9043944019708879\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 145.13041615486145,\n      \"min\": 145.13041615486145,\n      \"avg\": 145.13041615486145,\n      \"last\": 145.13041615486145,\n      \"last-5-avg\": 145.13041615486145,\n      \"last-10-avg\": 145.13041615486145\n    },\n    \"time_total_s\": {\n      \"max\": 145.13041615486145,\n      \"min\": 145.13041615486145,\n      \"avg\": 145.13041615486145,\n      \"last\": 145.13041615486145,\n      \"last-5-avg\": 145.13041615486145,\n      \"last-10-avg\": 145.13041615486145\n    },\n    \"time_since_restore\": {\n      \"max\": 145.13041615486145,\n      \"min\": 145.13041615486145,\n      \"avg\": 145.13041615486145,\n      \"last\": 145.13041615486145,\n      \"last-5-avg\": 145.13041615486145,\n      \"last-10-avg\": 145.13041615486145\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fecf40fb8e1fcfd612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fecf40fb8e1fcfd612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308008e893aecf5ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308008e893aecf5ec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fdfce1b80ff4ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fdfce1b80ff4ec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086bd06487ccf0ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086bd06487ccf0ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474062242c5e800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474062242c5e800000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474062242c5e800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474062242c5e800000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474062242c5e800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474062242c5e800000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00070\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303730948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 11,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 11,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 11,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"70_activation=relu,batch_size=128,dropout_rate=0.0000,hidden_sizes=1024_512_256_128_64,lr=0.0000,num_epochs=11,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00070\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00070\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00015\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303135948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 39,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 39,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 39,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"15_activation=relu,batch_size=128,dropout_rate=0.2000,hidden_sizes=512,lr=0.0000,num_epochs=39,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00015\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00015\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724682530.1039934,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8915158231744859,\n    \"precision\": 0.8905611323314566,\n    \"recall\": 0.8915158231744859,\n    \"f1_score\": 0.8904732015604003,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d62756666657294939428438090080000000000001a00000000000000c4020000000000008b000000000000001a000000000000008a09000000000000fa010000000000008d0000000000000074010000000000000e01000000000000e247000000000000c6040000000000004b00000000000000440000000000000054030000000000006c33000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.82      0.72      0.77      3065\\n     hyponym       0.87      0.78      0.82      3115\\n        none       0.90      0.91      0.90     20266\\n    synonymy       0.90      0.93      0.91     14159\\n\\n    accuracy                           0.89     40605\\n   macro avg       0.87      0.83      0.85     40605\\nweighted avg       0.89      0.89      0.89     40605\\n\",\n    \"timestamp\": 1724682660,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00015\",\n    \"date\": \"2024-08-26_17-31-00\",\n    \"time_this_iter_s\": 130.4985773563385,\n    \"time_total_s\": 130.4985773563385,\n    \"pid\": 31504,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 39,\n      \"batch_size\": 128,\n      \"hidden_sizes\": [\n        512\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 130.4985773563385,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"15_activation=relu,batch_size=128,dropout_rate=0.2000,hidden_sizes=512,lr=0.0000,num_epochs=39,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724682660.6075711,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8915158231744859,\n      \"min\": 0.8915158231744859,\n      \"avg\": 0.8915158231744859,\n      \"last\": 0.8915158231744859,\n      \"last-5-avg\": 0.8915158231744859,\n      \"last-10-avg\": 0.8915158231744859\n    },\n    \"precision\": {\n      \"max\": 0.8905611323314566,\n      \"min\": 0.8905611323314566,\n      \"avg\": 0.8905611323314566,\n      \"last\": 0.8905611323314566,\n      \"last-5-avg\": 0.8905611323314566,\n      \"last-10-avg\": 0.8905611323314566\n    },\n    \"recall\": {\n      \"max\": 0.8915158231744859,\n      \"min\": 0.8915158231744859,\n      \"avg\": 0.8915158231744859,\n      \"last\": 0.8915158231744859,\n      \"last-5-avg\": 0.8915158231744859,\n      \"last-10-avg\": 0.8915158231744859\n    },\n    \"f1_score\": {\n      \"max\": 0.8904732015604003,\n      \"min\": 0.8904732015604003,\n      \"avg\": 0.8904732015604003,\n      \"last\": 0.8904732015604003,\n      \"last-5-avg\": 0.8904732015604003,\n      \"last-10-avg\": 0.8904732015604003\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 130.4985773563385,\n      \"min\": 130.4985773563385,\n      \"avg\": 130.4985773563385,\n      \"last\": 130.4985773563385,\n      \"last-5-avg\": 130.4985773563385,\n      \"last-10-avg\": 130.4985773563385\n    },\n    \"time_total_s\": {\n      \"max\": 130.4985773563385,\n      \"min\": 130.4985773563385,\n      \"avg\": 130.4985773563385,\n      \"last\": 130.4985773563385,\n      \"last-5-avg\": 130.4985773563385,\n      \"last-10-avg\": 130.4985773563385\n    },\n    \"time_since_restore\": {\n      \"max\": 130.4985773563385,\n      \"min\": 130.4985773563385,\n      \"avg\": 130.4985773563385,\n      \"last\": 130.4985773563385,\n      \"last-5-avg\": 130.4985773563385,\n      \"last-10-avg\": 130.4985773563385\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fec874c310cd477612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fec874c310cd477612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430886794e0f7a7fec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430886794e0f7a7fec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430877d40c314c87ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430877d40c314c87ec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089f52d5a7c17eec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089f52d5a7c17eec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740604ff458800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740604ff458800000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740604ff458800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740604ff458800000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740604ff458800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740604ff458800000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00062\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303632948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 18,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 18,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 18,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"62_activation=relu,batch_size=512,dropout_rate=0.1000,hidden_sizes=128_64,lr=0.0001,num_epochs=18,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00062\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00062\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724692747.7492664,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8796336155354666,\n    \"precision\": 0.8782107928014724,\n    \"recall\": 0.8796336155354666,\n    \"f1_score\": 0.8778268690347487,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380c3070000000000001800000000000000ba03000000000000a40000000000000012000000000000006409000000000000280200000000000098000000000000007d0100000000000034010000000000006e4c00000000000078040000000000005100000000000000520000000000000095040000000000001832000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.81      0.64      0.71      3129\\n     hyponym       0.85      0.77      0.81      3126\\n        none       0.88      0.91      0.90     21399\\n    synonymy       0.90      0.91      0.90     14160\\n\\n    accuracy                           0.88     41814\\n   macro avg       0.86      0.81      0.83     41814\\nweighted avg       0.88      0.88      0.88     41814\\n\",\n    \"timestamp\": 1724692826,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00062\",\n    \"date\": \"2024-08-26_20-20-26\",\n    \"time_this_iter_s\": 78.60996866226196,\n    \"time_total_s\": 78.60996866226196,\n    \"pid\": 33092,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 18,\n      \"batch_size\": 512,\n      \"hidden_sizes\": [\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.1,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 78.60996866226196,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"62_activation=relu,batch_size=512,dropout_rate=0.1000,hidden_sizes=128_64,lr=0.0001,num_epochs=18,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724692826.3650904,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8796336155354666,\n      \"min\": 0.8796336155354666,\n      \"avg\": 0.8796336155354666,\n      \"last\": 0.8796336155354666,\n      \"last-5-avg\": 0.8796336155354666,\n      \"last-10-avg\": 0.8796336155354666\n    },\n    \"precision\": {\n      \"max\": 0.8782107928014724,\n      \"min\": 0.8782107928014724,\n      \"avg\": 0.8782107928014724,\n      \"last\": 0.8782107928014724,\n      \"last-5-avg\": 0.8782107928014724,\n      \"last-10-avg\": 0.8782107928014724\n    },\n    \"recall\": {\n      \"max\": 0.8796336155354666,\n      \"min\": 0.8796336155354666,\n      \"avg\": 0.8796336155354666,\n      \"last\": 0.8796336155354666,\n      \"last-5-avg\": 0.8796336155354666,\n      \"last-10-avg\": 0.8796336155354666\n    },\n    \"f1_score\": {\n      \"max\": 0.8778268690347487,\n      \"min\": 0.8778268690347487,\n      \"avg\": 0.8778268690347487,\n      \"last\": 0.8778268690347487,\n      \"last-5-avg\": 0.8778268690347487,\n      \"last-10-avg\": 0.8778268690347487\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 78.60996866226196,\n      \"min\": 78.60996866226196,\n      \"avg\": 78.60996866226196,\n      \"last\": 78.60996866226196,\n      \"last-5-avg\": 78.60996866226196,\n      \"last-10-avg\": 78.60996866226196\n    },\n    \"time_total_s\": {\n      \"max\": 78.60996866226196,\n      \"min\": 78.60996866226196,\n      \"avg\": 78.60996866226196,\n      \"last\": 78.60996866226196,\n      \"last-5-avg\": 78.60996866226196,\n      \"last-10-avg\": 78.60996866226196\n    },\n    \"time_since_restore\": {\n      \"max\": 78.60996866226196,\n      \"min\": 78.60996866226196,\n      \"avg\": 78.60996866226196,\n      \"last\": 78.60996866226196,\n      \"last-5-avg\": 78.60996866226196,\n      \"last-10-avg\": 78.60996866226196\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fec25f56565fc73612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fec25f56565fc73612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308267342854d1aec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308267342854d1aec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430873fc6565f525ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430873fc6565f525ec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ffbcc15f2817ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ffbcc15f2817ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474053a709ba000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474053a709ba000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474053a709ba000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474053a709ba000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474053a709ba000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474053a709ba000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00009\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303039948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 22,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 22,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 22,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"9_activation=relu,batch_size=128,dropout_rate=0.2000,hidden_sizes=128_64,lr=0.0000,num_epochs=22,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00009\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00009\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724681558.2090168,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8303678193906348,\n    \"precision\": 0.8259776931093521,\n    \"recall\": 0.8303678193906348,\n    \"f1_score\": 0.82296691117657,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d62756666657294939428438007050000000000002e000000000000004205000000000000c2010000000000000f000000000000001b07000000000000a50300000000000067010000000000004d010000000000005d01000000000000cd4a00000000000020060000000000005500000000000000af000000000000009a05000000000000b230000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.75      0.41      0.53      3129\\n     hyponym       0.76      0.58      0.66      3126\\n        none       0.84      0.89      0.87     21399\\n    synonymy       0.84      0.88      0.86     14160\\n\\n    accuracy                           0.83     41814\\n   macro avg       0.80      0.69      0.73     41814\\nweighted avg       0.83      0.83      0.82     41814\\n\",\n    \"timestamp\": 1724681673,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00009\",\n    \"date\": \"2024-08-26_17-14-33\",\n    \"time_this_iter_s\": 115.04887700080872,\n    \"time_total_s\": 115.04887700080872,\n    \"pid\": 29756,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 22,\n      \"batch_size\": 128,\n      \"hidden_sizes\": [\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 115.04887700080872,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"9_activation=relu,batch_size=128,dropout_rate=0.2000,hidden_sizes=128_64,lr=0.0000,num_epochs=22,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724681673.2640386,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8303678193906348,\n      \"min\": 0.8303678193906348,\n      \"avg\": 0.8303678193906348,\n      \"last\": 0.8303678193906348,\n      \"last-5-avg\": 0.8303678193906348,\n      \"last-10-avg\": 0.8303678193906348\n    },\n    \"precision\": {\n      \"max\": 0.8259776931093521,\n      \"min\": 0.8259776931093521,\n      \"avg\": 0.8259776931093521,\n      \"last\": 0.8259776931093521,\n      \"last-5-avg\": 0.8259776931093521,\n      \"last-10-avg\": 0.8259776931093521\n    },\n    \"recall\": {\n      \"max\": 0.8303678193906348,\n      \"min\": 0.8303678193906348,\n      \"avg\": 0.8303678193906348,\n      \"last\": 0.8303678193906348,\n      \"last-5-avg\": 0.8303678193906348,\n      \"last-10-avg\": 0.8303678193906348\n    },\n    \"f1_score\": {\n      \"max\": 0.82296691117657,\n      \"min\": 0.82296691117657,\n      \"avg\": 0.82296691117657,\n      \"last\": 0.82296691117657,\n      \"last-5-avg\": 0.82296691117657,\n      \"last-10-avg\": 0.82296691117657\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 115.04887700080872,\n      \"min\": 115.04887700080872,\n      \"avg\": 115.04887700080872,\n      \"last\": 115.04887700080872,\n      \"last-5-avg\": 115.04887700080872,\n      \"last-10-avg\": 115.04887700080872\n    },\n    \"time_total_s\": {\n      \"max\": 115.04887700080872,\n      \"min\": 115.04887700080872,\n      \"avg\": 115.04887700080872,\n      \"last\": 115.04887700080872,\n      \"last-5-avg\": 115.04887700080872,\n      \"last-10-avg\": 115.04887700080872\n    },\n    \"time_since_restore\": {\n      \"max\": 115.04887700080872,\n      \"min\": 115.04887700080872,\n      \"avg\": 115.04887700080872,\n      \"last\": 115.04887700080872,\n      \"last-5-avg\": 115.04887700080872,\n      \"last-10-avg\": 115.04887700080872\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fea925f887de024612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fea925f887de024612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308882a64c5686eea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308882a64c5686eea3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430824e07d885f92ea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430824e07d885f92ea3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308313126b4be55ea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308313126b4be55ea3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405cc320cd000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405cc320cd000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405cc320cd000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405cc320cd000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405cc320cd000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405cc320cd000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00007\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303037948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 32,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 32,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 32,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"7_activation=relu,batch_size=512,dropout_rate=0.1000,hidden_sizes=128_64,lr=0.0001,num_epochs=32,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00007\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00007\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724681361.4946275,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.900184706316956,\n    \"precision\": 0.8998727571770867,\n    \"recall\": 0.900184706316956,\n    \"f1_score\": 0.8995631929288003,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d6275666665729493942843801b090000000000001000000000000000590200000000000075000000000000001200000000000000200a0000000000009e010000000000005b000000000000007f010000000000004d010000000000002847000000000000360500000000000020000000000000003a0000000000000090020000000000006534000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.84      0.76      0.80      3065\\n     hyponym       0.86      0.83      0.85      3115\\n        none       0.92      0.90      0.91     20266\\n    synonymy       0.90      0.95      0.92     14159\\n\\n    accuracy                           0.90     40605\\n   macro avg       0.88      0.86      0.87     40605\\nweighted avg       0.90      0.90      0.90     40605\\n\",\n    \"timestamp\": 1724681447,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00007\",\n    \"date\": \"2024-08-26_17-10-47\",\n    \"time_this_iter_s\": 85.8374297618866,\n    \"time_total_s\": 85.8374297618866,\n    \"pid\": 31904,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 32,\n      \"batch_size\": 512,\n      \"hidden_sizes\": [\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.1,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 85.8374297618866,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"7_activation=relu,batch_size=512,dropout_rate=0.1000,hidden_sizes=128_64,lr=0.0001,num_epochs=32,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724681447.3376253,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.900184706316956,\n      \"min\": 0.900184706316956,\n      \"avg\": 0.900184706316956,\n      \"last\": 0.900184706316956,\n      \"last-5-avg\": 0.900184706316956,\n      \"last-10-avg\": 0.900184706316956\n    },\n    \"precision\": {\n      \"max\": 0.8998727571770867,\n      \"min\": 0.8998727571770867,\n      \"avg\": 0.8998727571770867,\n      \"last\": 0.8998727571770867,\n      \"last-5-avg\": 0.8998727571770867,\n      \"last-10-avg\": 0.8998727571770867\n    },\n    \"recall\": {\n      \"max\": 0.900184706316956,\n      \"min\": 0.900184706316956,\n      \"avg\": 0.900184706316956,\n      \"last\": 0.900184706316956,\n      \"last-5-avg\": 0.900184706316956,\n      \"last-10-avg\": 0.900184706316956\n    },\n    \"f1_score\": {\n      \"max\": 0.8995631929288003,\n      \"min\": 0.8995631929288003,\n      \"avg\": 0.8995631929288003,\n      \"last\": 0.8995631929288003,\n      \"last-5-avg\": 0.8995631929288003,\n      \"last-10-avg\": 0.8995631929288003\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 85.8374297618866,\n      \"min\": 85.8374297618866,\n      \"avg\": 85.8374297618866,\n      \"last\": 85.8374297618866,\n      \"last-5-avg\": 85.8374297618866,\n      \"last-10-avg\": 85.8374297618866\n    },\n    \"time_total_s\": {\n      \"max\": 85.8374297618866,\n      \"min\": 85.8374297618866,\n      \"avg\": 85.8374297618866,\n      \"last\": 85.8374297618866,\n      \"last-5-avg\": 85.8374297618866,\n      \"last-10-avg\": 85.8374297618866\n    },\n    \"time_since_restore\": {\n      \"max\": 85.8374297618866,\n      \"min\": 85.8374297618866,\n      \"avg\": 85.8374297618866,\n      \"last\": 85.8374297618866,\n      \"last-5-avg\": 85.8374297618866,\n      \"last-10-avg\": 85.8374297618866\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fecce50283fb3bd612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fecce50283fb3bd612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c961d4f3c1cbec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c961d4f3c1cbec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308bdb33f2850ceec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308bdb33f2850ceec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ad10cabf38c9ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ad10cabf38c9ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474055759873000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474055759873000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474055759873000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474055759873000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474055759873000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474055759873000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00014\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303134948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 16,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 16,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 16,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"14_activation=relu,batch_size=512,dropout_rate=0.0000,hidden_sizes=128_64,lr=0.0001,num_epochs=16,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00014\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00014\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724682445.0750394,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8668636867380864,\n    \"precision\": 0.8665787203720555,\n    \"recall\": 0.8668636867380864,\n    \"f1_score\": 0.8644568522376106,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d62756666657294939428438033070000000000002500000000000000110400000000000090000000000000001500000000000000d308000000000000b20200000000000091000000000000002c010000000000002d010000000000000649000000000000cb030000000000005100000000000000af00000000000000dc050000000000007330000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.82      0.60      0.69      3065\\n     hyponym       0.81      0.73      0.77      3115\\n        none       0.85      0.92      0.89     20266\\n    synonymy       0.91      0.88      0.89     14159\\n\\n    accuracy                           0.87     40605\\n   macro avg       0.85      0.78      0.81     40605\\nweighted avg       0.87      0.87      0.86     40605\\n\",\n    \"timestamp\": 1724682520,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00014\",\n    \"date\": \"2024-08-26_17-28-40\",\n    \"time_this_iter_s\": 75.40365171432495,\n    \"time_total_s\": 75.40365171432495,\n    \"pid\": 14744,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 16,\n      \"batch_size\": 512,\n      \"hidden_sizes\": [\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.0,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 75.40365171432495,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"14_activation=relu,batch_size=512,dropout_rate=0.0000,hidden_sizes=128_64,lr=0.0001,num_epochs=16,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724682520.4836926,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8668636867380864,\n      \"min\": 0.8668636867380864,\n      \"avg\": 0.8668636867380864,\n      \"last\": 0.8668636867380864,\n      \"last-5-avg\": 0.8668636867380864,\n      \"last-10-avg\": 0.8668636867380864\n    },\n    \"precision\": {\n      \"max\": 0.8665787203720555,\n      \"min\": 0.8665787203720555,\n      \"avg\": 0.8665787203720555,\n      \"last\": 0.8665787203720555,\n      \"last-5-avg\": 0.8665787203720555,\n      \"last-10-avg\": 0.8665787203720555\n    },\n    \"recall\": {\n      \"max\": 0.8668636867380864,\n      \"min\": 0.8668636867380864,\n      \"avg\": 0.8668636867380864,\n      \"last\": 0.8668636867380864,\n      \"last-5-avg\": 0.8668636867380864,\n      \"last-10-avg\": 0.8668636867380864\n    },\n    \"f1_score\": {\n      \"max\": 0.8644568522376106,\n      \"min\": 0.8644568522376106,\n      \"avg\": 0.8644568522376106,\n      \"last\": 0.8644568522376106,\n      \"last-5-avg\": 0.8644568522376106,\n      \"last-10-avg\": 0.8644568522376106\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 75.40365171432495,\n      \"min\": 75.40365171432495,\n      \"avg\": 75.40365171432495,\n      \"last\": 75.40365171432495,\n      \"last-5-avg\": 75.40365171432495,\n      \"last-10-avg\": 75.40365171432495\n    },\n    \"time_total_s\": {\n      \"max\": 75.40365171432495,\n      \"min\": 75.40365171432495,\n      \"avg\": 75.40365171432495,\n      \"last\": 75.40365171432495,\n      \"last-5-avg\": 75.40365171432495,\n      \"last-10-avg\": 75.40365171432495\n    },\n    \"time_since_restore\": {\n      \"max\": 75.40365171432495,\n      \"min\": 75.40365171432495,\n      \"avg\": 75.40365171432495,\n      \"last\": 75.40365171432495,\n      \"last-5-avg\": 75.40365171432495,\n      \"last-10-avg\": 75.40365171432495\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473febbd58ea142989612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473febbd58ea142989612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084d0aed4b03bbeb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084d0aed4b03bbeb3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308892914ea58bdeb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308892914ea58bdeb3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088e3ca56aa1a9eb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088e3ca56aa1a9eb3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474052d9d56e000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474052d9d56e000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474052d9d56e000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474052d9d56e000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474052d9d56e000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474052d9d56e000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00045\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303435948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 59,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 59,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 59,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"45_activation=relu,batch_size=128,dropout_rate=0.0000,hidden_sizes=128_64,lr=0.0000,num_epochs=59,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00045\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00045\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724689069.3798459,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8728416319892859,\n    \"precision\": 0.8705551253676043,\n    \"recall\": 0.8728416319892859,\n    \"f1_score\": 0.870193605862626,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380280700000000000021000000000000002004000000000000d0000000000000001900000000000000fb080000000000005802000000000000ca00000000000000900100000000000042010000000000005f4b0000000000006605000000000000550000000000000070000000000000007c030000000000000f33000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.78      0.59      0.67      3129\\n     hyponym       0.83      0.74      0.78      3126\\n        none       0.88      0.90      0.89     21399\\n    synonymy       0.88      0.92      0.90     14160\\n\\n    accuracy                           0.87     41814\\n   macro avg       0.84      0.79      0.81     41814\\nweighted avg       0.87      0.87      0.87     41814\\n\",\n    \"timestamp\": 1724689252,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00045\",\n    \"date\": \"2024-08-26_19-20-52\",\n    \"time_this_iter_s\": 183.1797149181366,\n    \"time_total_s\": 183.1797149181366,\n    \"pid\": 33004,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 59,\n      \"batch_size\": 128,\n      \"hidden_sizes\": [\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.0,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 183.1797149181366,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"45_activation=relu,batch_size=128,dropout_rate=0.0000,hidden_sizes=128_64,lr=0.0000,num_epochs=59,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724689252.5645647,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8728416319892859,\n      \"min\": 0.8728416319892859,\n      \"avg\": 0.8728416319892859,\n      \"last\": 0.8728416319892859,\n      \"last-5-avg\": 0.8728416319892859,\n      \"last-10-avg\": 0.8728416319892859\n    },\n    \"precision\": {\n      \"max\": 0.8705551253676043,\n      \"min\": 0.8705551253676043,\n      \"avg\": 0.8705551253676043,\n      \"last\": 0.8705551253676043,\n      \"last-5-avg\": 0.8705551253676043,\n      \"last-10-avg\": 0.8705551253676043\n    },\n    \"recall\": {\n      \"max\": 0.8728416319892859,\n      \"min\": 0.8728416319892859,\n      \"avg\": 0.8728416319892859,\n      \"last\": 0.8728416319892859,\n      \"last-5-avg\": 0.8728416319892859,\n      \"last-10-avg\": 0.8728416319892859\n    },\n    \"f1_score\": {\n      \"max\": 0.870193605862626,\n      \"min\": 0.870193605862626,\n      \"avg\": 0.870193605862626,\n      \"last\": 0.870193605862626,\n      \"last-5-avg\": 0.870193605862626,\n      \"last-10-avg\": 0.870193605862626\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 183.1797149181366,\n      \"min\": 183.1797149181366,\n      \"avg\": 183.1797149181366,\n      \"last\": 183.1797149181366,\n      \"last-5-avg\": 183.1797149181366,\n      \"last-10-avg\": 183.1797149181366\n    },\n    \"time_total_s\": {\n      \"max\": 183.1797149181366,\n      \"min\": 183.1797149181366,\n      \"avg\": 183.1797149181366,\n      \"last\": 183.1797149181366,\n      \"last-5-avg\": 183.1797149181366,\n      \"last-10-avg\": 183.1797149181366\n    },\n    \"time_since_restore\": {\n      \"max\": 183.1797149181366,\n      \"min\": 183.1797149181366,\n      \"avg\": 183.1797149181366,\n      \"last\": 183.1797149181366,\n      \"last-5-avg\": 183.1797149181366,\n      \"last-10-avg\": 183.1797149181366\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473febee5192ff6667612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473febee5192ff6667612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430894351a6c96dbeb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430894351a6c96dbeb3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086766ff9251eeeb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086766ff9251eeeb3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080dc9cb42a0d8eb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080dc9cb42a0d8eb3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474066e5c039800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474066e5c039800000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474066e5c039800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474066e5c039800000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474066e5c039800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474066e5c039800000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00010\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303130948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 15,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 15,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 15,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"10_activation=relu,batch_size=128,dropout_rate=0.2000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=15,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00010\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00010\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724681681.3654845,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.9122781843401732,\n    \"precision\": 0.9131683499768823,\n    \"recall\": 0.9122781843401732,\n    \"f1_score\": 0.912147110385929,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d6275666665729493942843802c0a0000000000001300000000000000b20100000000000048000000000000001600000000000000720a0000000000005a010000000000005400000000000000cc0100000000000019010000000000004c4b000000000000660500000000000040000000000000003600000000000000c2010000000000001835000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.83      0.83      0.83      3129\\n     hyponym       0.88      0.86      0.87      3126\\n        none       0.94      0.90      0.92     21399\\n    synonymy       0.90      0.96      0.93     14160\\n\\n    accuracy                           0.91     41814\\n   macro avg       0.89      0.89      0.89     41814\\nweighted avg       0.91      0.91      0.91     41814\\n\",\n    \"timestamp\": 1724681806,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00010\",\n    \"date\": \"2024-08-26_17-16-46\",\n    \"time_this_iter_s\": 125.1548764705658,\n    \"time_total_s\": 125.1548764705658,\n    \"pid\": 32260,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 15,\n      \"batch_size\": 128,\n      \"hidden_sizes\": [\n        1024,\n        512,\n        256,\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 125.1548764705658,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"10_activation=relu,batch_size=128,dropout_rate=0.2000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=15,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724681806.5262501,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.9122781843401732,\n      \"min\": 0.9122781843401732,\n      \"avg\": 0.9122781843401732,\n      \"last\": 0.9122781843401732,\n      \"last-5-avg\": 0.9122781843401732,\n      \"last-10-avg\": 0.9122781843401732\n    },\n    \"precision\": {\n      \"max\": 0.9131683499768823,\n      \"min\": 0.9131683499768823,\n      \"avg\": 0.9131683499768823,\n      \"last\": 0.9131683499768823,\n      \"last-5-avg\": 0.9131683499768823,\n      \"last-10-avg\": 0.9131683499768823\n    },\n    \"recall\": {\n      \"max\": 0.9122781843401732,\n      \"min\": 0.9122781843401732,\n      \"avg\": 0.9122781843401732,\n      \"last\": 0.9122781843401732,\n      \"last-5-avg\": 0.9122781843401732,\n      \"last-10-avg\": 0.9122781843401732\n    },\n    \"f1_score\": {\n      \"max\": 0.912147110385929,\n      \"min\": 0.912147110385929,\n      \"avg\": 0.912147110385929,\n      \"last\": 0.912147110385929,\n      \"last-5-avg\": 0.912147110385929,\n      \"last-10-avg\": 0.912147110385929\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 125.1548764705658,\n      \"min\": 125.1548764705658,\n      \"avg\": 125.1548764705658,\n      \"last\": 125.1548764705658,\n      \"last-5-avg\": 125.1548764705658,\n      \"last-10-avg\": 125.1548764705658\n    },\n    \"time_total_s\": {\n      \"max\": 125.1548764705658,\n      \"min\": 125.1548764705658,\n      \"avg\": 125.1548764705658,\n      \"last\": 125.1548764705658,\n      \"last-5-avg\": 125.1548764705658,\n      \"last-10-avg\": 125.1548764705658\n    },\n    \"time_since_restore\": {\n      \"max\": 125.1548764705658,\n      \"min\": 125.1548764705658,\n      \"avg\": 125.1548764705658,\n      \"last\": 125.1548764705658,\n      \"last-5-avg\": 125.1548764705658,\n      \"last-10-avg\": 125.1548764705658\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fed316204d30cb9612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fed316204d30cb9612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086493dcd4ac38ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086493dcd4ac38ed3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b90cd3046231ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b90cd3046231ed3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430871f307234f30ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430871f307234f30ed3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405f49e97f000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405f49e97f000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405f49e97f000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405f49e97f000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405f49e97f000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405f49e97f000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00073\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303733948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 12,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 12,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 12,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"73_activation=relu,batch_size=32,dropout_rate=0.1000,hidden_sizes=512,lr=0.0001,num_epochs=12,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00073\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00073\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00093\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303933948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 40,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 40,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 40,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"93_activation=relu,batch_size=512,dropout_rate=0.2000,hidden_sizes=1024_512_256_128_64,lr=0.0000,num_epochs=40,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00093\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00093\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00040\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303430948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 33,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 33,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 33,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"40_activation=relu,batch_size=512,dropout_rate=0.0000,hidden_sizes=512,lr=0.0000,num_epochs=33,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00040\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00040\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724687370.589921,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8464868225953031,\n    \"precision\": 0.843827882436615,\n    \"recall\": 0.8464868225953031,\n    \"f1_score\": 0.8410063455107366,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380d2050000000000002100000000000000d50400000000000071010000000000001000000000000000bb07000000000000ec020000000000007f0100000000000060010000000000001801000000000000464b000000000000d9050000000000002c000000000000008f0000000000000025050000000000007031000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.78      0.48      0.59      3129\\n     hyponym       0.81      0.63      0.71      3126\\n        none       0.85      0.90      0.88     21399\\n    synonymy       0.85      0.89      0.87     14160\\n\\n    accuracy                           0.85     41814\\n   macro avg       0.82      0.73      0.76     41814\\nweighted avg       0.84      0.85      0.84     41814\\n\",\n    \"timestamp\": 1724687453,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00040\",\n    \"date\": \"2024-08-26_18-50-53\",\n    \"time_this_iter_s\": 83.15569686889648,\n    \"time_total_s\": 83.15569686889648,\n    \"pid\": 26972,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 33,\n      \"batch_size\": 512,\n      \"hidden_sizes\": [\n        512\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.0,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 83.15569686889648,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"40_activation=relu,batch_size=512,dropout_rate=0.0000,hidden_sizes=512,lr=0.0000,num_epochs=33,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724687453.7506225,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8464868225953031,\n      \"min\": 0.8464868225953031,\n      \"avg\": 0.8464868225953031,\n      \"last\": 0.8464868225953031,\n      \"last-5-avg\": 0.8464868225953031,\n      \"last-10-avg\": 0.8464868225953031\n    },\n    \"precision\": {\n      \"max\": 0.843827882436615,\n      \"min\": 0.843827882436615,\n      \"avg\": 0.843827882436615,\n      \"last\": 0.843827882436615,\n      \"last-5-avg\": 0.843827882436615,\n      \"last-10-avg\": 0.843827882436615\n    },\n    \"recall\": {\n      \"max\": 0.8464868225953031,\n      \"min\": 0.8464868225953031,\n      \"avg\": 0.8464868225953031,\n      \"last\": 0.8464868225953031,\n      \"last-5-avg\": 0.8464868225953031,\n      \"last-10-avg\": 0.8464868225953031\n    },\n    \"f1_score\": {\n      \"max\": 0.8410063455107366,\n      \"min\": 0.8410063455107366,\n      \"avg\": 0.8410063455107366,\n      \"last\": 0.8410063455107366,\n      \"last-5-avg\": 0.8410063455107366,\n      \"last-10-avg\": 0.8410063455107366\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 83.15569686889648,\n      \"min\": 83.15569686889648,\n      \"avg\": 83.15569686889648,\n      \"last\": 83.15569686889648,\n      \"last-5-avg\": 83.15569686889648,\n      \"last-10-avg\": 83.15569686889648\n    },\n    \"time_total_s\": {\n      \"max\": 83.15569686889648,\n      \"min\": 83.15569686889648,\n      \"avg\": 83.15569686889648,\n      \"last\": 83.15569686889648,\n      \"last-5-avg\": 83.15569686889648,\n      \"last-10-avg\": 83.15569686889648\n    },\n    \"time_since_restore\": {\n      \"max\": 83.15569686889648,\n      \"min\": 83.15569686889648,\n      \"avg\": 83.15569686889648,\n      \"last\": 83.15569686889648,\n      \"last-5-avg\": 83.15569686889648,\n      \"last-10-avg\": 83.15569686889648\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473feb166b88715644612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473feb166b88715644612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080c95d054a300eb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080c95d054a300eb3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308445671886b16eb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308445671886b16eb3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308904eb62386e9ea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308904eb62386e9ea3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474054c9f6f0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474054c9f6f0000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474054c9f6f0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474054c9f6f0000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474054c9f6f0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474054c9f6f0000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00080\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303830948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 22,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 22,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 22,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"80_activation=relu,batch_size=128,dropout_rate=0.0000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=22,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00080\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00080\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00013\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303133948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 24,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 24,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 24,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"13_activation=relu,batch_size=512,dropout_rate=0.2000,hidden_sizes=512,lr=0.0000,num_epochs=24,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00013\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00013\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724682358.4687073,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8307743817860047,\n    \"precision\": 0.8293527914873203,\n    \"recall\": 0.8307743817860047,\n    \"f1_score\": 0.8221746696088004,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380d8040000000000001c00000000000000fd0500000000000048010000000000000e00000000000000d406000000000000f5030000000000005f010000000000000b01000000000000f000000000000000794c000000000000230500000000000038000000000000008f00000000000000fc060000000000008d2f000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.79      0.40      0.53      3129\\n     hyponym       0.81      0.56      0.66      3126\\n        none       0.82      0.91      0.86     21399\\n    synonymy       0.86      0.86      0.86     14160\\n\\n    accuracy                           0.83     41814\\n   macro avg       0.82      0.68      0.73     41814\\nweighted avg       0.83      0.83      0.82     41814\\n\",\n    \"timestamp\": 1724682437,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00013\",\n    \"date\": \"2024-08-26_17-27-17\",\n    \"time_this_iter_s\": 78.94827795028687,\n    \"time_total_s\": 78.94827795028687,\n    \"pid\": 32008,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 24,\n      \"batch_size\": 512,\n      \"hidden_sizes\": [\n        512\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 78.94827795028687,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"13_activation=relu,batch_size=512,dropout_rate=0.2000,hidden_sizes=512,lr=0.0000,num_epochs=24,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724682437.4224005,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8307743817860047,\n      \"min\": 0.8307743817860047,\n      \"avg\": 0.8307743817860047,\n      \"last\": 0.8307743817860047,\n      \"last-5-avg\": 0.8307743817860047,\n      \"last-10-avg\": 0.8307743817860047\n    },\n    \"precision\": {\n      \"max\": 0.8293527914873203,\n      \"min\": 0.8293527914873203,\n      \"avg\": 0.8293527914873203,\n      \"last\": 0.8293527914873203,\n      \"last-5-avg\": 0.8293527914873203,\n      \"last-10-avg\": 0.8293527914873203\n    },\n    \"recall\": {\n      \"max\": 0.8307743817860047,\n      \"min\": 0.8307743817860047,\n      \"avg\": 0.8307743817860047,\n      \"last\": 0.8307743817860047,\n      \"last-5-avg\": 0.8307743817860047,\n      \"last-10-avg\": 0.8307743817860047\n    },\n    \"f1_score\": {\n      \"max\": 0.8221746696088004,\n      \"min\": 0.8221746696088004,\n      \"avg\": 0.8221746696088004,\n      \"last\": 0.8221746696088004,\n      \"last-5-avg\": 0.8221746696088004,\n      \"last-10-avg\": 0.8221746696088004\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 78.94827795028687,\n      \"min\": 78.94827795028687,\n      \"avg\": 78.94827795028687,\n      \"last\": 78.94827795028687,\n      \"last-5-avg\": 78.94827795028687,\n      \"last-10-avg\": 78.94827795028687\n    },\n    \"time_total_s\": {\n      \"max\": 78.94827795028687,\n      \"min\": 78.94827795028687,\n      \"avg\": 78.94827795028687,\n      \"last\": 78.94827795028687,\n      \"last-5-avg\": 78.94827795028687,\n      \"last-10-avg\": 78.94827795028687\n    },\n    \"time_since_restore\": {\n      \"max\": 78.94827795028687,\n      \"min\": 78.94827795028687,\n      \"avg\": 78.94827795028687,\n      \"last\": 78.94827795028687,\n      \"last-5-avg\": 78.94827795028687,\n      \"last-10-avg\": 78.94827795028687\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fea95b42804042a612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fea95b42804042a612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308611989dd0e8aea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308611989dd0e8aea3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082a040428b495ea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082a040428b495ea3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088c38b240414fea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088c38b240414fea3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474053bcb096000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474053bcb096000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474053bcb096000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474053bcb096000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474053bcb096000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474053bcb096000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00006\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303036948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 18,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 18,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 18,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"6_activation=relu,batch_size=512,dropout_rate=0.1000,hidden_sizes=128_64,lr=0.0001,num_epochs=18,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00006\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00006\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724681276.6277993,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8819849772195543,\n    \"precision\": 0.8818164072500361,\n    \"recall\": 0.8819849772195543,\n    \"f1_score\": 0.8811250804647563,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d62756666657294939428438095080000000000001a000000000000007c02000000000000ce0000000000000014000000000000007a09000000000000cc01000000000000d10000000000000001020000000000005401000000000000d04500000000000005060000000000004c000000000000004900000000000000b4020000000000000634000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.78      0.72      0.75      3065\\n     hyponym       0.85      0.78      0.81      3115\\n        none       0.91      0.88      0.90     20266\\n    synonymy       0.87      0.94      0.90     14159\\n\\n    accuracy                           0.88     40605\\n   macro avg       0.85      0.83      0.84     40605\\nweighted avg       0.88      0.88      0.88     40605\\n\",\n    \"timestamp\": 1724681353,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00006\",\n    \"date\": \"2024-08-26_17-09-13\",\n    \"time_this_iter_s\": 76.42261219024658,\n    \"time_total_s\": 76.42261219024658,\n    \"pid\": 20044,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 18,\n      \"batch_size\": 512,\n      \"hidden_sizes\": [\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.1,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 76.42261219024658,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"6_activation=relu,batch_size=512,dropout_rate=0.1000,hidden_sizes=128_64,lr=0.0001,num_epochs=18,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724681353.0544188,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8819849772195543,\n      \"min\": 0.8819849772195543,\n      \"avg\": 0.8819849772195543,\n      \"last\": 0.8819849772195543,\n      \"last-5-avg\": 0.8819849772195543,\n      \"last-10-avg\": 0.8819849772195543\n    },\n    \"precision\": {\n      \"max\": 0.8818164072500361,\n      \"min\": 0.8818164072500361,\n      \"avg\": 0.8818164072500361,\n      \"last\": 0.8818164072500361,\n      \"last-5-avg\": 0.8818164072500361,\n      \"last-10-avg\": 0.8818164072500361\n    },\n    \"recall\": {\n      \"max\": 0.8819849772195543,\n      \"min\": 0.8819849772195543,\n      \"avg\": 0.8819849772195543,\n      \"last\": 0.8819849772195543,\n      \"last-5-avg\": 0.8819849772195543,\n      \"last-10-avg\": 0.8819849772195543\n    },\n    \"f1_score\": {\n      \"max\": 0.8811250804647563,\n      \"min\": 0.8811250804647563,\n      \"avg\": 0.8811250804647563,\n      \"last\": 0.8811250804647563,\n      \"last-5-avg\": 0.8811250804647563,\n      \"last-10-avg\": 0.8811250804647563\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 76.42261219024658,\n      \"min\": 76.42261219024658,\n      \"avg\": 76.42261219024658,\n      \"last\": 76.42261219024658,\n      \"last-5-avg\": 76.42261219024658,\n      \"last-10-avg\": 76.42261219024658\n    },\n    \"time_total_s\": {\n      \"max\": 76.42261219024658,\n      \"min\": 76.42261219024658,\n      \"avg\": 76.42261219024658,\n      \"last\": 76.42261219024658,\n      \"last-5-avg\": 76.42261219024658,\n      \"last-10-avg\": 76.42261219024658\n    },\n    \"time_since_restore\": {\n      \"max\": 76.42261219024658,\n      \"min\": 76.42261219024658,\n      \"avg\": 76.42261219024658,\n      \"last\": 76.42261219024658,\n      \"last-5-avg\": 76.42261219024658,\n      \"last-10-avg\": 76.42261219024658\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fec39388f1714d0612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fec39388f1714d0612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430848e2c60ad737ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430848e2c60ad737ec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d014178f3839ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d014178f3839ec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308060289392d32ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308060289392d32ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740531b0c14000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740531b0c14000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740531b0c14000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740531b0c14000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740531b0c14000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740531b0c14000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00033\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303333948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 25,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 25,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 25,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"33_activation=relu,batch_size=128,dropout_rate=0.2000,hidden_sizes=512,lr=0.0000,num_epochs=25,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00033\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00033\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724685861.3095396,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8702869104790051,\n    \"precision\": 0.8689446677576711,\n    \"recall\": 0.8702869104790051,\n    \"f1_score\": 0.867885803085707,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d62756666657294939428438075070000000000001000000000000000af03000000000000c5000000000000001c000000000000008208000000000000be02000000000000cf000000000000009301000000000000df00000000000000d847000000000000e0040000000000005800000000000000480000000000000074040000000000003b32000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.79      0.62      0.70      3065\\n     hyponym       0.88      0.70      0.78      3115\\n        none       0.87      0.91      0.89     20266\\n    synonymy       0.89      0.91      0.90     14159\\n\\n    accuracy                           0.87     40605\\n   macro avg       0.85      0.78      0.81     40605\\nweighted avg       0.87      0.87      0.87     40605\\n\",\n    \"timestamp\": 1724685968,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00033\",\n    \"date\": \"2024-08-26_18-26-08\",\n    \"time_this_iter_s\": 107.5938367843628,\n    \"time_total_s\": 107.5938367843628,\n    \"pid\": 32528,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 25,\n      \"batch_size\": 128,\n      \"hidden_sizes\": [\n        512\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 107.5938367843628,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"33_activation=relu,batch_size=128,dropout_rate=0.2000,hidden_sizes=512,lr=0.0000,num_epochs=25,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724685968.9073775,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8702869104790051,\n      \"min\": 0.8702869104790051,\n      \"avg\": 0.8702869104790051,\n      \"last\": 0.8702869104790051,\n      \"last-5-avg\": 0.8702869104790051,\n      \"last-10-avg\": 0.8702869104790051\n    },\n    \"precision\": {\n      \"max\": 0.8689446677576711,\n      \"min\": 0.8689446677576711,\n      \"avg\": 0.8689446677576711,\n      \"last\": 0.8689446677576711,\n      \"last-5-avg\": 0.8689446677576711,\n      \"last-10-avg\": 0.8689446677576711\n    },\n    \"recall\": {\n      \"max\": 0.8702869104790051,\n      \"min\": 0.8702869104790051,\n      \"avg\": 0.8702869104790051,\n      \"last\": 0.8702869104790051,\n      \"last-5-avg\": 0.8702869104790051,\n      \"last-10-avg\": 0.8702869104790051\n    },\n    \"f1_score\": {\n      \"max\": 0.867885803085707,\n      \"min\": 0.867885803085707,\n      \"avg\": 0.867885803085707,\n      \"last\": 0.867885803085707,\n      \"last-5-avg\": 0.867885803085707,\n      \"last-10-avg\": 0.867885803085707\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 107.5938367843628,\n      \"min\": 107.5938367843628,\n      \"avg\": 107.5938367843628,\n      \"last\": 107.5938367843628,\n      \"last-5-avg\": 107.5938367843628,\n      \"last-10-avg\": 107.5938367843628\n    },\n    \"time_total_s\": {\n      \"max\": 107.5938367843628,\n      \"min\": 107.5938367843628,\n      \"avg\": 107.5938367843628,\n      \"last\": 107.5938367843628,\n      \"last-5-avg\": 107.5938367843628,\n      \"last-10-avg\": 107.5938367843628\n    },\n    \"time_since_restore\": {\n      \"max\": 107.5938367843628,\n      \"min\": 107.5938367843628,\n      \"avg\": 107.5938367843628,\n      \"last\": 107.5938367843628,\n      \"last-5-avg\": 107.5938367843628,\n      \"last-10-avg\": 107.5938367843628\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473febd963ef549d57612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473febd963ef549d57612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430866b0410c65ceeb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430866b0410c65ceeb3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308579d54ef63d9eb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308579d54ef63d9eb3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084b4e9d72b8c5eb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084b4e9d72b8c5eb3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405ae6016c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405ae6016c000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405ae6016c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405ae6016c000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405ae6016c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405ae6016c000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00065\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303635948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 64,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 64,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 64,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"65_activation=relu,batch_size=512,dropout_rate=0.1000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=64,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00065\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00065\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724693066.6072052,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.9210073181231166,\n    \"precision\": 0.92170089737011,\n    \"recall\": 0.9210073181231166,\n    \"f1_score\": 0.9208288803044603,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d6275666665729493942843803b0a0000000000001200000000000000a1010000000000004b000000000000001400000000000000cb0a000000000000200100000000000037000000000000008c010000000000002401000000000000ef4b000000000000f80400000000000014000000000000002b0000000000000097010000000000007a35000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.86      0.84      0.85      3129\\n     hyponym       0.89      0.88      0.89      3126\\n        none       0.95      0.91      0.93     21399\\n    synonymy       0.91      0.97      0.94     14160\\n\\n    accuracy                           0.92     41814\\n   macro avg       0.90      0.90      0.90     41814\\nweighted avg       0.92      0.92      0.92     41814\\n\",\n    \"timestamp\": 1724693197,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00065\",\n    \"date\": \"2024-08-26_20-26-37\",\n    \"time_this_iter_s\": 130.5490062236786,\n    \"time_total_s\": 130.5490062236786,\n    \"pid\": 8880,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 64,\n      \"batch_size\": 512,\n      \"hidden_sizes\": [\n        1024,\n        512,\n        256,\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.1,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 130.5490062236786,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"65_activation=relu,batch_size=512,dropout_rate=0.1000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=64,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724693197.161214,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.9210073181231166,\n      \"min\": 0.9210073181231166,\n      \"avg\": 0.9210073181231166,\n      \"last\": 0.9210073181231166,\n      \"last-5-avg\": 0.9210073181231166,\n      \"last-10-avg\": 0.9210073181231166\n    },\n    \"precision\": {\n      \"max\": 0.92170089737011,\n      \"min\": 0.92170089737011,\n      \"avg\": 0.92170089737011,\n      \"last\": 0.92170089737011,\n      \"last-5-avg\": 0.92170089737011,\n      \"last-10-avg\": 0.92170089737011\n    },\n    \"recall\": {\n      \"max\": 0.9210073181231166,\n      \"min\": 0.9210073181231166,\n      \"avg\": 0.9210073181231166,\n      \"last\": 0.9210073181231166,\n      \"last-5-avg\": 0.9210073181231166,\n      \"last-10-avg\": 0.9210073181231166\n    },\n    \"f1_score\": {\n      \"max\": 0.9208288803044603,\n      \"min\": 0.9208288803044603,\n      \"avg\": 0.9208288803044603,\n      \"last\": 0.9208288803044603,\n      \"last-5-avg\": 0.9208288803044603,\n      \"last-10-avg\": 0.9208288803044603\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 130.5490062236786,\n      \"min\": 130.5490062236786,\n      \"avg\": 130.5490062236786,\n      \"last\": 130.5490062236786,\n      \"last-5-avg\": 130.5490062236786,\n      \"last-10-avg\": 130.5490062236786\n    },\n    \"time_total_s\": {\n      \"max\": 130.5490062236786,\n      \"min\": 130.5490062236786,\n      \"avg\": 130.5490062236786,\n      \"last\": 130.5490062236786,\n      \"last-5-avg\": 130.5490062236786,\n      \"last-10-avg\": 130.5490062236786\n    },\n    \"time_since_restore\": {\n      \"max\": 130.5490062236786,\n      \"min\": 130.5490062236786,\n      \"avg\": 130.5490062236786,\n      \"last\": 130.5490062236786,\n      \"last-5-avg\": 130.5490062236786,\n      \"last-10-avg\": 130.5490062236786\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fed78e456d6e500612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fed78e456d6e500612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084ec05ce1927eed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084ec05ce1927eed3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800e5d656e478ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800e5d656e478ed3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308add6c3206e77ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308add6c3206e77ed3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474060519175800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474060519175800000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474060519175800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474060519175800000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474060519175800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474060519175800000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00053\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303533948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 10,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 10,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 10,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"53_activation=relu,batch_size=32,dropout_rate=0.0000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=10,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00053\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00053\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724690944.3329828,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.9096474864877793,\n    \"precision\": 0.91027796051243,\n    \"recall\": 0.9096474864877793,\n    \"f1_score\": 0.9095402661436685,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380e5090000000000001900000000000000e0010000000000005b000000000000002500000000000000a20a0000000000001d0100000000000052000000000000008c0100000000000071010000000000007d4b0000000000001d050000000000002700000000000000760000000000000023020000000000009034000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.84      0.81      0.83      3129\\n     hyponym       0.84      0.87      0.86      3126\\n        none       0.94      0.90      0.92     21399\\n    synonymy       0.90      0.95      0.92     14160\\n\\n    accuracy                           0.91     41814\\n   macro avg       0.88      0.88      0.88     41814\\nweighted avg       0.91      0.91      0.91     41814\\n\",\n    \"timestamp\": 1724691142,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00053\",\n    \"date\": \"2024-08-26_19-52-22\",\n    \"time_this_iter_s\": 198.06905126571655,\n    \"time_total_s\": 198.06905126571655,\n    \"pid\": 5088,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 10,\n      \"batch_size\": 32,\n      \"hidden_sizes\": [\n        1024,\n        512,\n        256,\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.0,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 198.06905126571655,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"53_activation=relu,batch_size=32,dropout_rate=0.0000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=10,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724691142.407439,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.9096474864877793,\n      \"min\": 0.9096474864877793,\n      \"avg\": 0.9096474864877793,\n      \"last\": 0.9096474864877793,\n      \"last-5-avg\": 0.9096474864877793,\n      \"last-10-avg\": 0.9096474864877793\n    },\n    \"precision\": {\n      \"max\": 0.91027796051243,\n      \"min\": 0.91027796051243,\n      \"avg\": 0.91027796051243,\n      \"last\": 0.91027796051243,\n      \"last-5-avg\": 0.91027796051243,\n      \"last-10-avg\": 0.91027796051243\n    },\n    \"recall\": {\n      \"max\": 0.9096474864877793,\n      \"min\": 0.9096474864877793,\n      \"avg\": 0.9096474864877793,\n      \"last\": 0.9096474864877793,\n      \"last-5-avg\": 0.9096474864877793,\n      \"last-10-avg\": 0.9096474864877793\n    },\n    \"f1_score\": {\n      \"max\": 0.9095402661436685,\n      \"min\": 0.9095402661436685,\n      \"avg\": 0.9095402661436685,\n      \"last\": 0.9095402661436685,\n      \"last-5-avg\": 0.9095402661436685,\n      \"last-10-avg\": 0.9095402661436685\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 198.06905126571655,\n      \"min\": 198.06905126571655,\n      \"avg\": 198.06905126571655,\n      \"last\": 198.06905126571655,\n      \"last-5-avg\": 198.06905126571655,\n      \"last-10-avg\": 198.06905126571655\n    },\n    \"time_total_s\": {\n      \"max\": 198.06905126571655,\n      \"min\": 198.06905126571655,\n      \"avg\": 198.06905126571655,\n      \"last\": 198.06905126571655,\n      \"last-5-avg\": 198.06905126571655,\n      \"last-10-avg\": 198.06905126571655\n    },\n    \"time_since_restore\": {\n      \"max\": 198.06905126571655,\n      \"min\": 198.06905126571655,\n      \"avg\": 198.06905126571655,\n      \"last\": 198.06905126571655,\n      \"last-5-avg\": 198.06905126571655,\n      \"last-10-avg\": 198.06905126571655\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fed1bd50bab50ce612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fed1bd50bab50ce612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087674d53eff20ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087674d53eff20ed3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ce50ab0bd51bed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ce50ab0bd51bed3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081e6e2f30f41aed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081e6e2f30f41aed3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474068c235ab000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474068c235ab000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474068c235ab000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474068c235ab000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474068c235ab000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474068c235ab000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00039\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303339948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 56,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 56,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 56,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"39_activation=relu,batch_size=512,dropout_rate=0.1000,hidden_sizes=512,lr=0.0000,num_epochs=56,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00039\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00039\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724687268.5743625,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8781986894341608,\n    \"precision\": 0.8768668992174794,\n    \"recall\": 0.8781986894341608,\n    \"f1_score\": 0.8756841851306065,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d62756666657294939428438089070000000000001400000000000000df03000000000000bd000000000000001200000000000000c7080000000000008002000000000000dd000000000000006b01000000000000e800000000000000604c000000000000e4040000000000003e0000000000000041000000000000001004000000000000c132000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.81      0.62      0.70      3129\\n     hyponym       0.88      0.72      0.79      3126\\n        none       0.88      0.91      0.90     21399\\n    synonymy       0.89      0.92      0.90     14160\\n\\n    accuracy                           0.88     41814\\n   macro avg       0.86      0.79      0.82     41814\\nweighted avg       0.88      0.88      0.88     41814\\n\",\n    \"timestamp\": 1724687362,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00039\",\n    \"date\": \"2024-08-26_18-49-22\",\n    \"time_this_iter_s\": 93.96166610717773,\n    \"time_total_s\": 93.96166610717773,\n    \"pid\": 24516,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 56,\n      \"batch_size\": 512,\n      \"hidden_sizes\": [\n        512\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.1,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 93.96166610717773,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"39_activation=relu,batch_size=512,dropout_rate=0.1000,hidden_sizes=512,lr=0.0000,num_epochs=56,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724687362.540054,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8781986894341608,\n      \"min\": 0.8781986894341608,\n      \"avg\": 0.8781986894341608,\n      \"last\": 0.8781986894341608,\n      \"last-5-avg\": 0.8781986894341608,\n      \"last-10-avg\": 0.8781986894341608\n    },\n    \"precision\": {\n      \"max\": 0.8768668992174794,\n      \"min\": 0.8768668992174794,\n      \"avg\": 0.8768668992174794,\n      \"last\": 0.8768668992174794,\n      \"last-5-avg\": 0.8768668992174794,\n      \"last-10-avg\": 0.8768668992174794\n    },\n    \"recall\": {\n      \"max\": 0.8781986894341608,\n      \"min\": 0.8781986894341608,\n      \"avg\": 0.8781986894341608,\n      \"last\": 0.8781986894341608,\n      \"last-5-avg\": 0.8781986894341608,\n      \"last-10-avg\": 0.8781986894341608\n    },\n    \"f1_score\": {\n      \"max\": 0.8756841851306065,\n      \"min\": 0.8756841851306065,\n      \"avg\": 0.8756841851306065,\n      \"last\": 0.8756841851306065,\n      \"last-5-avg\": 0.8756841851306065,\n      \"last-10-avg\": 0.8756841851306065\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 93.96166610717773,\n      \"min\": 93.96166610717773,\n      \"avg\": 93.96166610717773,\n      \"last\": 93.96166610717773,\n      \"last-5-avg\": 93.96166610717773,\n      \"last-10-avg\": 93.96166610717773\n    },\n    \"time_total_s\": {\n      \"max\": 93.96166610717773,\n      \"min\": 93.96166610717773,\n      \"avg\": 93.96166610717773,\n      \"last\": 93.96166610717773,\n      \"last-5-avg\": 93.96166610717773,\n      \"last-10-avg\": 93.96166610717773\n    },\n    \"time_since_restore\": {\n      \"max\": 93.96166610717773,\n      \"min\": 93.96166610717773,\n      \"avg\": 93.96166610717773,\n      \"last\": 93.96166610717773,\n      \"last-5-avg\": 93.96166610717773,\n      \"last-10-avg\": 93.96166610717773\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fec1a3423505021612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fec1a3423505021612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430825b0e22b4b0fec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430825b0e22b4b0fec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430821505023341aec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430821505023341aec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e85418d79a05ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e85418d79a05ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740577d8bf0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740577d8bf0000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740577d8bf0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740577d8bf0000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740577d8bf0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740577d8bf0000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00026\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303236948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 16,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 16,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 16,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"26_activation=relu,batch_size=128,dropout_rate=0.2000,hidden_sizes=128_64,lr=0.0001,num_epochs=16,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00026\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00026\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724685011.5204237,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8842753355498091,\n    \"precision\": 0.8835021627236644,\n    \"recall\": 0.8842753355498091,\n    \"f1_score\": 0.8822469867545867,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d62756666657294939428438096070000000000001d00000000000000bb030000000000008b000000000000000b000000000000006d090000000000004a02000000000000690000000000000016010000000000001f010000000000002348000000000000d2040000000000001e000000000000005200000000000000c3030000000000001c33000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.86      0.63      0.73      3065\\n     hyponym       0.86      0.77      0.81      3115\\n        none       0.88      0.91      0.90     20266\\n    synonymy       0.90      0.92      0.91     14159\\n\\n    accuracy                           0.88     40605\\n   macro avg       0.87      0.81      0.84     40605\\nweighted avg       0.88      0.88      0.88     40605\\n\",\n    \"timestamp\": 1724685114,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00026\",\n    \"date\": \"2024-08-26_18-11-54\",\n    \"time_this_iter_s\": 103.10011863708496,\n    \"time_total_s\": 103.10011863708496,\n    \"pid\": 3500,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 16,\n      \"batch_size\": 128,\n      \"hidden_sizes\": [\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 103.10011863708496,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"26_activation=relu,batch_size=128,dropout_rate=0.2000,hidden_sizes=128_64,lr=0.0001,num_epochs=16,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724685114.6255453,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8842753355498091,\n      \"min\": 0.8842753355498091,\n      \"avg\": 0.8842753355498091,\n      \"last\": 0.8842753355498091,\n      \"last-5-avg\": 0.8842753355498091,\n      \"last-10-avg\": 0.8842753355498091\n    },\n    \"precision\": {\n      \"max\": 0.8835021627236644,\n      \"min\": 0.8835021627236644,\n      \"avg\": 0.8835021627236644,\n      \"last\": 0.8835021627236644,\n      \"last-5-avg\": 0.8835021627236644,\n      \"last-10-avg\": 0.8835021627236644\n    },\n    \"recall\": {\n      \"max\": 0.8842753355498091,\n      \"min\": 0.8842753355498091,\n      \"avg\": 0.8842753355498091,\n      \"last\": 0.8842753355498091,\n      \"last-5-avg\": 0.8842753355498091,\n      \"last-10-avg\": 0.8842753355498091\n    },\n    \"f1_score\": {\n      \"max\": 0.8822469867545867,\n      \"min\": 0.8822469867545867,\n      \"avg\": 0.8822469867545867,\n      \"last\": 0.8822469867545867,\n      \"last-5-avg\": 0.8822469867545867,\n      \"last-10-avg\": 0.8822469867545867\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 103.10011863708496,\n      \"min\": 103.10011863708496,\n      \"avg\": 103.10011863708496,\n      \"last\": 103.10011863708496,\n      \"last-5-avg\": 103.10011863708496,\n      \"last-10-avg\": 103.10011863708496\n    },\n    \"time_total_s\": {\n      \"max\": 103.10011863708496,\n      \"min\": 103.10011863708496,\n      \"avg\": 103.10011863708496,\n      \"last\": 103.10011863708496,\n      \"last-5-avg\": 103.10011863708496,\n      \"last-10-avg\": 103.10011863708496\n    },\n    \"time_since_restore\": {\n      \"max\": 103.10011863708496,\n      \"min\": 103.10011863708496,\n      \"avg\": 103.10011863708496,\n      \"last\": 103.10011863708496,\n      \"last-5-avg\": 103.10011863708496,\n      \"last-10-avg\": 103.10011863708496\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fec4bfbc9db1141612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fec4bfbc9db1141612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430835fdda53a645ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430835fdda53a645ec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084111dbc9fb4bec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084111dbc9fb4bec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308376063085e3bec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308376063085e3bec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474059c66858000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474059c66858000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474059c66858000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474059c66858000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474059c66858000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474059c66858000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00078\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303738948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 28,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 28,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 28,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"78_activation=relu,batch_size=32,dropout_rate=0.0000,hidden_sizes=128_64,lr=0.0001,num_epochs=28,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00078\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00078\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00090\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303930948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 52,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 52,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 52,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"90_activation=relu,batch_size=128,dropout_rate=0.1000,hidden_sizes=512,lr=0.0000,num_epochs=52,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00090\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00090\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00005\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303035948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 39,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 39,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 39,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"5_activation=relu,batch_size=512,dropout_rate=0.0000,hidden_sizes=128_64,lr=0.0000,num_epochs=39,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00005\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00005\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724681179.6898038,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8228105419237576,\n    \"precision\": 0.8171593335928798,\n    \"recall\": 0.8228105419237576,\n    \"f1_score\": 0.8129457799740231,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d62756666657294939428438062040000000000003300000000000000d305000000000000d1010000000000000f000000000000006f060000000000004b030000000000006d0200000000000041010000000000003101000000000000eb4a0000000000003a060000000000004600000000000000da000000000000008705000000000000a930000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.73      0.36      0.48      3129\\n     hyponym       0.74      0.53      0.62      3126\\n        none       0.84      0.90      0.87     21399\\n    synonymy       0.82      0.88      0.85     14160\\n\\n    accuracy                           0.82     41814\\n   macro avg       0.78      0.67      0.70     41814\\nweighted avg       0.82      0.82      0.81     41814\\n\",\n    \"timestamp\": 1724681268,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00005\",\n    \"date\": \"2024-08-26_17-07-48\",\n    \"time_this_iter_s\": 88.64360332489014,\n    \"time_total_s\": 88.64360332489014,\n    \"pid\": 31068,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 39,\n      \"batch_size\": 512,\n      \"hidden_sizes\": [\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.0,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 88.64360332489014,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"5_activation=relu,batch_size=512,dropout_rate=0.0000,hidden_sizes=128_64,lr=0.0000,num_epochs=39,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724681268.338409,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8228105419237576,\n      \"min\": 0.8228105419237576,\n      \"avg\": 0.8228105419237576,\n      \"last\": 0.8228105419237576,\n      \"last-5-avg\": 0.8228105419237576,\n      \"last-10-avg\": 0.8228105419237576\n    },\n    \"precision\": {\n      \"max\": 0.8171593335928798,\n      \"min\": 0.8171593335928798,\n      \"avg\": 0.8171593335928798,\n      \"last\": 0.8171593335928798,\n      \"last-5-avg\": 0.8171593335928798,\n      \"last-10-avg\": 0.8171593335928798\n    },\n    \"recall\": {\n      \"max\": 0.8228105419237576,\n      \"min\": 0.8228105419237576,\n      \"avg\": 0.8228105419237576,\n      \"last\": 0.8228105419237576,\n      \"last-5-avg\": 0.8228105419237576,\n      \"last-10-avg\": 0.8228105419237576\n    },\n    \"f1_score\": {\n      \"max\": 0.8129457799740231,\n      \"min\": 0.8129457799740231,\n      \"avg\": 0.8129457799740231,\n      \"last\": 0.8129457799740231,\n      \"last-5-avg\": 0.8129457799740231,\n      \"last-10-avg\": 0.8129457799740231\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 88.64360332489014,\n      \"min\": 88.64360332489014,\n      \"avg\": 88.64360332489014,\n      \"last\": 88.64360332489014,\n      \"last-5-avg\": 88.64360332489014,\n      \"last-10-avg\": 88.64360332489014\n    },\n    \"time_total_s\": {\n      \"max\": 88.64360332489014,\n      \"min\": 88.64360332489014,\n      \"avg\": 88.64360332489014,\n      \"last\": 88.64360332489014,\n      \"last-5-avg\": 88.64360332489014,\n      \"last-10-avg\": 88.64360332489014\n    },\n    \"time_since_restore\": {\n      \"max\": 88.64360332489014,\n      \"min\": 88.64360332489014,\n      \"avg\": 88.64360332489014,\n      \"last\": 88.64360332489014,\n      \"last-5-avg\": 88.64360332489014,\n      \"last-10-avg\": 88.64360332489014\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fea5476c60bbafd612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fea5476c60bbafd612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e1e1ac542b26ea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e1e1ac542b26ea3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fdba0bc67654ea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fdba0bc67654ea3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c71b4ddea603ea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c71b4ddea603ea3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740562930cc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740562930cc000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740562930cc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740562930cc000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740562930cc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740562930cc000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00004\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303034948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 48,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 48,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 48,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"4_activation=relu,batch_size=32,dropout_rate=0.2000,hidden_sizes=1024_512_256_128_64,lr=0.0000,num_epochs=48,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00004\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00004\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724680397.2915196,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.9161433321019579,\n    \"precision\": 0.9183880503996842,\n    \"recall\": 0.9161433321019579,\n    \"f1_score\": 0.9160682135006615,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380a30a0000000000000c00000000000000210100000000000029000000000000000f000000000000008c0a0000000000002e010000000000006200000000000000140200000000000027010000000000004c46000000000000a305000000000000220000000000000016000000000000004201000000000000d535000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.82      0.89      0.86      3065\\n     hyponym       0.89      0.87      0.88      3115\\n        none       0.95      0.89      0.92     20266\\n    synonymy       0.90      0.97      0.93     14159\\n\\n    accuracy                           0.92     40605\\n   macro avg       0.89      0.90      0.90     40605\\nweighted avg       0.92      0.92      0.92     40605\\n\",\n    \"timestamp\": 1724681170,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00004\",\n    \"date\": \"2024-08-26_17-06-10\",\n    \"time_this_iter_s\": 773.323451757431,\n    \"time_total_s\": 773.323451757431,\n    \"pid\": 33540,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 48,\n      \"batch_size\": 32,\n      \"hidden_sizes\": [\n        1024,\n        512,\n        256,\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 773.323451757431,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"4_activation=relu,batch_size=32,dropout_rate=0.2000,hidden_sizes=1024_512_256_128_64,lr=0.0000,num_epochs=48,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724681170.6209736,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.9161433321019579,\n      \"min\": 0.9161433321019579,\n      \"avg\": 0.9161433321019579,\n      \"last\": 0.9161433321019579,\n      \"last-5-avg\": 0.9161433321019579,\n      \"last-10-avg\": 0.9161433321019579\n    },\n    \"precision\": {\n      \"max\": 0.9183880503996842,\n      \"min\": 0.9183880503996842,\n      \"avg\": 0.9183880503996842,\n      \"last\": 0.9183880503996842,\n      \"last-5-avg\": 0.9183880503996842,\n      \"last-10-avg\": 0.9183880503996842\n    },\n    \"recall\": {\n      \"max\": 0.9161433321019579,\n      \"min\": 0.9161433321019579,\n      \"avg\": 0.9161433321019579,\n      \"last\": 0.9161433321019579,\n      \"last-5-avg\": 0.9161433321019579,\n      \"last-10-avg\": 0.9161433321019579\n    },\n    \"f1_score\": {\n      \"max\": 0.9160682135006615,\n      \"min\": 0.9160682135006615,\n      \"avg\": 0.9160682135006615,\n      \"last\": 0.9160682135006615,\n      \"last-5-avg\": 0.9160682135006615,\n      \"last-10-avg\": 0.9160682135006615\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 773.323451757431,\n      \"min\": 773.323451757431,\n      \"avg\": 773.323451757431,\n      \"last\": 773.323451757431,\n      \"last-5-avg\": 773.323451757431,\n      \"last-10-avg\": 773.323451757431\n    },\n    \"time_total_s\": {\n      \"max\": 773.323451757431,\n      \"min\": 773.323451757431,\n      \"avg\": 773.323451757431,\n      \"last\": 773.323451757431,\n      \"last-5-avg\": 773.323451757431,\n      \"last-10-avg\": 773.323451757431\n    },\n    \"time_since_restore\": {\n      \"max\": 773.323451757431,\n      \"min\": 773.323451757431,\n      \"avg\": 773.323451757431,\n      \"last\": 773.323451757431,\n      \"last-5-avg\": 773.323451757431,\n      \"last-10-avg\": 773.323451757431\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fed510bd23a71ac612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fed510bd23a71ac612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087c1f30566f63ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087c1f30566f63ed3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ac713ad20b51ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ac713ad20b51ed3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308de7e3c496e50ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308de7e3c496e50ed3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740882a966de00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740882a966de00000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740882a966de00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740882a966de00000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740882a966de00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740882a966de00000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00001\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303031948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 56,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 56,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 56,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"1_activation=relu,batch_size=128,dropout_rate=0.1000,hidden_sizes=512,lr=0.0000,num_epochs=56,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00001\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00001\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724679257.2844267,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8972540327545869,\n    \"precision\": 0.896708360454782,\n    \"recall\": 0.8972540327545869,\n    \"f1_score\": 0.8961580011280733,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380aa080000000000001500000000000000d5020000000000006500000000000000120000000000000089090000000000002a0200000000000066000000000000004201000000000000d600000000000000ae4800000000000064040000000000002d0000000000000024000000000000008e030000000000007033000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.85      0.72      0.78      3065\\n     hyponym       0.90      0.78      0.84      3115\\n        none       0.89      0.92      0.91     20266\\n    synonymy       0.91      0.93      0.92     14159\\n\\n    accuracy                           0.90     40605\\n   macro avg       0.89      0.84      0.86     40605\\nweighted avg       0.90      0.90      0.90     40605\\n\",\n    \"timestamp\": 1724679422,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00001\",\n    \"date\": \"2024-08-26_16-37-02\",\n    \"time_this_iter_s\": 164.78935885429382,\n    \"time_total_s\": 164.78935885429382,\n    \"pid\": 20896,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 56,\n      \"batch_size\": 128,\n      \"hidden_sizes\": [\n        512\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.1,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 164.78935885429382,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"1_activation=relu,batch_size=128,dropout_rate=0.1000,hidden_sizes=512,lr=0.0000,num_epochs=56,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724679422.080027,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8972540327545869,\n      \"min\": 0.8972540327545869,\n      \"avg\": 0.8972540327545869,\n      \"last\": 0.8972540327545869,\n      \"last-5-avg\": 0.8972540327545869,\n      \"last-10-avg\": 0.8972540327545869\n    },\n    \"precision\": {\n      \"max\": 0.896708360454782,\n      \"min\": 0.896708360454782,\n      \"avg\": 0.896708360454782,\n      \"last\": 0.896708360454782,\n      \"last-5-avg\": 0.896708360454782,\n      \"last-10-avg\": 0.896708360454782\n    },\n    \"recall\": {\n      \"max\": 0.8972540327545869,\n      \"min\": 0.8972540327545869,\n      \"avg\": 0.8972540327545869,\n      \"last\": 0.8972540327545869,\n      \"last-5-avg\": 0.8972540327545869,\n      \"last-10-avg\": 0.8972540327545869\n    },\n    \"f1_score\": {\n      \"max\": 0.8961580011280733,\n      \"min\": 0.8961580011280733,\n      \"avg\": 0.8961580011280733,\n      \"last\": 0.8961580011280733,\n      \"last-5-avg\": 0.8961580011280733,\n      \"last-10-avg\": 0.8961580011280733\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 164.78935885429382,\n      \"min\": 164.78935885429382,\n      \"avg\": 164.78935885429382,\n      \"last\": 164.78935885429382,\n      \"last-5-avg\": 164.78935885429382,\n      \"last-10-avg\": 164.78935885429382\n    },\n    \"time_total_s\": {\n      \"max\": 164.78935885429382,\n      \"min\": 164.78935885429382,\n      \"avg\": 164.78935885429382,\n      \"last\": 164.78935885429382,\n      \"last-5-avg\": 164.78935885429382,\n      \"last-10-avg\": 164.78935885429382\n    },\n    \"time_since_restore\": {\n      \"max\": 164.78935885429382,\n      \"min\": 164.78935885429382,\n      \"avg\": 164.78935885429382,\n      \"last\": 164.78935885429382,\n      \"last-5-avg\": 164.78935885429382,\n      \"last-10-avg\": 164.78935885429382\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fecb64e16dc5271612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fecb64e16dc5271612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308897f46bbd5b1ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308897f46bbd5b1ec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087152dc164eb6ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087152dc164eb6ec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080f9a5c8b53adec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080f9a5c8b53adec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447406499426d800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447406499426d800000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447406499426d800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447406499426d800000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447406499426d800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447406499426d800000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00019\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303139948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 69,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 69,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 69,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"19_activation=relu,batch_size=32,dropout_rate=0.2000,hidden_sizes=128_64,lr=0.0000,num_epochs=69,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00019\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00019\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724683021.460006,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.9016869843615318,\n    \"precision\": 0.9014606568669208,\n    \"recall\": 0.9016869843615318,\n    \"f1_score\": 0.9011296708070207,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d6275666665729493942843806609000000000000140000000000000045020000000000003a000000000000000b00000000000000ec09000000000000bf010000000000007500000000000000ba010000000000003c0100000000000005470000000000002f05000000000000220000000000000023000000000000005c02000000000000ae34000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.83      0.78      0.81      3065\\n     hyponym       0.87      0.82      0.84      3115\\n        none       0.92      0.90      0.91     20266\\n    synonymy       0.90      0.95      0.93     14159\\n\\n    accuracy                           0.90     40605\\n   macro avg       0.88      0.86      0.87     40605\\nweighted avg       0.90      0.90      0.90     40605\\n\",\n    \"timestamp\": 1724683669,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00019\",\n    \"date\": \"2024-08-26_17-47-49\",\n    \"time_this_iter_s\": 647.8082473278046,\n    \"time_total_s\": 647.8082473278046,\n    \"pid\": 3132,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 69,\n      \"batch_size\": 32,\n      \"hidden_sizes\": [\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 647.8082473278046,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"19_activation=relu,batch_size=32,dropout_rate=0.2000,hidden_sizes=128_64,lr=0.0000,num_epochs=69,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724683669.2736375,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.9016869843615318,\n      \"min\": 0.9016869843615318,\n      \"avg\": 0.9016869843615318,\n      \"last\": 0.9016869843615318,\n      \"last-5-avg\": 0.9016869843615318,\n      \"last-10-avg\": 0.9016869843615318\n    },\n    \"precision\": {\n      \"max\": 0.9014606568669208,\n      \"min\": 0.9014606568669208,\n      \"avg\": 0.9014606568669208,\n      \"last\": 0.9014606568669208,\n      \"last-5-avg\": 0.9014606568669208,\n      \"last-10-avg\": 0.9014606568669208\n    },\n    \"recall\": {\n      \"max\": 0.9016869843615318,\n      \"min\": 0.9016869843615318,\n      \"avg\": 0.9016869843615318,\n      \"last\": 0.9016869843615318,\n      \"last-5-avg\": 0.9016869843615318,\n      \"last-10-avg\": 0.9016869843615318\n    },\n    \"f1_score\": {\n      \"max\": 0.9011296708070207,\n      \"min\": 0.9011296708070207,\n      \"avg\": 0.9011296708070207,\n      \"last\": 0.9011296708070207,\n      \"last-5-avg\": 0.9011296708070207,\n      \"last-10-avg\": 0.9011296708070207\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 647.8082473278046,\n      \"min\": 647.8082473278046,\n      \"avg\": 647.8082473278046,\n      \"last\": 647.8082473278046,\n      \"last-5-avg\": 647.8082473278046,\n      \"last-10-avg\": 647.8082473278046\n    },\n    \"time_total_s\": {\n      \"max\": 647.8082473278046,\n      \"min\": 647.8082473278046,\n      \"avg\": 647.8082473278046,\n      \"last\": 647.8082473278046,\n      \"last-5-avg\": 647.8082473278046,\n      \"last-10-avg\": 647.8082473278046\n    },\n    \"time_since_restore\": {\n      \"max\": 647.8082473278046,\n      \"min\": 647.8082473278046,\n      \"avg\": 647.8082473278046,\n      \"last\": 647.8082473278046,\n      \"last-5-avg\": 647.8082473278046,\n      \"last-10-avg\": 647.8082473278046\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fecda9ea9a1f8fa612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fecda9ea9a1f8fa612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a6f8fb04c4d8ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a6f8fb04c4d8ec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308faf8a1a99edaec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308faf8a1a99edaec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e84832e40dd6ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e84832e40dd6ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740843e774a600000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740843e774a600000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740843e774a600000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740843e774a600000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740843e774a600000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740843e774a600000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00064\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303634948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 50,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 50,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 50,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"64_activation=relu,batch_size=512,dropout_rate=0.1000,hidden_sizes=1024_512_256_128_64,lr=0.0000,num_epochs=50,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00064\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00064\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724692943.4615285,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.9018347494150967,\n    \"precision\": 0.9032561407289045,\n    \"recall\": 0.9018347494150967,\n    \"f1_score\": 0.9018245899898787,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380ee090000000000001300000000000000c50100000000000033000000000000002300000000000000050a0000000000009f010000000000006400000000000000810200000000000032010000000000002f46000000000000480500000000000063000000000000001e00000000000000e501000000000000e934000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.77      0.83      0.80      3065\\n     hyponym       0.88      0.82      0.85      3115\\n        none       0.93      0.89      0.91     20266\\n    synonymy       0.90      0.96      0.93     14159\\n\\n    accuracy                           0.90     40605\\n   macro avg       0.87      0.87      0.87     40605\\nweighted avg       0.90      0.90      0.90     40605\\n\",\n    \"timestamp\": 1724693058,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00064\",\n    \"date\": \"2024-08-26_20-24-18\",\n    \"time_this_iter_s\": 114.65579628944397,\n    \"time_total_s\": 114.65579628944397,\n    \"pid\": 28340,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 50,\n      \"batch_size\": 512,\n      \"hidden_sizes\": [\n        1024,\n        512,\n        256,\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.1,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 114.65579628944397,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"64_activation=relu,batch_size=512,dropout_rate=0.1000,hidden_sizes=1024_512_256_128_64,lr=0.0000,num_epochs=50,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724693058.1223207,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.9018347494150967,\n      \"min\": 0.9018347494150967,\n      \"avg\": 0.9018347494150967,\n      \"last\": 0.9018347494150967,\n      \"last-5-avg\": 0.9018347494150967,\n      \"last-10-avg\": 0.9018347494150967\n    },\n    \"precision\": {\n      \"max\": 0.9032561407289045,\n      \"min\": 0.9032561407289045,\n      \"avg\": 0.9032561407289045,\n      \"last\": 0.9032561407289045,\n      \"last-5-avg\": 0.9032561407289045,\n      \"last-10-avg\": 0.9032561407289045\n    },\n    \"recall\": {\n      \"max\": 0.9018347494150967,\n      \"min\": 0.9018347494150967,\n      \"avg\": 0.9018347494150967,\n      \"last\": 0.9018347494150967,\n      \"last-5-avg\": 0.9018347494150967,\n      \"last-10-avg\": 0.9018347494150967\n    },\n    \"f1_score\": {\n      \"max\": 0.9018245899898787,\n      \"min\": 0.9018245899898787,\n      \"avg\": 0.9018245899898787,\n      \"last\": 0.9018245899898787,\n      \"last-5-avg\": 0.9018245899898787,\n      \"last-10-avg\": 0.9018245899898787\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 114.65579628944397,\n      \"min\": 114.65579628944397,\n      \"avg\": 114.65579628944397,\n      \"last\": 114.65579628944397,\n      \"last-5-avg\": 114.65579628944397,\n      \"last-10-avg\": 114.65579628944397\n    },\n    \"time_total_s\": {\n      \"max\": 114.65579628944397,\n      \"min\": 114.65579628944397,\n      \"avg\": 114.65579628944397,\n      \"last\": 114.65579628944397,\n      \"last-5-avg\": 114.65579628944397,\n      \"last-10-avg\": 114.65579628944397\n    },\n    \"time_since_restore\": {\n      \"max\": 114.65579628944397,\n      \"min\": 114.65579628944397,\n      \"avg\": 114.65579628944397,\n      \"last\": 114.65579628944397,\n      \"last-5-avg\": 114.65579628944397,\n      \"last-10-avg\": 114.65579628944397\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fecdbd48c644b54612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fecdbd48c644b54612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082df00a6c79e7ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082df00a6c79e7ec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308544b648cd4dbec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308544b648cd4dbec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084086173ebfdbec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084086173ebfdbec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405ca9f891000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405ca9f891000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405ca9f891000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405ca9f891000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405ca9f891000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405ca9f891000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00050\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303530948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 14,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 14,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 14,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"50_activation=relu,batch_size=128,dropout_rate=0.0000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=14,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00050\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00050\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724690564.6331363,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.9104366958434974,\n    \"precision\": 0.9113327764763662,\n    \"recall\": 0.9104366958434974,\n    \"f1_score\": 0.9102859570993732,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380720a000000000000080000000000000083010000000000003c000000000000001b00000000000000c409000000000000d40100000000000083000000000000003802000000000000b600000000000000054c000000000000a4040000000000004100000000000000150000000000000080020000000000007a34000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.80      0.85      0.83      3129\\n     hyponym       0.92      0.80      0.86      3126\\n        none       0.93      0.91      0.92     21399\\n    synonymy       0.91      0.95      0.93     14160\\n\\n    accuracy                           0.91     41814\\n   macro avg       0.89      0.88      0.88     41814\\nweighted avg       0.91      0.91      0.91     41814\\n\",\n    \"timestamp\": 1724690679,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00050\",\n    \"date\": \"2024-08-26_19-44-39\",\n    \"time_this_iter_s\": 115.1576178073883,\n    \"time_total_s\": 115.1576178073883,\n    \"pid\": 33708,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 14,\n      \"batch_size\": 128,\n      \"hidden_sizes\": [\n        1024,\n        512,\n        256,\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.0,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 115.1576178073883,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"50_activation=relu,batch_size=128,dropout_rate=0.0000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=14,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724690679.7947538,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.9104366958434974,\n      \"min\": 0.9104366958434974,\n      \"avg\": 0.9104366958434974,\n      \"last\": 0.9104366958434974,\n      \"last-5-avg\": 0.9104366958434974,\n      \"last-10-avg\": 0.9104366958434974\n    },\n    \"precision\": {\n      \"max\": 0.9113327764763662,\n      \"min\": 0.9113327764763662,\n      \"avg\": 0.9113327764763662,\n      \"last\": 0.9113327764763662,\n      \"last-5-avg\": 0.9113327764763662,\n      \"last-10-avg\": 0.9113327764763662\n    },\n    \"recall\": {\n      \"max\": 0.9104366958434974,\n      \"min\": 0.9104366958434974,\n      \"avg\": 0.9104366958434974,\n      \"last\": 0.9104366958434974,\n      \"last-5-avg\": 0.9104366958434974,\n      \"last-10-avg\": 0.9104366958434974\n    },\n    \"f1_score\": {\n      \"max\": 0.9102859570993732,\n      \"min\": 0.9102859570993732,\n      \"avg\": 0.9102859570993732,\n      \"last\": 0.9102859570993732,\n      \"last-5-avg\": 0.9102859570993732,\n      \"last-10-avg\": 0.9102859570993732\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 115.1576178073883,\n      \"min\": 115.1576178073883,\n      \"avg\": 115.1576178073883,\n      \"last\": 115.1576178073883,\n      \"last-5-avg\": 115.1576178073883,\n      \"last-10-avg\": 115.1576178073883\n    },\n    \"time_total_s\": {\n      \"max\": 115.1576178073883,\n      \"min\": 115.1576178073883,\n      \"avg\": 115.1576178073883,\n      \"last\": 115.1576178073883,\n      \"last-5-avg\": 115.1576178073883,\n      \"last-10-avg\": 115.1576178073883\n    },\n    \"time_since_restore\": {\n      \"max\": 115.1576178073883,\n      \"min\": 115.1576178073883,\n      \"avg\": 115.1576178073883,\n      \"last\": 115.1576178073883,\n      \"last-5-avg\": 115.1576178073883,\n      \"last-10-avg\": 115.1576178073883\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fed224c23373c61612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fed224c23373c61612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d5a4d75aa329ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d5a4d75aa329ed3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308613c37234c22ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308613c37234c22ed3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e9fef7031021ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e9fef7031021ed3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405cca1669000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405cca1669000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405cca1669000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405cca1669000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405cca1669000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405cca1669000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00060\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303630948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 54,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 54,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 54,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"60_activation=relu,batch_size=128,dropout_rate=0.1000,hidden_sizes=512,lr=0.0000,num_epochs=54,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00060\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00060\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724692444.8713458,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.9008226909647487,\n    \"precision\": 0.9001098305717193,\n    \"recall\": 0.9008226909647487,\n    \"f1_score\": 0.9000241315656848,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d62756666657294939428438011090000000000001200000000000000b10200000000000065000000000000001300000000000000c109000000000000dc010000000000008600000000000000a901000000000000f600000000000000564c000000000000a20400000000000048000000000000002f00000000000000de02000000000000fb33000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.82      0.74      0.78      3129\\n     hyponym       0.89      0.80      0.84      3126\\n        none       0.91      0.91      0.91     21399\\n    synonymy       0.90      0.94      0.92     14160\\n\\n    accuracy                           0.90     41814\\n   macro avg       0.88      0.85      0.86     41814\\nweighted avg       0.90      0.90      0.90     41814\\n\",\n    \"timestamp\": 1724692600,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00060\",\n    \"date\": \"2024-08-26_20-16-40\",\n    \"time_this_iter_s\": 156.11438059806824,\n    \"time_total_s\": 156.11438059806824,\n    \"pid\": 14624,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 54,\n      \"batch_size\": 128,\n      \"hidden_sizes\": [\n        512\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.1,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 156.11438059806824,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"60_activation=relu,batch_size=128,dropout_rate=0.1000,hidden_sizes=512,lr=0.0000,num_epochs=54,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724692600.9907274,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.9008226909647487,\n      \"min\": 0.9008226909647487,\n      \"avg\": 0.9008226909647487,\n      \"last\": 0.9008226909647487,\n      \"last-5-avg\": 0.9008226909647487,\n      \"last-10-avg\": 0.9008226909647487\n    },\n    \"precision\": {\n      \"max\": 0.9001098305717193,\n      \"min\": 0.9001098305717193,\n      \"avg\": 0.9001098305717193,\n      \"last\": 0.9001098305717193,\n      \"last-5-avg\": 0.9001098305717193,\n      \"last-10-avg\": 0.9001098305717193\n    },\n    \"recall\": {\n      \"max\": 0.9008226909647487,\n      \"min\": 0.9008226909647487,\n      \"avg\": 0.9008226909647487,\n      \"last\": 0.9008226909647487,\n      \"last-5-avg\": 0.9008226909647487,\n      \"last-10-avg\": 0.9008226909647487\n    },\n    \"f1_score\": {\n      \"max\": 0.9000241315656848,\n      \"min\": 0.9000241315656848,\n      \"avg\": 0.9000241315656848,\n      \"last\": 0.9000241315656848,\n      \"last-5-avg\": 0.9000241315656848,\n      \"last-10-avg\": 0.9000241315656848\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 156.11438059806824,\n      \"min\": 156.11438059806824,\n      \"avg\": 156.11438059806824,\n      \"last\": 156.11438059806824,\n      \"last-5-avg\": 156.11438059806824,\n      \"last-10-avg\": 156.11438059806824\n    },\n    \"time_total_s\": {\n      \"max\": 156.11438059806824,\n      \"min\": 156.11438059806824,\n      \"avg\": 156.11438059806824,\n      \"last\": 156.11438059806824,\n      \"last-5-avg\": 156.11438059806824,\n      \"last-10-avg\": 156.11438059806824\n    },\n    \"time_since_restore\": {\n      \"max\": 156.11438059806824,\n      \"min\": 156.11438059806824,\n      \"avg\": 156.11438059806824,\n      \"last\": 156.11438059806824,\n      \"last-5-avg\": 156.11438059806824,\n      \"last-10-avg\": 156.11438059806824\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fecd38a1ba606a3612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fecd38a1ba606a3612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e7a2a321b3cdec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e7a2a321b3cdec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a306a61b8ad3ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a306a61b8ad3ec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f1ee5568ffccec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f1ee5568ffccec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447406383a901800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447406383a901800000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447406383a901800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447406383a901800000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447406383a901800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447406383a901800000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00079\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303739948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 25,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 25,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 25,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"79_activation=relu,batch_size=128,dropout_rate=0.2000,hidden_sizes=1024_512_256_128_64,lr=0.0000,num_epochs=25,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00079\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00079\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00037\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303337948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 12,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 12,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 12,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"37_activation=relu,batch_size=32,dropout_rate=0.0000,hidden_sizes=128_64,lr=0.0000,num_epochs=12,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00037\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00037\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724686989.0091848,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8329506863729851,\n    \"precision\": 0.8284476605815355,\n    \"recall\": 0.8329506863729851,\n    \"f1_score\": 0.8259301617687819,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d6275666665729493942843800c05000000000000380000000000000067050000000000008e01000000000000150000000000000068070000000000003603000000000000830100000000000047010000000000005701000000000000ad4b0000000000004c050000000000006400000000000000ef000000000000001106000000000000ec2f000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.74      0.41      0.53      3129\\n     hyponym       0.75      0.61      0.67      3126\\n        none       0.84      0.91      0.87     21399\\n    synonymy       0.85      0.87      0.86     14160\\n\\n    accuracy                           0.83     41814\\n   macro avg       0.79      0.70      0.73     41814\\nweighted avg       0.83      0.83      0.83     41814\\n\",\n    \"timestamp\": 1724687151,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00037\",\n    \"date\": \"2024-08-26_18-45-51\",\n    \"time_this_iter_s\": 162.16068530082703,\n    \"time_total_s\": 162.16068530082703,\n    \"pid\": 33100,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 12,\n      \"batch_size\": 32,\n      \"hidden_sizes\": [\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.0,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 162.16068530082703,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"37_activation=relu,batch_size=32,dropout_rate=0.0000,hidden_sizes=128_64,lr=0.0000,num_epochs=12,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724687151.1745193,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8329506863729851,\n      \"min\": 0.8329506863729851,\n      \"avg\": 0.8329506863729851,\n      \"last\": 0.8329506863729851,\n      \"last-5-avg\": 0.8329506863729851,\n      \"last-10-avg\": 0.8329506863729851\n    },\n    \"precision\": {\n      \"max\": 0.8284476605815355,\n      \"min\": 0.8284476605815355,\n      \"avg\": 0.8284476605815355,\n      \"last\": 0.8284476605815355,\n      \"last-5-avg\": 0.8284476605815355,\n      \"last-10-avg\": 0.8284476605815355\n    },\n    \"recall\": {\n      \"max\": 0.8329506863729851,\n      \"min\": 0.8329506863729851,\n      \"avg\": 0.8329506863729851,\n      \"last\": 0.8329506863729851,\n      \"last-5-avg\": 0.8329506863729851,\n      \"last-10-avg\": 0.8329506863729851\n    },\n    \"f1_score\": {\n      \"max\": 0.8259301617687819,\n      \"min\": 0.8259301617687819,\n      \"avg\": 0.8259301617687819,\n      \"last\": 0.8259301617687819,\n      \"last-5-avg\": 0.8259301617687819,\n      \"last-10-avg\": 0.8259301617687819\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 162.16068530082703,\n      \"min\": 162.16068530082703,\n      \"avg\": 162.16068530082703,\n      \"last\": 162.16068530082703,\n      \"last-5-avg\": 162.16068530082703,\n      \"last-10-avg\": 162.16068530082703\n    },\n    \"time_total_s\": {\n      \"max\": 162.16068530082703,\n      \"min\": 162.16068530082703,\n      \"avg\": 162.16068530082703,\n      \"last\": 162.16068530082703,\n      \"last-5-avg\": 162.16068530082703,\n      \"last-10-avg\": 162.16068530082703\n    },\n    \"time_since_restore\": {\n      \"max\": 162.16068530082703,\n      \"min\": 162.16068530082703,\n      \"avg\": 162.16068530082703,\n      \"last\": 162.16068530082703,\n      \"last-5-avg\": 162.16068530082703,\n      \"last-10-avg\": 162.16068530082703\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473feaa78832a4e31d612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473feaa78832a4e31d612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430825a714aba482ea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430825a714aba482ea3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081de3a43288a7ea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081de3a43288a7ea3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430807763217056eea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430807763217056eea3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474064452455800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474064452455800000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474064452455800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474064452455800000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474064452455800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474064452455800000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00011\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303131948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 15,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 15,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 15,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"11_activation=relu,batch_size=32,dropout_rate=0.1000,hidden_sizes=128_64,lr=0.0000,num_epochs=15,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00011\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00011\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724681814.7299504,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8497632371932845,\n    \"precision\": 0.8470944419491699,\n    \"recall\": 0.8497632371932845,\n    \"f1_score\": 0.8463960144998239,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d6275666665729493942843809d0600000000000024000000000000000c040000000000006c010000000000001200000000000000250800000000000061020000000000009e01000000000000fd010000000000008b010000000000006a49000000000000a50600000000000049000000000000009700000000000000d003000000000000a032000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.74      0.54      0.62      3129\\n     hyponym       0.78      0.67      0.72      3126\\n        none       0.88      0.88      0.88     21399\\n    synonymy       0.84      0.92      0.88     14160\\n\\n    accuracy                           0.85     41814\\n   macro avg       0.81      0.75      0.77     41814\\nweighted avg       0.85      0.85      0.85     41814\\n\",\n    \"timestamp\": 1724682014,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00011\",\n    \"date\": \"2024-08-26_17-20-14\",\n    \"time_this_iter_s\": 199.61583471298218,\n    \"time_total_s\": 199.61583471298218,\n    \"pid\": 6864,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 15,\n      \"batch_size\": 32,\n      \"hidden_sizes\": [\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.1,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 199.61583471298218,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"11_activation=relu,batch_size=32,dropout_rate=0.1000,hidden_sizes=128_64,lr=0.0000,num_epochs=15,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724682014.3507817,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8497632371932845,\n      \"min\": 0.8497632371932845,\n      \"avg\": 0.8497632371932845,\n      \"last\": 0.8497632371932845,\n      \"last-5-avg\": 0.8497632371932845,\n      \"last-10-avg\": 0.8497632371932845\n    },\n    \"precision\": {\n      \"max\": 0.8470944419491699,\n      \"min\": 0.8470944419491699,\n      \"avg\": 0.8470944419491699,\n      \"last\": 0.8470944419491699,\n      \"last-5-avg\": 0.8470944419491699,\n      \"last-10-avg\": 0.8470944419491699\n    },\n    \"recall\": {\n      \"max\": 0.8497632371932845,\n      \"min\": 0.8497632371932845,\n      \"avg\": 0.8497632371932845,\n      \"last\": 0.8497632371932845,\n      \"last-5-avg\": 0.8497632371932845,\n      \"last-10-avg\": 0.8497632371932845\n    },\n    \"f1_score\": {\n      \"max\": 0.8463960144998239,\n      \"min\": 0.8463960144998239,\n      \"avg\": 0.8463960144998239,\n      \"last\": 0.8463960144998239,\n      \"last-5-avg\": 0.8463960144998239,\n      \"last-10-avg\": 0.8463960144998239\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 199.61583471298218,\n      \"min\": 199.61583471298218,\n      \"avg\": 199.61583471298218,\n      \"last\": 199.61583471298218,\n      \"last-5-avg\": 199.61583471298218,\n      \"last-10-avg\": 199.61583471298218\n    },\n    \"time_total_s\": {\n      \"max\": 199.61583471298218,\n      \"min\": 199.61583471298218,\n      \"avg\": 199.61583471298218,\n      \"last\": 199.61583471298218,\n      \"last-5-avg\": 199.61583471298218,\n      \"last-10-avg\": 199.61583471298218\n    },\n    \"time_since_restore\": {\n      \"max\": 199.61583471298218,\n      \"min\": 199.61583471298218,\n      \"avg\": 199.61583471298218,\n      \"last\": 199.61583471298218,\n      \"last-5-avg\": 199.61583471298218,\n      \"last-10-avg\": 199.61583471298218\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473feb3142ac22d2ed612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473feb3142ac22d2ed612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308187199cd651beb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308187199cd651beb3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308edd222ac4231eb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308edd222ac4231eb3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430840ba3718ad15eb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430840ba3718ad15eb3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474068f3b4eb000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474068f3b4eb000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474068f3b4eb000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474068f3b4eb000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474068f3b4eb000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474068f3b4eb000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00077\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303737948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 49,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 49,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 49,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"77_activation=relu,batch_size=128,dropout_rate=0.0000,hidden_sizes=512,lr=0.0001,num_epochs=49,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00077\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00077\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00049\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303439948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 38,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 38,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 38,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"49_activation=relu,batch_size=512,dropout_rate=0.2000,hidden_sizes=1024_512_256_128_64,lr=0.0000,num_epochs=38,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00049\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00049\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724690452.8049097,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8872552641300332,\n    \"precision\": 0.8891423103558062,\n    \"recall\": 0.8872552641300332,\n    \"f1_score\": 0.887405738433852,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d6275666665729493942843805e0900000000000025000000000000000d0200000000000069000000000000002100000000000000110a00000000000082010000000000007700000000000000c502000000000000ba01000000000000ee44000000000000bd0500000000000075000000000000006f000000000000000d020000000000005e34000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.74      0.78      0.76      3065\\n     hyponym       0.81      0.83      0.82      3115\\n        none       0.92      0.87      0.90     20266\\n    synonymy       0.89      0.95      0.92     14159\\n\\n    accuracy                           0.89     40605\\n   macro avg       0.84      0.86      0.85     40605\\nweighted avg       0.89      0.89      0.89     40605\\n\",\n    \"timestamp\": 1724690556,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00049\",\n    \"date\": \"2024-08-26_19-42-36\",\n    \"time_this_iter_s\": 103.45283079147339,\n    \"time_total_s\": 103.45283079147339,\n    \"pid\": 2028,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 38,\n      \"batch_size\": 512,\n      \"hidden_sizes\": [\n        1024,\n        512,\n        256,\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 103.45283079147339,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"49_activation=relu,batch_size=512,dropout_rate=0.2000,hidden_sizes=1024_512_256_128_64,lr=0.0000,num_epochs=38,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724690556.2627432,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8872552641300332,\n      \"min\": 0.8872552641300332,\n      \"avg\": 0.8872552641300332,\n      \"last\": 0.8872552641300332,\n      \"last-5-avg\": 0.8872552641300332,\n      \"last-10-avg\": 0.8872552641300332\n    },\n    \"precision\": {\n      \"max\": 0.8891423103558062,\n      \"min\": 0.8891423103558062,\n      \"avg\": 0.8891423103558062,\n      \"last\": 0.8891423103558062,\n      \"last-5-avg\": 0.8891423103558062,\n      \"last-10-avg\": 0.8891423103558062\n    },\n    \"recall\": {\n      \"max\": 0.8872552641300332,\n      \"min\": 0.8872552641300332,\n      \"avg\": 0.8872552641300332,\n      \"last\": 0.8872552641300332,\n      \"last-5-avg\": 0.8872552641300332,\n      \"last-10-avg\": 0.8872552641300332\n    },\n    \"f1_score\": {\n      \"max\": 0.887405738433852,\n      \"min\": 0.887405738433852,\n      \"avg\": 0.887405738433852,\n      \"last\": 0.887405738433852,\n      \"last-5-avg\": 0.887405738433852,\n      \"last-10-avg\": 0.887405738433852\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 103.45283079147339,\n      \"min\": 103.45283079147339,\n      \"avg\": 103.45283079147339,\n      \"last\": 103.45283079147339,\n      \"last-5-avg\": 103.45283079147339,\n      \"last-10-avg\": 103.45283079147339\n    },\n    \"time_total_s\": {\n      \"max\": 103.45283079147339,\n      \"min\": 103.45283079147339,\n      \"avg\": 103.45283079147339,\n      \"last\": 103.45283079147339,\n      \"last-5-avg\": 103.45283079147339,\n      \"last-10-avg\": 103.45283079147339\n    },\n    \"time_since_restore\": {\n      \"max\": 103.45283079147339,\n      \"min\": 103.45283079147339,\n      \"avg\": 103.45283079147339,\n      \"last\": 103.45283079147339,\n      \"last-5-avg\": 103.45283079147339,\n      \"last-10-avg\": 103.45283079147339\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fec646526d48e01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fec646526d48e01612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086dfa0e93da73ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086dfa0e93da73ec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308018ed4266564ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308018ed4266564ec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085f651bb8a065ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085f651bb8a065ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474059dcfb2e000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474059dcfb2e000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474059dcfb2e000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474059dcfb2e000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474059dcfb2e000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474059dcfb2e000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00056\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303536948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 57,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 57,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 57,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"56_activation=relu,batch_size=32,dropout_rate=0.2000,hidden_sizes=512,lr=0.0001,num_epochs=57,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00056\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00056\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724691628.995853,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.9142631654469795,\n    \"precision\": 0.9144361176693934,\n    \"recall\": 0.9142631654469795,\n    \"f1_score\": 0.9139434209148143,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380ee0900000000000012000000000000000402000000000000350000000000000010000000000000006c0a00000000000071010000000000004900000000000000c8010000000000000001000000000000dc4b000000000000f3040000000000001700000000000000150000000000000005020000000000001f35000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.84      0.81      0.82      3129\\n     hyponym       0.90      0.85      0.88      3126\\n        none       0.93      0.91      0.92     21399\\n    synonymy       0.91      0.96      0.93     14160\\n\\n    accuracy                           0.91     41814\\n   macro avg       0.89      0.88      0.89     41814\\nweighted avg       0.91      0.91      0.91     41814\\n\",\n    \"timestamp\": 1724692065,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00056\",\n    \"date\": \"2024-08-26_20-07-45\",\n    \"time_this_iter_s\": 436.728004693985,\n    \"time_total_s\": 436.728004693985,\n    \"pid\": 24936,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 57,\n      \"batch_size\": 32,\n      \"hidden_sizes\": [\n        512\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 436.728004693985,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"56_activation=relu,batch_size=32,dropout_rate=0.2000,hidden_sizes=512,lr=0.0001,num_epochs=57,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724692065.7278588,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.9142631654469795,\n      \"min\": 0.9142631654469795,\n      \"avg\": 0.9142631654469795,\n      \"last\": 0.9142631654469795,\n      \"last-5-avg\": 0.9142631654469795,\n      \"last-10-avg\": 0.9142631654469795\n    },\n    \"precision\": {\n      \"max\": 0.9144361176693934,\n      \"min\": 0.9144361176693934,\n      \"avg\": 0.9144361176693934,\n      \"last\": 0.9144361176693934,\n      \"last-5-avg\": 0.9144361176693934,\n      \"last-10-avg\": 0.9144361176693934\n    },\n    \"recall\": {\n      \"max\": 0.9142631654469795,\n      \"min\": 0.9142631654469795,\n      \"avg\": 0.9142631654469795,\n      \"last\": 0.9142631654469795,\n      \"last-5-avg\": 0.9142631654469795,\n      \"last-10-avg\": 0.9142631654469795\n    },\n    \"f1_score\": {\n      \"max\": 0.9139434209148143,\n      \"min\": 0.9139434209148143,\n      \"avg\": 0.9139434209148143,\n      \"last\": 0.9139434209148143,\n      \"last-5-avg\": 0.9139434209148143,\n      \"last-10-avg\": 0.9139434209148143\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 436.728004693985,\n      \"min\": 436.728004693985,\n      \"avg\": 436.728004693985,\n      \"last\": 436.728004693985,\n      \"last-5-avg\": 436.728004693985,\n      \"last-10-avg\": 436.728004693985\n    },\n    \"time_total_s\": {\n      \"max\": 436.728004693985,\n      \"min\": 436.728004693985,\n      \"avg\": 436.728004693985,\n      \"last\": 436.728004693985,\n      \"last-5-avg\": 436.728004693985,\n      \"last-10-avg\": 436.728004693985\n    },\n    \"time_since_restore\": {\n      \"max\": 436.728004693985,\n      \"min\": 436.728004693985,\n      \"avg\": 436.728004693985,\n      \"last\": 436.728004693985,\n      \"last-5-avg\": 436.728004693985,\n      \"last-10-avg\": 436.728004693985\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fed41a4d37107e6612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fed41a4d37107e6612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e67a75880f43ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e67a75880f43ed3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e60771d3a441ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e60771d3a441ed3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d426e745063fed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d426e745063fed3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407b4ba5e8400000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407b4ba5e8400000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407b4ba5e8400000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407b4ba5e8400000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407b4ba5e8400000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407b4ba5e8400000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00091\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303931948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 24,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 24,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 24,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"91_activation=relu,batch_size=512,dropout_rate=0.2000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=24,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00091\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00091\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00069\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303639948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 19,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 19,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 19,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"69_activation=relu,batch_size=32,dropout_rate=0.0000,hidden_sizes=512,lr=0.0001,num_epochs=19,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"relative_logdir\": \"run78d58_00069\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00069\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724695320.1970775,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"trial_id\": \"78d58_00069\"\n  },\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00002\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303032948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 63,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 63,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 63,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"2_activation=relu,batch_size=32,dropout_rate=0.0000,hidden_sizes=1024_512_256_128_64,lr=0.0000,num_epochs=63,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00002\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00002\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724679430.5425413,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.9104051225218569,\n    \"precision\": 0.9117123172203254,\n    \"recall\": 0.9104051225218569,\n    \"f1_score\": 0.909868894577146,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380e9090000000000000f00000000000000aa0100000000000057000000000000000a00000000000000df09000000000000c0010000000000008200000000000000a901000000000000d500000000000000bf46000000000000ed050000000000001d0000000000000010000000000000004201000000000000e035000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.85      0.83      0.84      3065\\n     hyponym       0.91      0.81      0.86      3115\\n        none       0.94      0.89      0.92     20266\\n    synonymy       0.89      0.97      0.93     14159\\n\\n    accuracy                           0.91     40605\\n   macro avg       0.90      0.88      0.88     40605\\nweighted avg       0.91      0.91      0.91     40605\\n\",\n    \"timestamp\": 1724680287,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00002\",\n    \"date\": \"2024-08-26_16-51-27\",\n    \"time_this_iter_s\": 856.6420238018036,\n    \"time_total_s\": 856.6420238018036,\n    \"pid\": 32408,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 63,\n      \"batch_size\": 32,\n      \"hidden_sizes\": [\n        1024,\n        512,\n        256,\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.0,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 856.6420238018036,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"2_activation=relu,batch_size=32,dropout_rate=0.0000,hidden_sizes=1024_512_256_128_64,lr=0.0000,num_epochs=63,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724680287.189583,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.9104051225218569,\n      \"min\": 0.9104051225218569,\n      \"avg\": 0.9104051225218569,\n      \"last\": 0.9104051225218569,\n      \"last-5-avg\": 0.9104051225218569,\n      \"last-10-avg\": 0.9104051225218569\n    },\n    \"precision\": {\n      \"max\": 0.9117123172203254,\n      \"min\": 0.9117123172203254,\n      \"avg\": 0.9117123172203254,\n      \"last\": 0.9117123172203254,\n      \"last-5-avg\": 0.9117123172203254,\n      \"last-10-avg\": 0.9117123172203254\n    },\n    \"recall\": {\n      \"max\": 0.9104051225218569,\n      \"min\": 0.9104051225218569,\n      \"avg\": 0.9104051225218569,\n      \"last\": 0.9104051225218569,\n      \"last-5-avg\": 0.9104051225218569,\n      \"last-10-avg\": 0.9104051225218569\n    },\n    \"f1_score\": {\n      \"max\": 0.909868894577146,\n      \"min\": 0.909868894577146,\n      \"avg\": 0.909868894577146,\n      \"last\": 0.909868894577146,\n      \"last-5-avg\": 0.909868894577146,\n      \"last-10-avg\": 0.909868894577146\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 856.6420238018036,\n      \"min\": 856.6420238018036,\n      \"avg\": 856.6420238018036,\n      \"last\": 856.6420238018036,\n      \"last-5-avg\": 856.6420238018036,\n      \"last-10-avg\": 856.6420238018036\n    },\n    \"time_total_s\": {\n      \"max\": 856.6420238018036,\n      \"min\": 856.6420238018036,\n      \"avg\": 856.6420238018036,\n      \"last\": 856.6420238018036,\n      \"last-5-avg\": 856.6420238018036,\n      \"last-10-avg\": 856.6420238018036\n    },\n    \"time_since_restore\": {\n      \"max\": 856.6420238018036,\n      \"min\": 856.6420238018036,\n      \"avg\": 856.6420238018036,\n      \"last\": 856.6420238018036,\n      \"last-5-avg\": 856.6420238018036,\n      \"last-10-avg\": 856.6420238018036\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fed2209ec6af3b3612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fed2209ec6af3b3612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082a4b3a4fbf2ced3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082a4b3a4fbf2ced3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b3f36aec0922ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b3f36aec0922ed3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430890683b5fa51ded3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430890683b5fa51ded3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447408ac522dd600000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447408ac522dd600000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447408ac522dd600000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447408ac522dd600000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447408ac522dd600000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447408ac522dd600000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00089\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303839948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 53,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 53,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 53,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"89_activation=relu,batch_size=32,dropout_rate=0.1000,hidden_sizes=128_64,lr=0.0000,num_epochs=53,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00089\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00089\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00084\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303834948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 42,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 42,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 42,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.1,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"84_activation=relu,batch_size=32,dropout_rate=0.1000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=42,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00084\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00084\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00051\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303531948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 11,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 11,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 11,\n    \"batch_size\": 128,\n    \"hidden_sizes\": [\n      512\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"51_activation=relu,batch_size=128,dropout_rate=0.0000,hidden_sizes=512,lr=0.0001,num_epochs=11,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00051\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00051\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724690688.2236805,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8800162624958148,\n    \"precision\": 0.8835441456286541,\n    \"recall\": 0.8800162624958148,\n    \"f1_score\": 0.8792302435208327,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d62756666657294939428438050090000000000000a00000000000000bb02000000000000240000000000000021000000000000001e090000000000009b020000000000005c00000000000000bc01000000000000a600000000000000a64e0000000000008f02000000000000b0000000000000001e00000000000000d907000000000000a92e000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.78      0.76      0.77      3129\\n     hyponym       0.92      0.75      0.82      3126\\n        none       0.86      0.94      0.90     21399\\n    synonymy       0.94      0.84      0.89     14160\\n\\n    accuracy                           0.88     41814\\n   macro avg       0.87      0.82      0.85     41814\\nweighted avg       0.88      0.88      0.88     41814\\n\",\n    \"timestamp\": 1724690774,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00051\",\n    \"date\": \"2024-08-26_19-46-14\",\n    \"time_this_iter_s\": 85.83034324645996,\n    \"time_total_s\": 85.83034324645996,\n    \"pid\": 332,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"num_epochs\": 11,\n      \"batch_size\": 128,\n      \"hidden_sizes\": [\n        512\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.0,\n      \"postive_percentage\": 0.6\n    },\n    \"time_since_restore\": 85.83034324645996,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"51_activation=relu,batch_size=128,dropout_rate=0.0000,hidden_sizes=512,lr=0.0001,num_epochs=11,optimizer=Adam,postive_percentage=0.6000\"\n  },\n  \"last_result_time\": 1724690774.0596058,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8800162624958148,\n      \"min\": 0.8800162624958148,\n      \"avg\": 0.8800162624958148,\n      \"last\": 0.8800162624958148,\n      \"last-5-avg\": 0.8800162624958148,\n      \"last-10-avg\": 0.8800162624958148\n    },\n    \"precision\": {\n      \"max\": 0.8835441456286541,\n      \"min\": 0.8835441456286541,\n      \"avg\": 0.8835441456286541,\n      \"last\": 0.8835441456286541,\n      \"last-5-avg\": 0.8835441456286541,\n      \"last-10-avg\": 0.8835441456286541\n    },\n    \"recall\": {\n      \"max\": 0.8800162624958148,\n      \"min\": 0.8800162624958148,\n      \"avg\": 0.8800162624958148,\n      \"last\": 0.8800162624958148,\n      \"last-5-avg\": 0.8800162624958148,\n      \"last-10-avg\": 0.8800162624958148\n    },\n    \"f1_score\": {\n      \"max\": 0.8792302435208327,\n      \"min\": 0.8792302435208327,\n      \"avg\": 0.8792302435208327,\n      \"last\": 0.8792302435208327,\n      \"last-5-avg\": 0.8792302435208327,\n      \"last-10-avg\": 0.8792302435208327\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 85.83034324645996,\n      \"min\": 85.83034324645996,\n      \"avg\": 85.83034324645996,\n      \"last\": 85.83034324645996,\n      \"last-5-avg\": 85.83034324645996,\n      \"last-10-avg\": 85.83034324645996\n    },\n    \"time_total_s\": {\n      \"max\": 85.83034324645996,\n      \"min\": 85.83034324645996,\n      \"avg\": 85.83034324645996,\n      \"last\": 85.83034324645996,\n      \"last-5-avg\": 85.83034324645996,\n      \"last-10-avg\": 85.83034324645996\n    },\n    \"time_since_restore\": {\n      \"max\": 85.83034324645996,\n      \"min\": 85.83034324645996,\n      \"avg\": 85.83034324645996,\n      \"last\": 85.83034324645996,\n      \"last-5-avg\": 85.83034324645996,\n      \"last-10-avg\": 85.83034324645996\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fec2917dd6bc400612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fec2917dd6bc400612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308bc83415ffe45ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308bc83415ffe45ec3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800c46bdd1729ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800c46bdd1729ec3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308596fb276a722ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308596fb276a722ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474055752458000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474055752458000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474055752458000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474055752458000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474055752458000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474055752458000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00098\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303938948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 41,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 41,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 41,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"98_activation=relu,batch_size=32,dropout_rate=0.0000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=41,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00098\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00098\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00092\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303932948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 36,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 36,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"evaluated_params\": {\n    \"lr\": 0.0001,\n    \"num_epochs\": 36,\n    \"batch_size\": 32,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.0,\n    \"postive_percentage\": 0.6\n  },\n  \"experiment_tag\": \"92_activation=relu,batch_size=32,dropout_rate=0.0000,hidden_sizes=1024_512_256_128_64,lr=0.0001,num_epochs=36,optimizer=Adam,postive_percentage=0.6000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"run78d58_00092\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00092\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_model\",\n  \"trial_id\": \"78d58_00057\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b6020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1f747261696e5f6d6f64656c5f323032342d30382d32365f31362d33312d3136948c0e747269616c5f6469725f6e616d65948c0e72756e37386435385f3030303537948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c0e433a2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30382d32365f31362d33312d31369475622e\"\n  },\n  \"config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 15,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 15,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"evaluated_params\": {\n    \"lr\": 1e-05,\n    \"num_epochs\": 15,\n    \"batch_size\": 512,\n    \"hidden_sizes\": [\n      1024,\n      512,\n      256,\n      128,\n      64\n    ],\n    \"activation\": \"relu\",\n    \"optimizer\": \"Adam\",\n    \"dropout_rate\": 0.2,\n    \"postive_percentage\": 0.7\n  },\n  \"experiment_tag\": \"57_activation=relu,batch_size=512,dropout_rate=0.2000,hidden_sizes=1024_512_256_128_64,lr=0.0000,num_epochs=15,optimizer=Adam,postive_percentage=0.7000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740280000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"run78d58_00057\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059514020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b024b43430c64017c006a009b009d025300944e8c0372756e9486948c08747269616c5f69649485948c05747269616c9485948c52633a5c55736572735c64617669735c4f6e6544726976655c4465736b746f705c456c697a615c61692e6c61625f70726f6772616d6d696e675c50726f64756374696f6e5c4d6f64656c5c6d6f64656c2e7079948c1a64796e616d69635f747269616c5f6e616d655f63726561746f72944baa43020001942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f9468108c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"run78d58_00057\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1724692073.3426313,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"accuracy\": 0.8210318926240611,\n    \"precision\": 0.8146253965867812,\n    \"recall\": 0.8210318926240611,\n    \"f1_score\": 0.8159518542378614,\n    \"confusion_matrix\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"800595ee000000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284380a7050000000000004400000000000000c2040000000000004c0100000000000036000000000000009f060000000000008a03000000000000cc010000000000004a02000000000000760100000000000039450000000000003106000000000000e70000000000000016010000000000009704000000000000bb30000000000000948c056e756d7079948c0564747970659493948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b044b0486948c014394749452942e\"\n    },\n    \"classification_report\": \"              precision    recall  f1-score   support\\n\\n    hypernym       0.62      0.47      0.54      3065\\n     hyponym       0.70      0.54      0.61      3115\\n        none       0.84      0.87      0.86     20266\\n    synonymy       0.84      0.88      0.86     14159\\n\\n    accuracy                           0.82     40605\\n   macro avg       0.75      0.69      0.72     40605\\nweighted avg       0.81      0.82      0.82     40605\\n\",\n    \"timestamp\": 1724692154,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"78d58_00057\",\n    \"date\": \"2024-08-26_20-09-14\",\n    \"time_this_iter_s\": 81.23779773712158,\n    \"time_total_s\": 81.23779773712158,\n    \"pid\": 20948,\n    \"hostname\": \"Davidovic\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"lr\": 1e-05,\n      \"num_epochs\": 15,\n      \"batch_size\": 512,\n      \"hidden_sizes\": [\n        1024,\n        512,\n        256,\n        128,\n        64\n      ],\n      \"activation\": \"relu\",\n      \"optimizer\": \"Adam\",\n      \"dropout_rate\": 0.2,\n      \"postive_percentage\": 0.7\n    },\n    \"time_since_restore\": 81.23779773712158,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"57_activation=relu,batch_size=512,dropout_rate=0.2000,hidden_sizes=1024_512_256_128_64,lr=0.0000,num_epochs=15,optimizer=Adam,postive_percentage=0.7000\"\n  },\n  \"last_result_time\": 1724692154.5864308,\n  \"metric_analysis\": {\n    \"accuracy\": {\n      \"max\": 0.8210318926240611,\n      \"min\": 0.8210318926240611,\n      \"avg\": 0.8210318926240611,\n      \"last\": 0.8210318926240611,\n      \"last-5-avg\": 0.8210318926240611,\n      \"last-10-avg\": 0.8210318926240611\n    },\n    \"precision\": {\n      \"max\": 0.8146253965867812,\n      \"min\": 0.8146253965867812,\n      \"avg\": 0.8146253965867812,\n      \"last\": 0.8146253965867812,\n      \"last-5-avg\": 0.8146253965867812,\n      \"last-10-avg\": 0.8146253965867812\n    },\n    \"recall\": {\n      \"max\": 0.8210318926240611,\n      \"min\": 0.8210318926240611,\n      \"avg\": 0.8210318926240611,\n      \"last\": 0.8210318926240611,\n      \"last-5-avg\": 0.8210318926240611,\n      \"last-10-avg\": 0.8210318926240611\n    },\n    \"f1_score\": {\n      \"max\": 0.8159518542378614,\n      \"min\": 0.8159518542378614,\n      \"avg\": 0.8159518542378614,\n      \"last\": 0.8159518542378614,\n      \"last-5-avg\": 0.8159518542378614,\n      \"last-10-avg\": 0.8159518542378614\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 81.23779773712158,\n      \"min\": 81.23779773712158,\n      \"avg\": 81.23779773712158,\n      \"last\": 81.23779773712158,\n      \"last-5-avg\": 81.23779773712158,\n      \"last-10-avg\": 81.23779773712158\n    },\n    \"time_total_s\": {\n      \"max\": 81.23779773712158,\n      \"min\": 81.23779773712158,\n      \"avg\": 81.23779773712158,\n      \"last\": 81.23779773712158,\n      \"last-5-avg\": 81.23779773712158,\n      \"last-10-avg\": 81.23779773712158\n    },\n    \"time_since_restore\": {\n      \"max\": 81.23779773712158,\n      \"min\": 81.23779773712158,\n      \"avg\": 81.23779773712158,\n      \"last\": 81.23779773712158,\n      \"last-5-avg\": 81.23779773712158,\n      \"last-10-avg\": 81.23779773712158\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fea45e4acf962ed612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fea45e4acf962ed612e\"\n      }\n    },\n    \"precision\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a5999a476911ea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a5999a476911ea3f9486945294612e\"\n      }\n    },\n    \"recall\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ed62f9ace445ea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ed62f9ace445ea3f9486945294612e\"\n      }\n    },\n    \"f1_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430854fd2110471cea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430854fd2110471cea3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740544f3814000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740544f3814000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740544f3814000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740544f3814000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740544f3814000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740544f3814000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"]], "runner_data": {"_earliest_stopping_actor": Infinity, "_actor_cleanup_timeout": 600, "_actor_force_cleanup_timeout": 10, "_reuse_actors": false, "_buffer_length": 1, "_buffer_min_time_s": 0.0, "_buffer_max_time_s": 100.0, "_max_pending_trials": 200, "_metric": null, "_total_time": 31306.447161197662, "_iteration": 149033, "_has_errored": false, "_fail_fast": false, "_print_trial_errors": true, "_cached_trial_decisions": {}, "_queued_trial_decisions": {}, "_should_stop_experiment": false, "_stopper": {"_type": "CLOUDPICKLE_FALLBACK", "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"}, "_start_time": 1724679076.9513257, "_session_str": "2024-08-26_16-31-16", "_checkpoint_period": "auto", "_trial_checkpoint_config": {"_type": "CLOUDPICKLE_FALLBACK", "value": "800595f2000000000000008c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394680c75622e"}, "_resumed": false}, "stats": {"start_time": 1724679076.9513257}}