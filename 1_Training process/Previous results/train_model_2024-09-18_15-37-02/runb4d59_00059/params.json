{
  "activation": "relu",
  "batch_size": 16,
  "dropout_rate": 0.0,
  "hidden_sizes": [
    512
  ],
  "lr": 1e-09,
  "num_epochs": 180,
  "optimizer": "Adam",
  "postive_percentage": 0.5
}